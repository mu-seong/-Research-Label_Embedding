{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15829551645306807057\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1118514866292952045\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16155055388888054481\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8689479877316554743\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_ls32_v2_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_ls32_v2_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_ls32_v2_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...</td>\n",
       "      <td>0.417401</td>\n",
       "      <td>3.110558</td>\n",
       "      <td>3.668839</td>\n",
       "      <td>1.226133</td>\n",
       "      <td>2.162574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931701</td>\n",
       "      <td>2.592113</td>\n",
       "      <td>...</td>\n",
       "      <td>3.868774</td>\n",
       "      <td>3.319746</td>\n",
       "      <td>3.433081</td>\n",
       "      <td>2.390619</td>\n",
       "      <td>4.531190</td>\n",
       "      <td>2.798172</td>\n",
       "      <td>2.228583</td>\n",
       "      <td>1.412827</td>\n",
       "      <td>0.902569</td>\n",
       "      <td>4.032192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...</td>\n",
       "      <td>0.156090</td>\n",
       "      <td>1.817906</td>\n",
       "      <td>2.516934</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.786605</td>\n",
       "      <td>1.056361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765907</td>\n",
       "      <td>2.722389</td>\n",
       "      <td>2.902149</td>\n",
       "      <td>1.056934</td>\n",
       "      <td>3.805281</td>\n",
       "      <td>2.013745</td>\n",
       "      <td>0.807450</td>\n",
       "      <td>1.169613</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>1.259672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...</td>\n",
       "      <td>2.615420</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>3.032917</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>4.051877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>2.249975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535463</td>\n",
       "      <td>1.525661</td>\n",
       "      <td>3.134440</td>\n",
       "      <td>3.392141</td>\n",
       "      <td>3.054707</td>\n",
       "      <td>2.136985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086341</td>\n",
       "      <td>2.693710</td>\n",
       "      <td>3.209113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...</td>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>1.078584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...</td>\n",
       "      <td>3.056171</td>\n",
       "      <td>2.104629</td>\n",
       "      <td>2.814471</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>2.857896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006338</td>\n",
       "      <td>1.256253</td>\n",
       "      <td>...</td>\n",
       "      <td>2.394616</td>\n",
       "      <td>2.801673</td>\n",
       "      <td>2.485481</td>\n",
       "      <td>3.802172</td>\n",
       "      <td>4.070567</td>\n",
       "      <td>2.348916</td>\n",
       "      <td>2.177757</td>\n",
       "      <td>0.869026</td>\n",
       "      <td>1.684833</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2800</td>\n",
       "      <td>딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...</td>\n",
       "      <td>4.186645</td>\n",
       "      <td>3.224278</td>\n",
       "      <td>2.117567</td>\n",
       "      <td>0.419262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.746918</td>\n",
       "      <td>1.778923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820696</td>\n",
       "      <td>3.612397</td>\n",
       "      <td>4.454446</td>\n",
       "      <td>1.590904</td>\n",
       "      <td>2.417366</td>\n",
       "      <td>5.644652</td>\n",
       "      <td>4.679737</td>\n",
       "      <td>1.634320</td>\n",
       "      <td>1.236829</td>\n",
       "      <td>0.237118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2801</td>\n",
       "      <td>본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...</td>\n",
       "      <td>3.364617</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>1.230430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383199</td>\n",
       "      <td>1.191509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606773</td>\n",
       "      <td>4.367097</td>\n",
       "      <td>3.565836</td>\n",
       "      <td>3.955093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233802</td>\n",
       "      <td>1.044027</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>3.691920</td>\n",
       "      <td>2.591480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2802</td>\n",
       "      <td>인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...</td>\n",
       "      <td>1.978602</td>\n",
       "      <td>1.928831</td>\n",
       "      <td>2.123523</td>\n",
       "      <td>0.511366</td>\n",
       "      <td>1.142202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.150192</td>\n",
       "      <td>2.086830</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064874</td>\n",
       "      <td>2.610252</td>\n",
       "      <td>3.291699</td>\n",
       "      <td>0.881856</td>\n",
       "      <td>1.587655</td>\n",
       "      <td>2.168864</td>\n",
       "      <td>2.272126</td>\n",
       "      <td>1.206674</td>\n",
       "      <td>1.673436</td>\n",
       "      <td>2.926039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2803</td>\n",
       "      <td>인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...</td>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255934</td>\n",
       "      <td>4.824238</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...</td>\n",
       "      <td>2.148395</td>\n",
       "      <td>1.330493</td>\n",
       "      <td>6.214635</td>\n",
       "      <td>0.701584</td>\n",
       "      <td>2.780770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.274260</td>\n",
       "      <td>1.540647</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185889</td>\n",
       "      <td>3.204329</td>\n",
       "      <td>0.845317</td>\n",
       "      <td>3.219305</td>\n",
       "      <td>3.225749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905107</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>2.276694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...  0.417401   \n",
       "1              1  고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...  0.156090   \n",
       "2              2  마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...  2.615420   \n",
       "3              3  현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...  2.049675   \n",
       "4              4  최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...  3.056171   \n",
       "...          ...                                                ...       ...   \n",
       "2800        2800  딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...  4.186645   \n",
       "2801        2801  본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...  3.364617   \n",
       "2802        2802  인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...  1.978602   \n",
       "2803        2803  인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...  2.831361   \n",
       "2804        2804  현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...  2.148395   \n",
       "\n",
       "             1         2         3         4    5         6         7  ...  \\\n",
       "0     3.110558  3.668839  1.226133  2.162574  0.0  3.931701  2.592113  ...   \n",
       "1     1.817906  2.516934  0.445787  0.861615  0.0  1.786605  1.056361  ...   \n",
       "2     0.419531  3.032917  0.012062  4.051877  0.0  0.107185  2.249975  ...   \n",
       "3     1.346292  3.854792  0.000000  0.622733  0.0  2.288307  1.360127  ...   \n",
       "4     2.104629  2.814471  0.420903  2.857896  0.0  2.006338  1.256253  ...   \n",
       "...        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "2800  3.224278  2.117567  0.419262  0.000000  0.0  2.746918  1.778923  ...   \n",
       "2801  0.964592  0.363475  0.003237  1.230430  0.0  2.383199  1.191509  ...   \n",
       "2802  1.928831  2.123523  0.511366  1.142202  0.0  2.150192  2.086830  ...   \n",
       "2803  2.731905  3.412751  0.971666  2.699568  0.0  3.641780  2.886727  ...   \n",
       "2804  1.330493  6.214635  0.701584  2.780770  0.0  3.274260  1.540647  ...   \n",
       "\n",
       "            22        23        24        25        26        27        28  \\\n",
       "0     3.868774  3.319746  3.433081  2.390619  4.531190  2.798172  2.228583   \n",
       "1     0.765907  2.722389  2.902149  1.056934  3.805281  2.013745  0.807450   \n",
       "2     1.535463  1.525661  3.134440  3.392141  3.054707  2.136985  0.000000   \n",
       "3     0.000000  2.582102  3.751017  0.447963  2.649111  2.317543  0.984748   \n",
       "4     2.394616  2.801673  2.485481  3.802172  4.070567  2.348916  2.177757   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2800  0.820696  3.612397  4.454446  1.590904  2.417366  5.644652  4.679737   \n",
       "2801  1.606773  4.367097  3.565836  3.955093  0.000000  1.233802  1.044027   \n",
       "2802  2.064874  2.610252  3.291699  0.881856  1.587655  2.168864  2.272126   \n",
       "2803  3.224768  2.851137  4.704193  2.255934  4.824238  2.652613  3.096685   \n",
       "2804  2.185889  3.204329  0.845317  3.219305  3.225749  0.000000  0.000000   \n",
       "\n",
       "            29        30        31  \n",
       "0     1.412827  0.902569  4.032192  \n",
       "1     1.169613  0.953063  1.259672  \n",
       "2     1.086341  2.693710  3.209113  \n",
       "3     0.844156  0.903332  1.078584  \n",
       "4     0.869026  1.684833  1.638000  \n",
       "...        ...       ...       ...  \n",
       "2800  1.634320  1.236829  0.237118  \n",
       "2801  0.285247  3.691920  2.591480  \n",
       "2802  1.206674  1.673436  2.926039  \n",
       "2803  1.063173  1.317709  2.316168  \n",
       "2804  0.905107  0.900056  2.276694  \n",
       "\n",
       "[2805 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...</td>\n",
       "      <td>1.160812</td>\n",
       "      <td>0.702376</td>\n",
       "      <td>1.826283</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>2.379605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>2.613026</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>2.660992</td>\n",
       "      <td>3.650507</td>\n",
       "      <td>1.895083</td>\n",
       "      <td>1.215869</td>\n",
       "      <td>1.655062</td>\n",
       "      <td>1.252426</td>\n",
       "      <td>1.994516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...</td>\n",
       "      <td>1.830713</td>\n",
       "      <td>1.299031</td>\n",
       "      <td>2.827974</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>3.418776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.422769</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050494</td>\n",
       "      <td>2.773801</td>\n",
       "      <td>2.208181</td>\n",
       "      <td>3.877333</td>\n",
       "      <td>4.353286</td>\n",
       "      <td>0.376468</td>\n",
       "      <td>1.152847</td>\n",
       "      <td>0.281889</td>\n",
       "      <td>1.411207</td>\n",
       "      <td>1.251945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...</td>\n",
       "      <td>0.723097</td>\n",
       "      <td>3.877661</td>\n",
       "      <td>3.058774</td>\n",
       "      <td>0.566229</td>\n",
       "      <td>3.005013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>1.975427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238015</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>1.527651</td>\n",
       "      <td>3.695491</td>\n",
       "      <td>4.489433</td>\n",
       "      <td>1.267462</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>1.831583</td>\n",
       "      <td>1.644332</td>\n",
       "      <td>3.562235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...</td>\n",
       "      <td>1.319847</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>3.826420</td>\n",
       "      <td>0.593425</td>\n",
       "      <td>3.193208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417923</td>\n",
       "      <td>2.732662</td>\n",
       "      <td>2.437556</td>\n",
       "      <td>2.723172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.527535</td>\n",
       "      <td>0.437404</td>\n",
       "      <td>2.085263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...</td>\n",
       "      <td>2.897877</td>\n",
       "      <td>0.160974</td>\n",
       "      <td>2.582344</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>3.052699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078064</td>\n",
       "      <td>4.584823</td>\n",
       "      <td>1.536940</td>\n",
       "      <td>3.385062</td>\n",
       "      <td>4.425127</td>\n",
       "      <td>3.917932</td>\n",
       "      <td>1.746897</td>\n",
       "      <td>2.050241</td>\n",
       "      <td>1.952030</td>\n",
       "      <td>1.620024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...</td>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701067</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341525</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...</td>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255933</td>\n",
       "      <td>4.824239</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...</td>\n",
       "      <td>2.594126</td>\n",
       "      <td>1.276027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376698</td>\n",
       "      <td>2.051559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.165917</td>\n",
       "      <td>2.785203</td>\n",
       "      <td>...</td>\n",
       "      <td>3.747175</td>\n",
       "      <td>1.908190</td>\n",
       "      <td>4.824211</td>\n",
       "      <td>1.065796</td>\n",
       "      <td>2.344577</td>\n",
       "      <td>2.191438</td>\n",
       "      <td>2.762595</td>\n",
       "      <td>0.569525</td>\n",
       "      <td>1.726421</td>\n",
       "      <td>1.344647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...</td>\n",
       "      <td>2.014281</td>\n",
       "      <td>2.630730</td>\n",
       "      <td>4.114912</td>\n",
       "      <td>0.681983</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169341</td>\n",
       "      <td>1.979973</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057004</td>\n",
       "      <td>2.688292</td>\n",
       "      <td>2.035194</td>\n",
       "      <td>2.976359</td>\n",
       "      <td>0.179143</td>\n",
       "      <td>3.286419</td>\n",
       "      <td>1.043921</td>\n",
       "      <td>0.200325</td>\n",
       "      <td>0.232417</td>\n",
       "      <td>2.168765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...</td>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.078585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...  1.160812   \n",
       "1             1  최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...  1.830713   \n",
       "2             2  가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...  0.723097   \n",
       "3             3  문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...  1.319847   \n",
       "4             4  최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...  2.897877   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...  1.387571   \n",
       "931         931  제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...  2.831361   \n",
       "932         932  초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...  2.594126   \n",
       "933         933  사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...  2.014281   \n",
       "934         934  이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...  2.049675   \n",
       "\n",
       "            1         2         3         4    5         6         7  ...  \\\n",
       "0    0.702376  1.826283  0.070483  2.379605  0.0  0.315229  0.000000  ...   \n",
       "1    1.299031  2.827974  0.773668  3.418776  0.0  2.422769  0.279148  ...   \n",
       "2    3.877661  3.058774  0.566229  3.005013  0.0  0.051266  1.975427  ...   \n",
       "3    0.874532  3.826420  0.593425  3.193208  0.0  0.000000  2.089211  ...   \n",
       "4    0.160974  2.582344  0.373056  3.052699  0.0  0.876786  0.000000  ...   \n",
       "..        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "930  3.701067  3.436297  0.713277  2.880716  0.0  1.513215  2.407779  ...   \n",
       "931  2.731905  3.412751  0.971666  2.699569  0.0  3.641780  2.886727  ...   \n",
       "932  1.276027  0.000000  0.376698  2.051559  0.0  2.165917  2.785203  ...   \n",
       "933  2.630730  4.114912  0.681983  0.295765  0.0  3.169341  1.979973  ...   \n",
       "934  1.346292  3.854792  0.000000  0.622734  0.0  2.288307  1.360127  ...   \n",
       "\n",
       "           22        23        24        25        26        27        28  \\\n",
       "0    0.659600  2.613026  0.217506  2.660992  3.650507  1.895083  1.215869   \n",
       "1    1.050494  2.773801  2.208181  3.877333  4.353286  0.376468  1.152847   \n",
       "2    0.238015  0.224763  1.527651  3.695491  4.489433  1.267462  0.980352   \n",
       "3    1.499055  0.000000  1.417923  2.732662  2.437556  2.723172  0.000000   \n",
       "4    1.078064  4.584823  1.536940  3.385062  4.425127  3.917932  1.746897   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  1.571257  1.976123  3.341525  2.811006  5.955709  2.899572  2.129996   \n",
       "931  3.224768  2.851137  4.704193  2.255933  4.824239  2.652613  3.096685   \n",
       "932  3.747175  1.908190  4.824211  1.065796  2.344577  2.191438  2.762595   \n",
       "933  1.057004  2.688292  2.035194  2.976359  0.179143  3.286419  1.043921   \n",
       "934  0.000000  2.582102  3.751017  0.447963  2.649111  2.317543  0.984748   \n",
       "\n",
       "           29        30        31  \n",
       "0    1.655062  1.252426  1.994516  \n",
       "1    0.281889  1.411207  1.251945  \n",
       "2    1.831583  1.644332  3.562235  \n",
       "3    1.527535  0.437404  2.085263  \n",
       "4    2.050241  1.952030  1.620024  \n",
       "..        ...       ...       ...  \n",
       "930  2.093030  1.566517  2.736027  \n",
       "931  1.063173  1.317709  2.316168  \n",
       "932  0.569525  1.726421  1.344647  \n",
       "933  0.200325  0.232417  2.168765  \n",
       "934  0.844156  0.903333  1.078585  \n",
       "\n",
       "[935 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...</td>\n",
       "      <td>2.721272</td>\n",
       "      <td>0.645896</td>\n",
       "      <td>4.298009</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>1.257981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.013318</td>\n",
       "      <td>1.731955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354994</td>\n",
       "      <td>2.312873</td>\n",
       "      <td>2.890211</td>\n",
       "      <td>2.014307</td>\n",
       "      <td>1.847732</td>\n",
       "      <td>5.673225</td>\n",
       "      <td>1.020746</td>\n",
       "      <td>0.565236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...</td>\n",
       "      <td>1.959765</td>\n",
       "      <td>0.626602</td>\n",
       "      <td>4.517123</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>3.517265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.748332</td>\n",
       "      <td>1.154613</td>\n",
       "      <td>...</td>\n",
       "      <td>2.489295</td>\n",
       "      <td>3.683540</td>\n",
       "      <td>2.161397</td>\n",
       "      <td>2.854535</td>\n",
       "      <td>5.056381</td>\n",
       "      <td>1.238201</td>\n",
       "      <td>0.931779</td>\n",
       "      <td>1.155392</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>1.745236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...</td>\n",
       "      <td>1.957325</td>\n",
       "      <td>3.521863</td>\n",
       "      <td>2.222190</td>\n",
       "      <td>0.223836</td>\n",
       "      <td>2.106490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.032464</td>\n",
       "      <td>1.760850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079385</td>\n",
       "      <td>2.673229</td>\n",
       "      <td>3.130688</td>\n",
       "      <td>2.876190</td>\n",
       "      <td>3.573605</td>\n",
       "      <td>0.368269</td>\n",
       "      <td>2.141461</td>\n",
       "      <td>1.194386</td>\n",
       "      <td>2.718087</td>\n",
       "      <td>3.641629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...</td>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701068</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341526</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...</td>\n",
       "      <td>0.703739</td>\n",
       "      <td>2.954461</td>\n",
       "      <td>2.771776</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>1.774965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>2.249922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.968887</td>\n",
       "      <td>2.441638</td>\n",
       "      <td>3.184179</td>\n",
       "      <td>1.979293</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>1.360672</td>\n",
       "      <td>0.692212</td>\n",
       "      <td>0.601506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>2.426008</td>\n",
       "      <td>3.340866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.929126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355311</td>\n",
       "      <td>1.899159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710930</td>\n",
       "      <td>2.244099</td>\n",
       "      <td>3.783546</td>\n",
       "      <td>1.620312</td>\n",
       "      <td>4.401006</td>\n",
       "      <td>1.960070</td>\n",
       "      <td>2.434037</td>\n",
       "      <td>1.895536</td>\n",
       "      <td>2.504398</td>\n",
       "      <td>2.101616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...</td>\n",
       "      <td>3.354524</td>\n",
       "      <td>1.159952</td>\n",
       "      <td>3.526752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.501508</td>\n",
       "      <td>1.826950</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144366</td>\n",
       "      <td>2.221884</td>\n",
       "      <td>3.508570</td>\n",
       "      <td>1.472551</td>\n",
       "      <td>2.723095</td>\n",
       "      <td>4.782733</td>\n",
       "      <td>1.848716</td>\n",
       "      <td>1.308293</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>1.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...</td>\n",
       "      <td>2.714454</td>\n",
       "      <td>1.673788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.821686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185407</td>\n",
       "      <td>2.911188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139254</td>\n",
       "      <td>1.647037</td>\n",
       "      <td>7.096872</td>\n",
       "      <td>1.583680</td>\n",
       "      <td>2.399300</td>\n",
       "      <td>3.760466</td>\n",
       "      <td>1.740469</td>\n",
       "      <td>0.742290</td>\n",
       "      <td>3.041659</td>\n",
       "      <td>1.197816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...</td>\n",
       "      <td>3.213248</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>2.797871</td>\n",
       "      <td>0.109383</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178684</td>\n",
       "      <td>3.220061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223520</td>\n",
       "      <td>1.225312</td>\n",
       "      <td>4.065963</td>\n",
       "      <td>2.213822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>1.601210</td>\n",
       "      <td>2.577209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>(연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...</td>\n",
       "      <td>2.200617</td>\n",
       "      <td>0.842916</td>\n",
       "      <td>2.497828</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>2.430539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441842</td>\n",
       "      <td>1.346443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628967</td>\n",
       "      <td>4.088872</td>\n",
       "      <td>2.199776</td>\n",
       "      <td>3.532276</td>\n",
       "      <td>1.747651</td>\n",
       "      <td>3.185071</td>\n",
       "      <td>0.429099</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>2.201858</td>\n",
       "      <td>3.067677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...  2.721272   \n",
       "1             1  본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...  1.959765   \n",
       "2             2  오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...  1.957325   \n",
       "3             3  도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...  1.387571   \n",
       "4             4  컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...  0.703739   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...  2.998761   \n",
       "931         931  4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...  3.354524   \n",
       "932         932  본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...  2.714454   \n",
       "933         933  제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...  3.213248   \n",
       "934         934  (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...  2.200617   \n",
       "\n",
       "            1         2         3         4    5         6         7  ...  \\\n",
       "0    0.645896  4.298009  0.091566  1.257981  0.0  2.013318  1.731955  ...   \n",
       "1    0.626602  4.517123  0.869072  3.517265  0.0  2.748332  1.154613  ...   \n",
       "2    3.521863  2.222190  0.223836  2.106490  0.0  2.032464  1.760850  ...   \n",
       "3    3.701068  3.436297  0.713277  2.880716  0.0  1.513215  2.407779  ...   \n",
       "4    2.954461  2.771776  0.833788  1.774965  0.0  0.097611  2.249922  ...   \n",
       "..        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "930  2.426008  3.340866  0.000000  1.929126  0.0  1.355311  1.899159  ...   \n",
       "931  1.159952  3.526752  0.000000  1.252942  0.0  1.501508  1.826950  ...   \n",
       "932  1.673788  0.000000  0.000000  1.821686  0.0  1.185407  2.911188  ...   \n",
       "933  0.995946  2.797871  0.109383  1.458100  0.0  2.178684  3.220061  ...   \n",
       "934  0.842916  2.497828  0.361635  2.430539  0.0  1.441842  1.346443  ...   \n",
       "\n",
       "           22        23        24        25        26        27        28  \\\n",
       "0    1.354994  2.312873  2.890211  2.014307  1.847732  5.673225  1.020746   \n",
       "1    2.489295  3.683540  2.161397  2.854535  5.056381  1.238201  0.931779   \n",
       "2    1.079385  2.673229  3.130688  2.876190  3.573605  0.368269  2.141461   \n",
       "3    1.571257  1.976123  3.341526  2.811006  5.955709  2.899572  2.129996   \n",
       "4    0.593649  0.000000  1.968887  2.441638  3.184179  1.979293  0.447488   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  0.710930  2.244099  3.783546  1.620312  4.401006  1.960070  2.434037   \n",
       "931  1.144366  2.221884  3.508570  1.472551  2.723095  4.782733  1.848716   \n",
       "932  1.139254  1.647037  7.096872  1.583680  2.399300  3.760466  1.740469   \n",
       "933  1.223520  1.225312  4.065963  2.213822  0.000000  2.059089  0.000000   \n",
       "934  1.628967  4.088872  2.199776  3.532276  1.747651  3.185071  0.429099   \n",
       "\n",
       "           29        30        31  \n",
       "0    0.565236  0.000000  1.063749  \n",
       "1    1.155392  0.996462  1.745236  \n",
       "2    1.194386  2.718087  3.641629  \n",
       "3    2.093030  1.566517  2.736027  \n",
       "4    1.360672  0.692212  0.601506  \n",
       "..        ...       ...       ...  \n",
       "930  1.895536  2.504398  2.101616  \n",
       "931  1.308293  0.793596  1.098957  \n",
       "932  0.742290  3.041659  1.197816  \n",
       "933  0.027858  1.601210  2.577209  \n",
       "934  0.811605  2.201858  3.067677  \n",
       "\n",
       "[935 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...\n",
       "1       고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...\n",
       "2       마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...\n",
       "3       현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...\n",
       "4       최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...\n",
       "                              ...                        \n",
       "2800    딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...\n",
       "2801    본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...\n",
       "2802    인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...\n",
       "2803    인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...\n",
       "2804    현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...\n",
       "Name: abstract, Length: 2805, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417401</td>\n",
       "      <td>3.110558</td>\n",
       "      <td>3.668839</td>\n",
       "      <td>1.226133</td>\n",
       "      <td>2.162574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931701</td>\n",
       "      <td>2.592113</td>\n",
       "      <td>2.431996</td>\n",
       "      <td>2.476200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.868774</td>\n",
       "      <td>3.319746</td>\n",
       "      <td>3.433081</td>\n",
       "      <td>2.390619</td>\n",
       "      <td>4.531190</td>\n",
       "      <td>2.798172</td>\n",
       "      <td>2.228583</td>\n",
       "      <td>1.412827</td>\n",
       "      <td>0.902569</td>\n",
       "      <td>4.032192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156090</td>\n",
       "      <td>1.817906</td>\n",
       "      <td>2.516934</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.786605</td>\n",
       "      <td>1.056361</td>\n",
       "      <td>3.568340</td>\n",
       "      <td>2.172769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765907</td>\n",
       "      <td>2.722389</td>\n",
       "      <td>2.902149</td>\n",
       "      <td>1.056934</td>\n",
       "      <td>3.805281</td>\n",
       "      <td>2.013745</td>\n",
       "      <td>0.807450</td>\n",
       "      <td>1.169613</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>1.259672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.615420</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>3.032917</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>4.051877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>2.249975</td>\n",
       "      <td>1.793349</td>\n",
       "      <td>3.025448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535463</td>\n",
       "      <td>1.525661</td>\n",
       "      <td>3.134440</td>\n",
       "      <td>3.392141</td>\n",
       "      <td>3.054707</td>\n",
       "      <td>2.136985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086341</td>\n",
       "      <td>2.693710</td>\n",
       "      <td>3.209113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>2.699560</td>\n",
       "      <td>2.448431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>1.078584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.056171</td>\n",
       "      <td>2.104629</td>\n",
       "      <td>2.814471</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>2.857896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006338</td>\n",
       "      <td>1.256253</td>\n",
       "      <td>0.640941</td>\n",
       "      <td>2.060637</td>\n",
       "      <td>...</td>\n",
       "      <td>2.394616</td>\n",
       "      <td>2.801673</td>\n",
       "      <td>2.485481</td>\n",
       "      <td>3.802172</td>\n",
       "      <td>4.070567</td>\n",
       "      <td>2.348916</td>\n",
       "      <td>2.177757</td>\n",
       "      <td>0.869026</td>\n",
       "      <td>1.684833</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>4.186645</td>\n",
       "      <td>3.224278</td>\n",
       "      <td>2.117567</td>\n",
       "      <td>0.419262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.746918</td>\n",
       "      <td>1.778923</td>\n",
       "      <td>0.206681</td>\n",
       "      <td>4.238903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820696</td>\n",
       "      <td>3.612397</td>\n",
       "      <td>4.454446</td>\n",
       "      <td>1.590904</td>\n",
       "      <td>2.417366</td>\n",
       "      <td>5.644652</td>\n",
       "      <td>4.679737</td>\n",
       "      <td>1.634320</td>\n",
       "      <td>1.236829</td>\n",
       "      <td>0.237118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>3.364617</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>1.230430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383199</td>\n",
       "      <td>1.191509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.663036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606773</td>\n",
       "      <td>4.367097</td>\n",
       "      <td>3.565836</td>\n",
       "      <td>3.955093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233802</td>\n",
       "      <td>1.044027</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>3.691920</td>\n",
       "      <td>2.591480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1.978602</td>\n",
       "      <td>1.928831</td>\n",
       "      <td>2.123523</td>\n",
       "      <td>0.511366</td>\n",
       "      <td>1.142202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.150192</td>\n",
       "      <td>2.086830</td>\n",
       "      <td>0.591417</td>\n",
       "      <td>3.308824</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064874</td>\n",
       "      <td>2.610252</td>\n",
       "      <td>3.291699</td>\n",
       "      <td>0.881856</td>\n",
       "      <td>1.587655</td>\n",
       "      <td>2.168864</td>\n",
       "      <td>2.272126</td>\n",
       "      <td>1.206674</td>\n",
       "      <td>1.673436</td>\n",
       "      <td>2.926039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>1.724109</td>\n",
       "      <td>2.706757</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255934</td>\n",
       "      <td>4.824238</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2.148395</td>\n",
       "      <td>1.330493</td>\n",
       "      <td>6.214635</td>\n",
       "      <td>0.701584</td>\n",
       "      <td>2.780770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.274260</td>\n",
       "      <td>1.540647</td>\n",
       "      <td>3.870544</td>\n",
       "      <td>1.940017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185889</td>\n",
       "      <td>3.204329</td>\n",
       "      <td>0.845317</td>\n",
       "      <td>3.219305</td>\n",
       "      <td>3.225749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905107</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>2.276694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4    5         6   \\\n",
       "0     0.417401  3.110558  3.668839  1.226133  2.162574  0.0  3.931701   \n",
       "1     0.156090  1.817906  2.516934  0.445787  0.861615  0.0  1.786605   \n",
       "2     2.615420  0.419531  3.032917  0.012062  4.051877  0.0  0.107185   \n",
       "3     2.049675  1.346292  3.854792  0.000000  0.622733  0.0  2.288307   \n",
       "4     3.056171  2.104629  2.814471  0.420903  2.857896  0.0  2.006338   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2800  4.186645  3.224278  2.117567  0.419262  0.000000  0.0  2.746918   \n",
       "2801  3.364617  0.964592  0.363475  0.003237  1.230430  0.0  2.383199   \n",
       "2802  1.978602  1.928831  2.123523  0.511366  1.142202  0.0  2.150192   \n",
       "2803  2.831361  2.731905  3.412751  0.971666  2.699568  0.0  3.641780   \n",
       "2804  2.148395  1.330493  6.214635  0.701584  2.780770  0.0  3.274260   \n",
       "\n",
       "            7         8         9   ...        22        23        24  \\\n",
       "0     2.592113  2.431996  2.476200  ...  3.868774  3.319746  3.433081   \n",
       "1     1.056361  3.568340  2.172769  ...  0.765907  2.722389  2.902149   \n",
       "2     2.249975  1.793349  3.025448  ...  1.535463  1.525661  3.134440   \n",
       "3     1.360127  2.699560  2.448431  ...  0.000000  2.582102  3.751017   \n",
       "4     1.256253  0.640941  2.060637  ...  2.394616  2.801673  2.485481   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2800  1.778923  0.206681  4.238903  ...  0.820696  3.612397  4.454446   \n",
       "2801  1.191509  0.000000  5.663036  ...  1.606773  4.367097  3.565836   \n",
       "2802  2.086830  0.591417  3.308824  ...  2.064874  2.610252  3.291699   \n",
       "2803  2.886727  1.724109  2.706757  ...  3.224768  2.851137  4.704193   \n",
       "2804  1.540647  3.870544  1.940017  ...  2.185889  3.204329  0.845317   \n",
       "\n",
       "            25        26        27        28        29        30        31  \n",
       "0     2.390619  4.531190  2.798172  2.228583  1.412827  0.902569  4.032192  \n",
       "1     1.056934  3.805281  2.013745  0.807450  1.169613  0.953063  1.259672  \n",
       "2     3.392141  3.054707  2.136985  0.000000  1.086341  2.693710  3.209113  \n",
       "3     0.447963  2.649111  2.317543  0.984748  0.844156  0.903332  1.078584  \n",
       "4     3.802172  4.070567  2.348916  2.177757  0.869026  1.684833  1.638000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2800  1.590904  2.417366  5.644652  4.679737  1.634320  1.236829  0.237118  \n",
       "2801  3.955093  0.000000  1.233802  1.044027  0.285247  3.691920  2.591480  \n",
       "2802  0.881856  1.587655  2.168864  2.272126  1.206674  1.673436  2.926039  \n",
       "2803  2.255934  4.824238  2.652613  3.096685  1.063173  1.317709  2.316168  \n",
       "2804  3.219305  3.225749  0.000000  0.000000  0.905107  0.900056  2.276694  \n",
       "\n",
       "[2805 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...\n",
       "1      최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...\n",
       "2      가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...\n",
       "3      문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...\n",
       "4      최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...\n",
       "                             ...                        \n",
       "930    인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...\n",
       "931    제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...\n",
       "932    초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...\n",
       "933    사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...\n",
       "934    이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.160812</td>\n",
       "      <td>0.702376</td>\n",
       "      <td>1.826283</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>2.379605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745975</td>\n",
       "      <td>1.606460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>2.613026</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>2.660992</td>\n",
       "      <td>3.650507</td>\n",
       "      <td>1.895083</td>\n",
       "      <td>1.215869</td>\n",
       "      <td>1.655062</td>\n",
       "      <td>1.252426</td>\n",
       "      <td>1.994516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.830713</td>\n",
       "      <td>1.299031</td>\n",
       "      <td>2.827974</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>3.418776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.422769</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>0.451877</td>\n",
       "      <td>0.110715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050494</td>\n",
       "      <td>2.773801</td>\n",
       "      <td>2.208181</td>\n",
       "      <td>3.877333</td>\n",
       "      <td>4.353286</td>\n",
       "      <td>0.376468</td>\n",
       "      <td>1.152847</td>\n",
       "      <td>0.281889</td>\n",
       "      <td>1.411207</td>\n",
       "      <td>1.251945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723097</td>\n",
       "      <td>3.877661</td>\n",
       "      <td>3.058774</td>\n",
       "      <td>0.566229</td>\n",
       "      <td>3.005013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>1.975427</td>\n",
       "      <td>0.217108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238015</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>1.527651</td>\n",
       "      <td>3.695491</td>\n",
       "      <td>4.489433</td>\n",
       "      <td>1.267462</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>1.831583</td>\n",
       "      <td>1.644332</td>\n",
       "      <td>3.562235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.319847</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>3.826420</td>\n",
       "      <td>0.593425</td>\n",
       "      <td>3.193208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089211</td>\n",
       "      <td>1.337028</td>\n",
       "      <td>0.508158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417923</td>\n",
       "      <td>2.732662</td>\n",
       "      <td>2.437556</td>\n",
       "      <td>2.723172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.527535</td>\n",
       "      <td>0.437404</td>\n",
       "      <td>2.085263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.897877</td>\n",
       "      <td>0.160974</td>\n",
       "      <td>2.582344</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>3.052699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.993815</td>\n",
       "      <td>4.044471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078064</td>\n",
       "      <td>4.584823</td>\n",
       "      <td>1.536940</td>\n",
       "      <td>3.385062</td>\n",
       "      <td>4.425127</td>\n",
       "      <td>3.917932</td>\n",
       "      <td>1.746897</td>\n",
       "      <td>2.050241</td>\n",
       "      <td>1.952030</td>\n",
       "      <td>1.620024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701067</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>2.422989</td>\n",
       "      <td>1.501756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341525</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>1.724109</td>\n",
       "      <td>2.706757</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255933</td>\n",
       "      <td>4.824239</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.594126</td>\n",
       "      <td>1.276027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376698</td>\n",
       "      <td>2.051559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.165917</td>\n",
       "      <td>2.785203</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>3.525016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.747175</td>\n",
       "      <td>1.908190</td>\n",
       "      <td>4.824211</td>\n",
       "      <td>1.065796</td>\n",
       "      <td>2.344577</td>\n",
       "      <td>2.191438</td>\n",
       "      <td>2.762595</td>\n",
       "      <td>0.569525</td>\n",
       "      <td>1.726421</td>\n",
       "      <td>1.344647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2.014281</td>\n",
       "      <td>2.630730</td>\n",
       "      <td>4.114912</td>\n",
       "      <td>0.681983</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169341</td>\n",
       "      <td>1.979973</td>\n",
       "      <td>1.175908</td>\n",
       "      <td>2.783127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057004</td>\n",
       "      <td>2.688292</td>\n",
       "      <td>2.035194</td>\n",
       "      <td>2.976359</td>\n",
       "      <td>0.179143</td>\n",
       "      <td>3.286419</td>\n",
       "      <td>1.043921</td>\n",
       "      <td>0.200325</td>\n",
       "      <td>0.232417</td>\n",
       "      <td>2.168765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>2.699560</td>\n",
       "      <td>2.448431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.078585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4    5         6   \\\n",
       "0    1.160812  0.702376  1.826283  0.070483  2.379605  0.0  0.315229   \n",
       "1    1.830713  1.299031  2.827974  0.773668  3.418776  0.0  2.422769   \n",
       "2    0.723097  3.877661  3.058774  0.566229  3.005013  0.0  0.051266   \n",
       "3    1.319847  0.874532  3.826420  0.593425  3.193208  0.0  0.000000   \n",
       "4    2.897877  0.160974  2.582344  0.373056  3.052699  0.0  0.876786   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "930  1.387571  3.701067  3.436297  0.713277  2.880716  0.0  1.513215   \n",
       "931  2.831361  2.731905  3.412751  0.971666  2.699569  0.0  3.641780   \n",
       "932  2.594126  1.276027  0.000000  0.376698  2.051559  0.0  2.165917   \n",
       "933  2.014281  2.630730  4.114912  0.681983  0.295765  0.0  3.169341   \n",
       "934  2.049675  1.346292  3.854792  0.000000  0.622734  0.0  2.288307   \n",
       "\n",
       "           7         8         9   ...        22        23        24  \\\n",
       "0    0.000000  0.745975  1.606460  ...  0.659600  2.613026  0.217506   \n",
       "1    0.279148  0.451877  0.110715  ...  1.050494  2.773801  2.208181   \n",
       "2    1.975427  0.217108  0.000000  ...  0.238015  0.224763  1.527651   \n",
       "3    2.089211  1.337028  0.508158  ...  1.499055  0.000000  1.417923   \n",
       "4    0.000000  1.993815  4.044471  ...  1.078064  4.584823  1.536940   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  2.407779  2.422989  1.501756  ...  1.571257  1.976123  3.341525   \n",
       "931  2.886727  1.724109  2.706757  ...  3.224768  2.851137  4.704193   \n",
       "932  2.785203  0.166379  3.525016  ...  3.747175  1.908190  4.824211   \n",
       "933  1.979973  1.175908  2.783127  ...  1.057004  2.688292  2.035194   \n",
       "934  1.360127  2.699560  2.448431  ...  0.000000  2.582102  3.751017   \n",
       "\n",
       "           25        26        27        28        29        30        31  \n",
       "0    2.660992  3.650507  1.895083  1.215869  1.655062  1.252426  1.994516  \n",
       "1    3.877333  4.353286  0.376468  1.152847  0.281889  1.411207  1.251945  \n",
       "2    3.695491  4.489433  1.267462  0.980352  1.831583  1.644332  3.562235  \n",
       "3    2.732662  2.437556  2.723172  0.000000  1.527535  0.437404  2.085263  \n",
       "4    3.385062  4.425127  3.917932  1.746897  2.050241  1.952030  1.620024  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "930  2.811006  5.955709  2.899572  2.129996  2.093030  1.566517  2.736027  \n",
       "931  2.255933  4.824239  2.652613  3.096685  1.063173  1.317709  2.316168  \n",
       "932  1.065796  2.344577  2.191438  2.762595  0.569525  1.726421  1.344647  \n",
       "933  2.976359  0.179143  3.286419  1.043921  0.200325  0.232417  2.168765  \n",
       "934  0.447963  2.649111  2.317543  0.984748  0.844156  0.903333  1.078585  \n",
       "\n",
       "[935 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...\n",
       "1      본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...\n",
       "2      오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...\n",
       "3      도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...\n",
       "4      컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...\n",
       "                             ...                        \n",
       "930    포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...\n",
       "931    4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...\n",
       "932    본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...\n",
       "933    제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...\n",
       "934    (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.721272</td>\n",
       "      <td>0.645896</td>\n",
       "      <td>4.298009</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>1.257981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.013318</td>\n",
       "      <td>1.731955</td>\n",
       "      <td>2.479199</td>\n",
       "      <td>3.847471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354994</td>\n",
       "      <td>2.312873</td>\n",
       "      <td>2.890211</td>\n",
       "      <td>2.014307</td>\n",
       "      <td>1.847732</td>\n",
       "      <td>5.673225</td>\n",
       "      <td>1.020746</td>\n",
       "      <td>0.565236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.959765</td>\n",
       "      <td>0.626602</td>\n",
       "      <td>4.517123</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>3.517265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.748332</td>\n",
       "      <td>1.154613</td>\n",
       "      <td>3.767540</td>\n",
       "      <td>2.511817</td>\n",
       "      <td>...</td>\n",
       "      <td>2.489295</td>\n",
       "      <td>3.683540</td>\n",
       "      <td>2.161397</td>\n",
       "      <td>2.854535</td>\n",
       "      <td>5.056381</td>\n",
       "      <td>1.238201</td>\n",
       "      <td>0.931779</td>\n",
       "      <td>1.155392</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>1.745236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.957325</td>\n",
       "      <td>3.521863</td>\n",
       "      <td>2.222190</td>\n",
       "      <td>0.223836</td>\n",
       "      <td>2.106490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.032464</td>\n",
       "      <td>1.760850</td>\n",
       "      <td>0.163494</td>\n",
       "      <td>1.658984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079385</td>\n",
       "      <td>2.673229</td>\n",
       "      <td>3.130688</td>\n",
       "      <td>2.876190</td>\n",
       "      <td>3.573605</td>\n",
       "      <td>0.368269</td>\n",
       "      <td>2.141461</td>\n",
       "      <td>1.194386</td>\n",
       "      <td>2.718087</td>\n",
       "      <td>3.641629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701068</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>2.422989</td>\n",
       "      <td>1.501756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341526</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703739</td>\n",
       "      <td>2.954461</td>\n",
       "      <td>2.771776</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>1.774965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>2.249922</td>\n",
       "      <td>1.318498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.968887</td>\n",
       "      <td>2.441638</td>\n",
       "      <td>3.184179</td>\n",
       "      <td>1.979293</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>1.360672</td>\n",
       "      <td>0.692212</td>\n",
       "      <td>0.601506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2.998761</td>\n",
       "      <td>2.426008</td>\n",
       "      <td>3.340866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.929126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355311</td>\n",
       "      <td>1.899159</td>\n",
       "      <td>1.465890</td>\n",
       "      <td>2.361195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710930</td>\n",
       "      <td>2.244099</td>\n",
       "      <td>3.783546</td>\n",
       "      <td>1.620312</td>\n",
       "      <td>4.401006</td>\n",
       "      <td>1.960070</td>\n",
       "      <td>2.434037</td>\n",
       "      <td>1.895536</td>\n",
       "      <td>2.504398</td>\n",
       "      <td>2.101616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>3.354524</td>\n",
       "      <td>1.159952</td>\n",
       "      <td>3.526752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.501508</td>\n",
       "      <td>1.826950</td>\n",
       "      <td>1.973675</td>\n",
       "      <td>3.578372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144366</td>\n",
       "      <td>2.221884</td>\n",
       "      <td>3.508570</td>\n",
       "      <td>1.472551</td>\n",
       "      <td>2.723095</td>\n",
       "      <td>4.782733</td>\n",
       "      <td>1.848716</td>\n",
       "      <td>1.308293</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>1.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.714454</td>\n",
       "      <td>1.673788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.821686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185407</td>\n",
       "      <td>2.911188</td>\n",
       "      <td>0.637718</td>\n",
       "      <td>3.822897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139254</td>\n",
       "      <td>1.647037</td>\n",
       "      <td>7.096872</td>\n",
       "      <td>1.583680</td>\n",
       "      <td>2.399300</td>\n",
       "      <td>3.760466</td>\n",
       "      <td>1.740469</td>\n",
       "      <td>0.742290</td>\n",
       "      <td>3.041659</td>\n",
       "      <td>1.197816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>3.213248</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>2.797871</td>\n",
       "      <td>0.109383</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178684</td>\n",
       "      <td>3.220061</td>\n",
       "      <td>0.931835</td>\n",
       "      <td>3.105134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223520</td>\n",
       "      <td>1.225312</td>\n",
       "      <td>4.065963</td>\n",
       "      <td>2.213822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>1.601210</td>\n",
       "      <td>2.577209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2.200617</td>\n",
       "      <td>0.842916</td>\n",
       "      <td>2.497828</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>2.430539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441842</td>\n",
       "      <td>1.346443</td>\n",
       "      <td>1.778603</td>\n",
       "      <td>4.711728</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628967</td>\n",
       "      <td>4.088872</td>\n",
       "      <td>2.199776</td>\n",
       "      <td>3.532276</td>\n",
       "      <td>1.747651</td>\n",
       "      <td>3.185071</td>\n",
       "      <td>0.429099</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>2.201858</td>\n",
       "      <td>3.067677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4    5         6   \\\n",
       "0    2.721272  0.645896  4.298009  0.091566  1.257981  0.0  2.013318   \n",
       "1    1.959765  0.626602  4.517123  0.869072  3.517265  0.0  2.748332   \n",
       "2    1.957325  3.521863  2.222190  0.223836  2.106490  0.0  2.032464   \n",
       "3    1.387571  3.701068  3.436297  0.713277  2.880716  0.0  1.513215   \n",
       "4    0.703739  2.954461  2.771776  0.833788  1.774965  0.0  0.097611   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "930  2.998761  2.426008  3.340866  0.000000  1.929126  0.0  1.355311   \n",
       "931  3.354524  1.159952  3.526752  0.000000  1.252942  0.0  1.501508   \n",
       "932  2.714454  1.673788  0.000000  0.000000  1.821686  0.0  1.185407   \n",
       "933  3.213248  0.995946  2.797871  0.109383  1.458100  0.0  2.178684   \n",
       "934  2.200617  0.842916  2.497828  0.361635  2.430539  0.0  1.441842   \n",
       "\n",
       "           7         8         9   ...        22        23        24  \\\n",
       "0    1.731955  2.479199  3.847471  ...  1.354994  2.312873  2.890211   \n",
       "1    1.154613  3.767540  2.511817  ...  2.489295  3.683540  2.161397   \n",
       "2    1.760850  0.163494  1.658984  ...  1.079385  2.673229  3.130688   \n",
       "3    2.407779  2.422989  1.501756  ...  1.571257  1.976123  3.341526   \n",
       "4    2.249922  1.318498  0.000000  ...  0.593649  0.000000  1.968887   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  1.899159  1.465890  2.361195  ...  0.710930  2.244099  3.783546   \n",
       "931  1.826950  1.973675  3.578372  ...  1.144366  2.221884  3.508570   \n",
       "932  2.911188  0.637718  3.822897  ...  1.139254  1.647037  7.096872   \n",
       "933  3.220061  0.931835  3.105134  ...  1.223520  1.225312  4.065963   \n",
       "934  1.346443  1.778603  4.711728  ...  1.628967  4.088872  2.199776   \n",
       "\n",
       "           25        26        27        28        29        30        31  \n",
       "0    2.014307  1.847732  5.673225  1.020746  0.565236  0.000000  1.063749  \n",
       "1    2.854535  5.056381  1.238201  0.931779  1.155392  0.996462  1.745236  \n",
       "2    2.876190  3.573605  0.368269  2.141461  1.194386  2.718087  3.641629  \n",
       "3    2.811006  5.955709  2.899572  2.129996  2.093030  1.566517  2.736027  \n",
       "4    2.441638  3.184179  1.979293  0.447488  1.360672  0.692212  0.601506  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "930  1.620312  4.401006  1.960070  2.434037  1.895536  2.504398  2.101616  \n",
       "931  1.472551  2.723095  4.782733  1.848716  1.308293  0.793596  1.098957  \n",
       "932  1.583680  2.399300  3.760466  1.740469  0.742290  3.041659  1.197816  \n",
       "933  2.213822  0.000000  2.059089  0.000000  0.027858  1.601210  2.577209  \n",
       "934  3.532276  1.747651  3.185071  0.429099  0.811605  2.201858  3.067677  \n",
       "\n",
       "[935 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2805/2805 [01:08<00:00, 40.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:22<00:00, 41.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:22<00:00, 41.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['로지',\n",
       "  '스틱',\n",
       "  '회귀분석은',\n",
       "  '통계학',\n",
       "  '등의',\n",
       "  '분야에서',\n",
       "  '예측을',\n",
       "  '위한',\n",
       "  '기술',\n",
       "  '혹은',\n",
       "  '변수',\n",
       "  '간의',\n",
       "  '상관관계',\n",
       "  '를',\n",
       "  '설명',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '오랫동안',\n",
       "  '사용',\n",
       "  '되어',\n",
       "  '왔다',\n",
       "  '이러한',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법에서',\n",
       "  '현재',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '들',\n",
       "  '은',\n",
       "  '목적',\n",
       "  '값에',\n",
       "  '대하여',\n",
       "  '동일한',\n",
       "  '중요도를',\n",
       "  '가지고',\n",
       "  '있다',\n",
       "  '본',\n",
       "  '연구에서는',\n",
       "  '이러한',\n",
       "  '가중치',\n",
       "  '계산',\n",
       "  '을',\n",
       "  '좀더',\n",
       "  '세분화',\n",
       "  '하여',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '의',\n",
       "  '값이',\n",
       "  '서로',\n",
       "  '다른',\n",
       "  '중요도를',\n",
       "  '가지는',\n",
       "  '새로운',\n",
       "  '학습',\n",
       "  '방법을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '알고리즘의',\n",
       "  '성능을',\n",
       "  '최대',\n",
       "  '화하는',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '가중치',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '계산',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '점진적',\n",
       "  '하강법을',\n",
       "  '이용하여',\n",
       "  '개발',\n",
       "  '하였다',\n",
       "  '본',\n",
       "  '연구에서',\n",
       "  '제안된',\n",
       "  '방법은',\n",
       "  '다양한',\n",
       "  '데이터를',\n",
       "  '이용하여',\n",
       "  '실험',\n",
       "  '하였고',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '기반',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법은',\n",
       "  '기존의',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '보다',\n",
       "  '우수한',\n",
       "  '학습',\n",
       "  '능력을',\n",
       "  '보임을',\n",
       "  '알',\n",
       "  '수',\n",
       "  '있었다'],\n",
       " ['최근에',\n",
       "  '이르러',\n",
       "  '기계학습',\n",
       "  '및',\n",
       "  '데이터마이닝',\n",
       "  '은',\n",
       "  '수많은',\n",
       "  '질병',\n",
       "  '예측',\n",
       "  '및',\n",
       "  '진단에',\n",
       "  '활용되고',\n",
       "  '있다',\n",
       "  '만성질환',\n",
       "  '은',\n",
       "  '전체',\n",
       "  '사망률',\n",
       "  '의',\n",
       "  '약',\n",
       "  '80',\n",
       "  '를',\n",
       "  '차지하는',\n",
       "  '질병',\n",
       "  '으로',\n",
       "  '점점',\n",
       "  '증가',\n",
       "  '하는',\n",
       "  '추세',\n",
       "  '이다',\n",
       "  '만성질환',\n",
       "  '관련',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '연구',\n",
       "  '한',\n",
       "  '기존',\n",
       "  '연구들은',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '구성하는',\n",
       "  '데이터로',\n",
       "  '혈당',\n",
       "  '혈압',\n",
       "  '인슐린',\n",
       "  '수치',\n",
       "  '등의',\n",
       "  '건강검진',\n",
       "  '수준의',\n",
       "  '데이터를',\n",
       "  '이용',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '논문은',\n",
       "  '만성질환',\n",
       "  '의',\n",
       "  '위험',\n",
       "  '요인인',\n",
       "  '이상',\n",
       "  '지질혈증과',\n",
       "  '안면',\n",
       "  '정보의',\n",
       "  '연관성을',\n",
       "  '검증',\n",
       "  '하고',\n",
       "  '기계학습',\n",
       "  '기반',\n",
       "  '안면',\n",
       "  '정보를',\n",
       "  '이용한',\n",
       "  '이상',\n",
       "  '지질혈증',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '세계',\n",
       "  '최초로',\n",
       "  '개발',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '연구는',\n",
       "  '5390',\n",
       "  '명의',\n",
       "  '임상',\n",
       "  '데이터',\n",
       "  '중',\n",
       "  '안면',\n",
       "  '정보와',\n",
       "  '중성지방혈증',\n",
       "  '정보를',\n",
       "  '바탕으로',\n",
       "  '수행',\n",
       "  '하였다',\n",
       "  '중성지방혈증은',\n",
       "  '이상',\n",
       "  '지질혈증을',\n",
       "  '판단하는',\n",
       "  '척도',\n",
       "  '이다',\n",
       "  '연구의',\n",
       "  '결과로',\n",
       "  '얼굴',\n",
       "  '의',\n",
       "  '하악',\n",
       "  '간의',\n",
       "  '거리를',\n",
       "  '나타내는',\n",
       "  '4314300001',\n",
       "  '0652',\n",
       "  '와',\n",
       "  '고중성지방혈증이',\n",
       "  '매우',\n",
       "  '높은',\n",
       "  '연관성을',\n",
       "  '가진',\n",
       "  '것을',\n",
       "  '밝혀냈고',\n",
       "  '이를',\n",
       "  '기반으로',\n",
       "  '구축',\n",
       "  '한',\n",
       "  '모델은',\n",
       "  '0662',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '획득',\n",
       "  '하였다',\n",
       "  '이러한',\n",
       "  '연구결과는',\n",
       "  '향후',\n",
       "  '질병',\n",
       "  '역학',\n",
       "  '및',\n",
       "  '대중',\n",
       "  '보건',\n",
       "  '영역의',\n",
       "  '스크',\n",
       "  '리닝',\n",
       "  '단계에서',\n",
       "  '안면정보만으로',\n",
       "  '다양할',\n",
       "  '질병',\n",
       "  '을',\n",
       "  '예측할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '기반을',\n",
       "  '제',\n",
       "  '공할',\n",
       "  '수',\n",
       "  '있을',\n",
       "  '것이',\n",
       "  '다'],\n",
       " ['가상',\n",
       "  '발전소',\n",
       "  '시장에',\n",
       "  '전력을',\n",
       "  '안정적으로',\n",
       "  '공급',\n",
       "  '하기',\n",
       "  '위해서는',\n",
       "  '발전',\n",
       "  '량에',\n",
       "  '대한',\n",
       "  '정확한',\n",
       "  '예측이',\n",
       "  '필요하다',\n",
       "  '하지만',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량은',\n",
       "  '기상',\n",
       "  '환경에',\n",
       "  '영향을',\n",
       "  '받아',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '편차가',\n",
       "  '심하기',\n",
       "  '때문에',\n",
       "  '안정적',\n",
       "  '인',\n",
       "  '예측이',\n",
       "  '어렵다',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '기반',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델을',\n",
       "  '제안',\n",
       "  '한다',\n",
       "  '우리는',\n",
       "  '기상',\n",
       "  '데이터와',\n",
       "  '기상',\n",
       "  '예보',\n",
       "  '데이터를',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델에',\n",
       "  '입력',\n",
       "  '하여',\n",
       "  '성능을',\n",
       "  '향상',\n",
       "  '시킨다',\n",
       "  '또한',\n",
       "  '상관계수',\n",
       "  '를',\n",
       "  '기준으로',\n",
       "  '우선순위',\n",
       "  '를',\n",
       "  '설정하',\n",
       "  '여',\n",
       "  '변수를',\n",
       "  '선택',\n",
       "  '한다',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '상관관계',\n",
       "  '와',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측',\n",
       "  '결과를',\n",
       "  '비교하여',\n",
       "  '태양광',\n",
       "  '에너지',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측에',\n",
       "  '활용',\n",
       "  '되는',\n",
       "  '최적의',\n",
       "  '기상',\n",
       "  '요인을',\n",
       "  '검토',\n",
       "  '한다'],\n",
       " ['문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '주어진',\n",
       "  '문서로부터',\n",
       "  '주요',\n",
       "  '내용을',\n",
       "  '추출',\n",
       "  '하거나',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '축약',\n",
       "  '하는',\n",
       "  '작업을',\n",
       "  '말',\n",
       "  '한다',\n",
       "  '최근',\n",
       "  '연구에서는',\n",
       "  '대량의',\n",
       "  '문서를',\n",
       "  '딥러닝',\n",
       "  '기법을',\n",
       "  '적용하여',\n",
       "  '요약',\n",
       "  '문',\n",
       "  '자체',\n",
       "  '를',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '발전',\n",
       "  '하고',\n",
       "  '있다',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '미리',\n",
       "  '생성',\n",
       "  '된',\n",
       "  '위드',\n",
       "  '임베딩',\n",
       "  '정보를',\n",
       "  '사용하는데',\n",
       "  '전문',\n",
       "  '용어와',\n",
       "  '같이',\n",
       "  '저빈도',\n",
       "  '핵심',\n",
       "  '어휘',\n",
       "  '는',\n",
       "  '입베딩',\n",
       "  '된',\n",
       "  '사전',\n",
       "  '에',\n",
       "  '없는',\n",
       "  '문제가',\n",
       "  '발생',\n",
       "  '한다',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '신경망',\n",
       "  '모델의',\n",
       "  '문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '에서',\n",
       "  '미등록',\n",
       "  '어휘',\n",
       "  '의',\n",
       "  '출현',\n",
       "  '은',\n",
       "  '요약',\n",
       "  '성능',\n",
       "  '저하',\n",
       "  '의',\n",
       "  '요인',\n",
       "  '이다',\n",
       "  '이를',\n",
       "  '해결',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '요약',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '에서',\n",
       "  '새로',\n",
       "  '출현',\n",
       "  '한',\n",
       "  '단어',\n",
       "  '를',\n",
       "  '복사',\n",
       "  '하여',\n",
       "  '요약',\n",
       "  '문을',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방법을',\n",
       "  '사용',\n",
       "  '한다',\n",
       "  '기존의',\n",
       "  '연구',\n",
       "  '와는',\n",
       "  '달리',\n",
       "  '정확한',\n",
       "  '포인',\n",
       "  '팅',\n",
       "  '정보와',\n",
       "  '선택',\n",
       "  '적',\n",
       "  '복사',\n",
       "  '지시',\n",
       "  '정보를',\n",
       "  '명시적',\n",
       "  '으로',\n",
       "  '제공하는',\n",
       "  '방법으로',\n",
       "  '제안',\n",
       "  '하였다',\n",
       "  '학습',\n",
       "  '데이터는',\n",
       "  '논문의',\n",
       "  '초록과',\n",
       "  '제목을',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '와',\n",
       "  '정답',\n",
       "  '요약',\n",
       "  '으로',\n",
       "  '사용',\n",
       "  '하였다',\n",
       "  '제안한',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '기반',\n",
       "  '모델을',\n",
       "  '통해서',\n",
       "  '자동',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '을',\n",
       "  '수행',\n",
       "  '한',\n",
       "  '결과',\n",
       "  '단어',\n",
       "  '제현',\n",
       "  '기반의',\n",
       "  '1',\n",
       "  '이',\n",
       "  '4701',\n",
       "  '로',\n",
       "  '나타났으며',\n",
       "  '또한',\n",
       "  '어순',\n",
       "  '기반의',\n",
       "  '이',\n",
       "  '2955',\n",
       "  '로',\n",
       "  '향상',\n",
       "  '되었다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3740/3740 [00:01<00:00, 3404.71it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그러므로',\n",
       " '선박,',\n",
       " '빌딩,',\n",
       " '기차,',\n",
       " '비행기',\n",
       " '등',\n",
       " 'Modbus를',\n",
       " '이용하는',\n",
       " '모든',\n",
       " '장비들과',\n",
       " '연결이',\n",
       " '가능하여',\n",
       " '환경변수의',\n",
       " '측정',\n",
       " '및',\n",
       " '원격제어가',\n",
       " '가능하게',\n",
       " '된다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3740/3740 [00:00<00:00, 340955.85it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 자발적 산업표준 통신 프로토콜이다',\n",
       " '그러므로 선박, 빌딩, 기차, 비행기 등 Modbus를 이용하는 모든 장비들과 연결이 가능하여 환경변수의 측정 및 원격제어가 가능하게 된다',\n",
       " '본 논문에서 는 퍼지제어 시스템을 이용하여 외부환경요인을 각각 조합한 불확실한 내용을 정량적인 값으로 변환하여 LED 조명으로 표현하기 위해 알고 리즘을 설계하고, 설계한 알고리즘에 Modbus 통신 프로토콜을 추가하여 선박의 통합관리 시스템에서 외부환경요인 확인 및 원격제어가 가능 한 감성조명용 LED 제어기 회로를 설계 및 구현 하였다',\n",
       " '외부환경요소인 온도, 습도, 조도 값을 센서를 통해 제어기로 받아들이고 이 값들을 퍼지제어 알고리즘을 통해 LED로 표현된다',\n",
       " 'Modbus는 Serial 통신으로 RS485를 이용하여 다른 기기와 연결 되어 온도, 습도, 조도 상태 및 LED 출력 값 확인이 가능하고 또한 사용자가 원격으로 RGB 값을 변경 할 수 있기 때문에 원하는 색으로 변경이 가능하게 된다',\n",
       " '제작한 제 어기로 온도, 습도, 조도에 따라 LED 조명색상이 변화 되는 것을 확인 하였다.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  34\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.831550802139038\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  391\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 19.31136906794128\n",
      "문장 내의 단어 개수 중앙값 : 18.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2805, 20, 200)\n",
      "train_Y_data.shape: (2805, 32)\n",
      "val_X_data.shape: (935, 20, 200)\n",
      "val_Y_data.shape: (935, 32)\n",
      "test_X_data.shape: (935, 20, 200)\n",
      "test_Y_data.shape: (935, 32)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '을': 2,\n",
       " '에': 3,\n",
       " '이': 4,\n",
       " '수': 5,\n",
       " '있다': 6,\n",
       " '하였다': 7,\n",
       " '를': 8,\n",
       " '한다': 9,\n",
       " '하고': 10,\n",
       " '할': 11,\n",
       " '본': 12,\n",
       " '대한': 13,\n",
       " '과': 14,\n",
       " '적': 15,\n",
       " '및': 16,\n",
       " '는': 17,\n",
       " '하는': 18,\n",
       " '있는': 19,\n",
       " '한': 20,\n",
       " '은': 21,\n",
       " '가': 22,\n",
       " '으로': 23,\n",
       " '것이': 24,\n",
       " '와': 25,\n",
       " '위해': 26,\n",
       " '통해': 27,\n",
       " '된': 28,\n",
       " '인': 29,\n",
       " '위한': 30,\n",
       " '로': 31,\n",
       " '인공지능': 32,\n",
       " '분석': 33,\n",
       " '하기': 34,\n",
       " '다': 35,\n",
       " '학습': 36,\n",
       " '들': 37,\n",
       " '이다': 38,\n",
       " '연구': 39,\n",
       " '에서': 40,\n",
       " '그': 41,\n",
       " '활용': 42,\n",
       " '이러한': 43,\n",
       " '다양한': 44,\n",
       " '이를': 45,\n",
       " '4': 46,\n",
       " '하여': 47,\n",
       " '것으로': 48,\n",
       " '교육': 49,\n",
       " '연구는': 50,\n",
       " '기술': 51,\n",
       " '고': 52,\n",
       " '제안': 53,\n",
       " '될': 54,\n",
       " '차': 55,\n",
       " '적용': 56,\n",
       " '또한': 57,\n",
       " '데이터': 58,\n",
       " '개발': 59,\n",
       " '사용': 60,\n",
       " '결과': 61,\n",
       " '된다': 62,\n",
       " '새로운': 63,\n",
       " '산업혁명': 64,\n",
       " '따라': 65,\n",
       " '예측': 66,\n",
       " '되고': 67,\n",
       " '경우': 68,\n",
       " '관련': 69,\n",
       " '도': 70,\n",
       " '되는': 71,\n",
       " '스마트': 72,\n",
       " '연구에서는': 73,\n",
       " '그리고': 74,\n",
       " '정보': 75,\n",
       " '되었다': 76,\n",
       " '기반': 77,\n",
       " '대해': 78,\n",
       " '인간': 79,\n",
       " '제': 80,\n",
       " '등': 81,\n",
       " '논문에서는': 82,\n",
       " '데이터를': 83,\n",
       " '영향을': 84,\n",
       " '제시': 85,\n",
       " '같은': 86,\n",
       " '최근': 87,\n",
       " '이에': 88,\n",
       " '3': 89,\n",
       " '분류': 90,\n",
       " '따라서': 91,\n",
       " '해': 92,\n",
       " '가장': 93,\n",
       " '이용하여': 94,\n",
       " '서': 95,\n",
       " '수행': 96,\n",
       " '확인': 97,\n",
       " '평가': 98,\n",
       " '인간의': 99,\n",
       " '되어': 100,\n",
       " '보다': 101,\n",
       " '사물인터넷': 102,\n",
       " '중': 103,\n",
       " '가지': 104,\n",
       " '연구의': 105,\n",
       " '특히': 106,\n",
       " '지': 107,\n",
       " '성': 108,\n",
       " '위하여': 109,\n",
       " '서비스': 110,\n",
       " '문제': 111,\n",
       " '기존': 112,\n",
       " '2': 113,\n",
       " '정보를': 114,\n",
       " '있었다': 115,\n",
       " '융합': 116,\n",
       " '인식': 117,\n",
       " '미래': 118,\n",
       " '제공': 119,\n",
       " '있으며': 120,\n",
       " '수업': 121,\n",
       " '나타났다': 122,\n",
       " '결과를': 123,\n",
       " '하고자': 124,\n",
       " '발생': 125,\n",
       " '설계': 126,\n",
       " '모델을': 127,\n",
       " '높은': 128,\n",
       " '것을': 129,\n",
       " '더': 130,\n",
       " '핵심': 131,\n",
       " '그러나': 132,\n",
       " '따른': 133,\n",
       " '비교': 134,\n",
       " '많은': 135,\n",
       " '아니라': 136,\n",
       " '방법을': 137,\n",
       " '대상으로': 138,\n",
       " '사회': 139,\n",
       " '관한': 140,\n",
       " '기존의': 141,\n",
       " '여': 142,\n",
       " '디자인': 143,\n",
       " '증가': 144,\n",
       " '진행': 145,\n",
       " '생성': 146,\n",
       " '해결': 147,\n",
       " '등의': 148,\n",
       " '산업': 149,\n",
       " '해야': 150,\n",
       " '기술의': 151,\n",
       " '각': 152,\n",
       " '인공지능의': 153,\n",
       " '기반으로': 154,\n",
       " '실험': 155,\n",
       " '변화': 156,\n",
       " '현재': 157,\n",
       " '구성': 158,\n",
       " '있을': 159,\n",
       " '하였으며': 160,\n",
       " '성능을': 161,\n",
       " '다른': 162,\n",
       " '에서는': 163,\n",
       " '발전': 164,\n",
       " '빅데이터': 165,\n",
       " '통한': 166,\n",
       " '기반의': 167,\n",
       " '1': 168,\n",
       " '바탕으로': 169,\n",
       " '딥러닝': 170,\n",
       " '활용하여': 171,\n",
       " '실제': 172,\n",
       " '연구가': 173,\n",
       " '미치는': 174,\n",
       " '문제를': 175,\n",
       " '기술을': 176,\n",
       " '등을': 177,\n",
       " '통하여': 178,\n",
       " '때': 179,\n",
       " '활용한': 180,\n",
       " '위해서는': 181,\n",
       " '개선': 182,\n",
       " '분석을': 183,\n",
       " '둘째': 184,\n",
       " '첫째': 185,\n",
       " '논문은': 186,\n",
       " '때문에': 187,\n",
       " '디지털': 188,\n",
       " '중요한': 189,\n",
       " '검토': 190,\n",
       " '수집': 191,\n",
       " '이용한': 192,\n",
       " '공학': 193,\n",
       " '의미': 194,\n",
       " '향후': 195,\n",
       " '필요': 196,\n",
       " '음악': 197,\n",
       " '논의': 198,\n",
       " '중심으로': 199,\n",
       " '도출': 200,\n",
       " '며': 201,\n",
       " '향상': 202,\n",
       " '이용': 203,\n",
       " '사회적': 204,\n",
       " '접근': 205,\n",
       " '후': 206,\n",
       " '시스템을': 207,\n",
       " '개의': 208,\n",
       " '연구를': 209,\n",
       " '간': 210,\n",
       " '했다': 211,\n",
       " '화': 212,\n",
       " '하지만': 213,\n",
       " '에는': 214,\n",
       " '필요하다': 215,\n",
       " '검증': 216,\n",
       " '에게': 217,\n",
       " '구축': 218,\n",
       " '주요': 219,\n",
       " '자': 220,\n",
       " '개': 221,\n",
       " '네트워크': 222,\n",
       " '사용자': 223,\n",
       " '필요한': 224,\n",
       " '있어': 225,\n",
       " '두': 226,\n",
       " '관리': 227,\n",
       " '기계학습': 228,\n",
       " '있도록': 229,\n",
       " '기초': 230,\n",
       " '이는': 231,\n",
       " '국내': 232,\n",
       " '시스템': 233,\n",
       " '하는데': 234,\n",
       " '이나': 235,\n",
       " '여러': 236,\n",
       " '인공지능이': 237,\n",
       " '다음': 238,\n",
       " '기법을': 239,\n",
       " '사물': 240,\n",
       " '것은': 241,\n",
       " '함께': 242,\n",
       " '존재': 243,\n",
       " '함으로써': 244,\n",
       " '교육의': 245,\n",
       " '한국': 246,\n",
       " '교수': 247,\n",
       " '하였고': 248,\n",
       " '과학': 249,\n",
       " '개인': 250,\n",
       " '측정': 251,\n",
       " '방안을': 252,\n",
       " '고려': 253,\n",
       " '나': 254,\n",
       " '판단': 255,\n",
       " '성능': 256,\n",
       " '법적': 257,\n",
       " '매우': 258,\n",
       " '관련된': 259,\n",
       " '알고리즘': 260,\n",
       " '어떻게': 261,\n",
       " '대하여': 262,\n",
       " '로봇': 263,\n",
       " '구현': 264,\n",
       " '하며': 265,\n",
       " '셋째': 266,\n",
       " '큰': 267,\n",
       " '모든': 268,\n",
       " '지식': 269,\n",
       " '있다는': 270,\n",
       " '도입': 271,\n",
       " '이미지': 272,\n",
       " '또는': 273,\n",
       " '인해': 274,\n",
       " '보안': 275,\n",
       " '운영': 276,\n",
       " '처리': 277,\n",
       " '되어야': 278,\n",
       " '개인정보': 279,\n",
       " '변화를': 280,\n",
       " '조사': 281,\n",
       " '지원': 282,\n",
       " '형': 283,\n",
       " '대학': 284,\n",
       " '요구': 285,\n",
       " '기계': 286,\n",
       " '특성을': 287,\n",
       " '데이터의': 288,\n",
       " '사용하여': 289,\n",
       " '탐색': 290,\n",
       " '알고리즘을': 291,\n",
       " '생각': 292,\n",
       " '실시': 293,\n",
       " '지능': 294,\n",
       " '연결': 295,\n",
       " '있어서': 296,\n",
       " '하면서': 297,\n",
       " '방법': 298,\n",
       " '개념': 299,\n",
       " '해당': 300,\n",
       " '센서': 301,\n",
       " '가능한': 302,\n",
       " '5': 303,\n",
       " '적용하여': 304,\n",
       " '특징': 305,\n",
       " '가능성을': 306,\n",
       " '환경': 307,\n",
       " '있음을': 308,\n",
       " '대': 309,\n",
       " '사전': 310,\n",
       " '영상': 311,\n",
       " '선택': 312,\n",
       " '게': 313,\n",
       " '확장': 314,\n",
       " '간의': 315,\n",
       " '국가': 316,\n",
       " '있고': 317,\n",
       " '인공지능에': 318,\n",
       " '없는': 319,\n",
       " '인터넷': 320,\n",
       " '통합': 321,\n",
       " '대응': 322,\n",
       " '과정에서': 323,\n",
       " '이고': 324,\n",
       " '현실': 325,\n",
       " '보였다': 326,\n",
       " '모두': 327,\n",
       " '이해': 328,\n",
       " '하지': 329,\n",
       " '결과는': 330,\n",
       " '역할을': 331,\n",
       " '관점에서': 332,\n",
       " '기술이': 333,\n",
       " '소프트웨어': 334,\n",
       " '모델': 335,\n",
       " '즉': 336,\n",
       " '비해': 337,\n",
       " '감성': 338,\n",
       " '참여': 339,\n",
       " '표현': 340,\n",
       " '시': 341,\n",
       " '포함': 342,\n",
       " '규제': 343,\n",
       " '에서의': 344,\n",
       " '학교': 345,\n",
       " '보호': 346,\n",
       " '인공지능을': 347,\n",
       " '인지': 348,\n",
       " '서비스를': 349,\n",
       " '의한': 350,\n",
       " '프로그램': 351,\n",
       " '내용': 352,\n",
       " '텍스트': 353,\n",
       " '일반': 354,\n",
       " '정의': 355,\n",
       " '등장': 356,\n",
       " '모형을': 357,\n",
       " '문제점': 358,\n",
       " '생산': 359,\n",
       " '경험': 360,\n",
       " '제안하는': 361,\n",
       " '체계': 362,\n",
       " '만': 363,\n",
       " '분야에서': 364,\n",
       " '데': 365,\n",
       " '부터': 366,\n",
       " '라는': 367,\n",
       " '자료를': 368,\n",
       " '전공': 369,\n",
       " '기능': 370,\n",
       " '이와': 371,\n",
       " '추출': 372,\n",
       " '과정을': 373,\n",
       " '심층': 374,\n",
       " '전체': 375,\n",
       " '연구에서': 376,\n",
       " '시스템의': 377,\n",
       " '까지': 378,\n",
       " '의해': 379,\n",
       " '정책': 380,\n",
       " '목적은': 381,\n",
       " '활동': 382,\n",
       " '컴퓨터': 383,\n",
       " '확보': 384,\n",
       " '결정': 385,\n",
       " '설명': 386,\n",
       " '크게': 387,\n",
       " '볼': 388,\n",
       " '모델의': 389,\n",
       " '상호작용': 390,\n",
       " '이며': 391,\n",
       " '때문': 392,\n",
       " '어떤': 393,\n",
       " '환경에서': 394,\n",
       " '자기': 395,\n",
       " '가지고': 396,\n",
       " '세': 397,\n",
       " '역량': 398,\n",
       " '전': 399,\n",
       " '중심': 400,\n",
       " '더욱': 401,\n",
       " '뿐': 402,\n",
       " '사용자의': 403,\n",
       " '상황': 404,\n",
       " '한계': 405,\n",
       " '창의적': 406,\n",
       " '제품': 407,\n",
       " '우리': 408,\n",
       " '먼저': 409,\n",
       " '분야': 410,\n",
       " '의료': 411,\n",
       " '학년': 412,\n",
       " '온라인': 413,\n",
       " '확대': 414,\n",
       " '세계': 415,\n",
       " '측면에서': 416,\n",
       " '예술': 417,\n",
       " '교육을': 418,\n",
       " '이라는': 419,\n",
       " '전문가': 420,\n",
       " '인간과': 421,\n",
       " '특성': 422,\n",
       " '콘텐츠': 423,\n",
       " '시대에': 424,\n",
       " '행동': 425,\n",
       " '효과를': 426,\n",
       " '정확도를': 427,\n",
       " '관계': 428,\n",
       " '사고': 429,\n",
       " '머신러닝': 430,\n",
       " '점에서': 431,\n",
       " '분야의': 432,\n",
       " '디바이스': 433,\n",
       " '한다는': 434,\n",
       " '시도': 435,\n",
       " '모바일': 436,\n",
       " '교과': 437,\n",
       " '총': 438,\n",
       " '내용을': 439,\n",
       " '제작': 440,\n",
       " '탐지': 441,\n",
       " '분석하여': 442,\n",
       " '야': 443,\n",
       " '문화': 444,\n",
       " '공간': 445,\n",
       " '관계를': 446,\n",
       " '평균': 447,\n",
       " '마련': 448,\n",
       " '자료': 449,\n",
       " '인공지능과': 450,\n",
       " '같다': 451,\n",
       " '입력': 452,\n",
       " '구': 453,\n",
       " '문제가': 454,\n",
       " '자동': 455,\n",
       " '학생들의': 456,\n",
       " '직접': 457,\n",
       " '토대로': 458,\n",
       " '영향': 459,\n",
       " '학생': 460,\n",
       " '등이': 461,\n",
       " '제공하는': 462,\n",
       " '기술적': 463,\n",
       " '시대의': 464,\n",
       " '않은': 465,\n",
       " '차이가': 466,\n",
       " '제안한': 467,\n",
       " '파악': 468,\n",
       " '이상': 469,\n",
       " '이후': 470,\n",
       " '우리나라': 471,\n",
       " '하게': 472,\n",
       " '시작': 473,\n",
       " '제안된': 474,\n",
       " '현': 475,\n",
       " '유의': 476,\n",
       " '학습을': 477,\n",
       " '방향을': 478,\n",
       " '감정': 479,\n",
       " '형성': 480,\n",
       " '신경망': 481,\n",
       " '별': 482,\n",
       " '많이': 483,\n",
       " '같이': 484,\n",
       " '사이버': 485,\n",
       " '위치': 486,\n",
       " '동시에': 487,\n",
       " '인한': 488,\n",
       " '되지': 489,\n",
       " '화된': 490,\n",
       " '기업': 491,\n",
       " '프로그램을': 492,\n",
       " '측면': 493,\n",
       " '에도': 494,\n",
       " '혁신': 495,\n",
       " '방법은': 496,\n",
       " '유형': 497,\n",
       " '적합한': 498,\n",
       " '실험을': 499,\n",
       " '변화에': 500,\n",
       " '교사': 501,\n",
       " '시스템은': 502,\n",
       " '법률': 503,\n",
       " '플랫폼': 504,\n",
       " '연계': 505,\n",
       " '영역': 506,\n",
       " '기대': 507,\n",
       " '사례를': 508,\n",
       " '마지막으로': 509,\n",
       " '의사결정': 510,\n",
       " '이루어지': 511,\n",
       " '어떠한': 512,\n",
       " '상호': 513,\n",
       " '상': 514,\n",
       " '선정': 515,\n",
       " '설정': 516,\n",
       " '제어': 517,\n",
       " '면': 518,\n",
       " '개별': 519,\n",
       " '가치': 520,\n",
       " '등에': 521,\n",
       " '고찰': 522,\n",
       " '알': 523,\n",
       " '통신': 524,\n",
       " '단어': 525,\n",
       " '기능을': 526,\n",
       " '관련하여': 527,\n",
       " '컴퓨팅': 528,\n",
       " '스마트폰': 529,\n",
       " '언어': 530,\n",
       " '전문': 531,\n",
       " '특정': 532,\n",
       " '시킬': 533,\n",
       " '계산': 534,\n",
       " '인공지능은': 535,\n",
       " '결합': 536,\n",
       " '우선': 537,\n",
       " '교수학습': 538,\n",
       " '과제': 539,\n",
       " '수학': 540,\n",
       " '었다': 541,\n",
       " '학습자': 542,\n",
       " '더불어': 543,\n",
       " '로봇의': 544,\n",
       " '발달': 545,\n",
       " '능력': 546,\n",
       " '점을': 547,\n",
       " '있지만': 548,\n",
       " '내': 549,\n",
       " '감소': 550,\n",
       " '모형': 551,\n",
       " '시간': 552,\n",
       " '인공': 553,\n",
       " '창의성': 554,\n",
       " '문장': 555,\n",
       " '모색': 556,\n",
       " '중국': 557,\n",
       " '방식을': 558,\n",
       " '책임': 559,\n",
       " '라고': 560,\n",
       " '금융': 561,\n",
       " '않고': 562,\n",
       " '분야에': 563,\n",
       " '글쓰기': 564,\n",
       " '보인다': 565,\n",
       " '발생하는': 566,\n",
       " '효과적인': 567,\n",
       " '전자': 568,\n",
       " '구조': 569,\n",
       " '특징을': 570,\n",
       " '없이': 571,\n",
       " '차원': 572,\n",
       " '나아가': 573,\n",
       " '지능형': 574,\n",
       " '협력': 575,\n",
       " '가치를': 576,\n",
       " '응용': 577,\n",
       " '효과적으로': 578,\n",
       " '공유': 579,\n",
       " '부분': 580,\n",
       " '검색': 581,\n",
       " '확인할': 582,\n",
       " '아닌': 583,\n",
       " '기술은': 584,\n",
       " '없다': 585,\n",
       " '소비자': 586,\n",
       " '에서도': 587,\n",
       " '권리': 588,\n",
       " '시대': 589,\n",
       " '주로': 590,\n",
       " '교육과정': 591,\n",
       " '자동차': 592,\n",
       " '클라우드': 593,\n",
       " '기본': 594,\n",
       " '위험': 595,\n",
       " '검출': 596,\n",
       " '사례': 597,\n",
       " '단계': 598,\n",
       " '약': 599,\n",
       " '살펴보았다': 600,\n",
       " '러닝': 601,\n",
       " '하도록': 602,\n",
       " '능력을': 603,\n",
       " '하거나': 604,\n",
       " '잘': 605,\n",
       " '목적으로': 606,\n",
       " '성과': 607,\n",
       " '우리는': 608,\n",
       " '가상': 609,\n",
       " '중심의': 610,\n",
       " '윤리적': 611,\n",
       " '확산': 612,\n",
       " '정보의': 613,\n",
       " '윤리': 614,\n",
       " '과의': 615,\n",
       " '함에': 616,\n",
       " '있게': 617,\n",
       " '기술과': 618,\n",
       " '목적을': 619,\n",
       " '탐구': 620,\n",
       " '학생들이': 621,\n",
       " '진행되고': 622,\n",
       " '효과': 623,\n",
       " '혹은': 624,\n",
       " '미국': 625,\n",
       " '모델은': 626,\n",
       " '인간이': 627,\n",
       " '않는': 628,\n",
       " '고려하여': 629,\n",
       " '력': 630,\n",
       " '강조': 631,\n",
       " '과학기술': 632,\n",
       " '수용': 633,\n",
       " '시사점을': 634,\n",
       " '산업의': 635,\n",
       " '방법으로': 636,\n",
       " '목적': 637,\n",
       " '영화': 638,\n",
       " '인정': 639,\n",
       " '개인의': 640,\n",
       " '역할': 641,\n",
       " '객체': 642,\n",
       " '반영': 643,\n",
       " '추정': 644,\n",
       " '블록체인': 645,\n",
       " '스스로': 646,\n",
       " '6': 647,\n",
       " '현대': 648,\n",
       " '통해서': 649,\n",
       " '차량': 650,\n",
       " '창작': 651,\n",
       " '좋은': 652,\n",
       " '주장': 653,\n",
       " '활성화': 654,\n",
       " '중에서': 655,\n",
       " '기법': 656,\n",
       " '사용하는': 657,\n",
       " '연구결과': 658,\n",
       " '서로': 659,\n",
       " '요소를': 660,\n",
       " '실시간': 661,\n",
       " '진단': 662,\n",
       " '하면': 663,\n",
       " '강화': 664,\n",
       " '실행': 665,\n",
       " '문제해결': 666,\n",
       " '양성': 667,\n",
       " '과정': 668,\n",
       " '분석한': 669,\n",
       " '이런': 670,\n",
       " '방법이': 671,\n",
       " '모니터링': 672,\n",
       " '요소': 673,\n",
       " '사': 674,\n",
       " '속에서': 675,\n",
       " '상태': 676,\n",
       " '주목': 677,\n",
       " '향상을': 678,\n",
       " '역량을': 679,\n",
       " '이들': 680,\n",
       " '있다고': 681,\n",
       " '이론적': 682,\n",
       " '식': 683,\n",
       " '집중': 684,\n",
       " '이미': 685,\n",
       " '아직': 686,\n",
       " '추가': 687,\n",
       " '안전': 688,\n",
       " '개념을': 689,\n",
       " '한국어': 690,\n",
       " '평가를': 691,\n",
       " '줄': 692,\n",
       " '한편': 693,\n",
       " '유의미한': 694,\n",
       " '기업의': 695,\n",
       " '대상': 696,\n",
       " '가능성이': 697,\n",
       " '개발된': 698,\n",
       " '학습자의': 699,\n",
       " '하나의': 700,\n",
       " '있기': 701,\n",
       " '종합': 702,\n",
       " '웹': 703,\n",
       " '활용하는': 704,\n",
       " '접목': 705,\n",
       " '경제': 706,\n",
       " '시각': 707,\n",
       " '첨단': 708,\n",
       " '빅': 709,\n",
       " '현장': 710,\n",
       " '보조공학': 711,\n",
       " '가진': 712,\n",
       " '초기': 713,\n",
       " '되기': 714,\n",
       " '드론': 715,\n",
       " '모형의': 716,\n",
       " '교육에': 717,\n",
       " '개정': 718,\n",
       " '프로젝트': 719,\n",
       " '추천': 720,\n",
       " '창의': 721,\n",
       " '시장': 722,\n",
       " '각각': 723,\n",
       " '지역': 724,\n",
       " '것인지': 725,\n",
       " '자신의': 726,\n",
       " '변화가': 727,\n",
       " '주제': 728,\n",
       " '진로': 729,\n",
       " '구분': 730,\n",
       " '법': 731,\n",
       " '데이터에': 732,\n",
       " '기대한다': 733,\n",
       " '체험': 734,\n",
       " '우수한': 735,\n",
       " '배경': 736,\n",
       " '창출': 737,\n",
       " '어려운': 738,\n",
       " '방식으로': 739,\n",
       " '효율적인': 740,\n",
       " '실현': 741,\n",
       " '논문에서': 742,\n",
       " '되었으며': 743,\n",
       " '장애': 744,\n",
       " '대학의': 745,\n",
       " '낮은': 746,\n",
       " '불구하고': 747,\n",
       " '갖는': 748,\n",
       " '살펴보고': 749,\n",
       " '에너지': 750,\n",
       " '적절한': 751,\n",
       " '대비': 752,\n",
       " '한계를': 753,\n",
       " '데이터가': 754,\n",
       " '의미를': 755,\n",
       " '물론': 756,\n",
       " '통계적': 757,\n",
       " '보완': 758,\n",
       " '높게': 759,\n",
       " '예상': 760,\n",
       " '유사한': 761,\n",
       " '관점': 762,\n",
       " '국제': 763,\n",
       " '수정': 764,\n",
       " '교육이': 765,\n",
       " '자동화': 766,\n",
       " '달성': 767,\n",
       " '집단': 768,\n",
       " '도덕': 769,\n",
       " '왔다': 770,\n",
       " '기술에': 771,\n",
       " '전송': 772,\n",
       " '공공': 773,\n",
       " '앞으로': 774,\n",
       " '쟁점': 775,\n",
       " '수업을': 776,\n",
       " '해석': 777,\n",
       " '사회의': 778,\n",
       " '상황에서': 779,\n",
       " '수집된': 780,\n",
       " '아니': 781,\n",
       " '시뮬레이션': 782,\n",
       " '효율적으로': 783,\n",
       " '사람': 784,\n",
       " '대체': 785,\n",
       " '미디어': 786,\n",
       " '발견': 787,\n",
       " '명의': 788,\n",
       " '교육적': 789,\n",
       " '형태의': 790,\n",
       " '전통적인': 791,\n",
       " '부여': 792,\n",
       " '다중': 793,\n",
       " '서비스의': 794,\n",
       " '환경을': 795,\n",
       " '영역에서': 796,\n",
       " '추론': 797,\n",
       " '달리': 798,\n",
       " '필요성': 799,\n",
       " '형태로': 800,\n",
       " '하여야': 801,\n",
       " '최적화': 802,\n",
       " '되면서': 803,\n",
       " '차이를': 804,\n",
       " '유지': 805,\n",
       " '뿐만': 806,\n",
       " '패턴': 807,\n",
       " '관심이': 808,\n",
       " '설치': 809,\n",
       " '역시': 810,\n",
       " '구체적으로': 811,\n",
       " '방법에': 812,\n",
       " '피드백': 813,\n",
       " '지만': 814,\n",
       " '지식을': 815,\n",
       " '최종': 816,\n",
       " '그에': 817,\n",
       " '소통': 818,\n",
       " '포스트휴먼': 819,\n",
       " '기기': 820,\n",
       " '전망': 821,\n",
       " '신체': 822,\n",
       " '요인': 823,\n",
       " '노력': 824,\n",
       " '사이의': 825,\n",
       " '영역을': 826,\n",
       " '수준': 827,\n",
       " '등으로': 828,\n",
       " '10': 829,\n",
       " '이상의': 830,\n",
       " '도움이': 831,\n",
       " '으로는': 832,\n",
       " '생활': 833,\n",
       " '구체적인': 834,\n",
       " '상황을': 835,\n",
       " '발전에': 836,\n",
       " '넷째': 837,\n",
       " '있으나': 838,\n",
       " '소개': 839,\n",
       " '개발을': 840,\n",
       " '작성': 841,\n",
       " '긍정적인': 842,\n",
       " '침해': 843,\n",
       " '본질': 844,\n",
       " '전략을': 845,\n",
       " '무선': 846,\n",
       " '수준의': 847,\n",
       " '하나인': 848,\n",
       " '명을': 849,\n",
       " '식별': 850,\n",
       " '속': 851,\n",
       " '문제에': 852,\n",
       " '검사': 853,\n",
       " '논의가': 854,\n",
       " '만을': 855,\n",
       " '새롭게': 856,\n",
       " '계': 857,\n",
       " '게임': 858,\n",
       " '인하여': 859,\n",
       " '문서': 860,\n",
       " '현행': 861,\n",
       " '방식': 862,\n",
       " '우리의': 863,\n",
       " '연구에': 864,\n",
       " '것에': 865,\n",
       " '실천': 866,\n",
       " '빠르게': 867,\n",
       " '이용해': 868,\n",
       " '챗봇': 869,\n",
       " '속성': 870,\n",
       " '국내외': 871,\n",
       " '전략': 872,\n",
       " '활용되고': 873,\n",
       " '인식을': 874,\n",
       " '의의': 875,\n",
       " '대표적인': 876,\n",
       " '번째': 877,\n",
       " '추진': 878,\n",
       " '경제적': 879,\n",
       " '사용자가': 880,\n",
       " '점이': 881,\n",
       " '응답': 882,\n",
       " '시켜': 883,\n",
       " '지속적으로': 884,\n",
       " '대해서는': 885,\n",
       " '하나': 886,\n",
       " '군집': 887,\n",
       " '현재의': 888,\n",
       " '도시': 889,\n",
       " '관심을': 890,\n",
       " '근거': 891,\n",
       " '보았다': 892,\n",
       " '직업': 893,\n",
       " '선행': 894,\n",
       " '논의를': 895,\n",
       " '기': 896,\n",
       " '변수': 897,\n",
       " '특허': 898,\n",
       " '되며': 899,\n",
       " '의사소통': 900,\n",
       " '않다': 901,\n",
       " '제한': 902,\n",
       " '파악하고': 903,\n",
       " '데이터는': 904,\n",
       " '알고리즘의': 905,\n",
       " '작동': 906,\n",
       " '도로': 907,\n",
       " '방법의': 908,\n",
       " '실정': 909,\n",
       " '표준': 910,\n",
       " '구조를': 911,\n",
       " '긍정적': 912,\n",
       " '과거': 913,\n",
       " '주는': 914,\n",
       " '대부분': 915,\n",
       " '함을': 916,\n",
       " '진화': 917,\n",
       " '문제는': 918,\n",
       " '하려는': 919,\n",
       " '도덕적': 920,\n",
       " '반면': 921,\n",
       " '중요하다': 922,\n",
       " '경험을': 923,\n",
       " '상대적으로': 924,\n",
       " '딥': 925,\n",
       " '작업': 926,\n",
       " '전력': 927,\n",
       " '저장': 928,\n",
       " '동작': 929,\n",
       " '인공신경망': 930,\n",
       " '필요성이': 931,\n",
       " '테스트': 932,\n",
       " '생명': 933,\n",
       " '도출하': 934,\n",
       " '환경에': 935,\n",
       " '목적이': 936,\n",
       " '시키기': 937,\n",
       " '성능이': 938,\n",
       " '지적': 939,\n",
       " '활발히': 940,\n",
       " '오늘날': 941,\n",
       " '마음': 942,\n",
       " '자연': 943,\n",
       " '테크놀로지': 944,\n",
       " '규정': 945,\n",
       " '오류': 946,\n",
       " '정확한': 947,\n",
       " '것': 948,\n",
       " '훈련': 949,\n",
       " '목표': 950,\n",
       " '증대': 951,\n",
       " '이미지를': 952,\n",
       " '값을': 953,\n",
       " '어느': 954,\n",
       " '보장': 955,\n",
       " '논문': 956,\n",
       " '일부': 957,\n",
       " '으로서': 958,\n",
       " '실시간으로': 959,\n",
       " '프라이버시': 960,\n",
       " '받고': 961,\n",
       " '학습에': 962,\n",
       " '보다는': 963,\n",
       " '시대를': 964,\n",
       " '포함한': 965,\n",
       " '인성': 966,\n",
       " '교육공학': 967,\n",
       " '공할': 968,\n",
       " '20': 969,\n",
       " '기반한': 970,\n",
       " '웨어러블': 971,\n",
       " '시키는': 972,\n",
       " '서버': 973,\n",
       " '준비': 974,\n",
       " '기준': 975,\n",
       " '되었고': 976,\n",
       " '촉진': 977,\n",
       " '시키고': 978,\n",
       " '인간을': 979,\n",
       " '번역': 980,\n",
       " '프로그래밍': 981,\n",
       " '분석하는': 982,\n",
       " '문헌': 983,\n",
       " '수도': 984,\n",
       " '영역에': 985,\n",
       " '자율': 986,\n",
       " '점': 987,\n",
       " '제조': 988,\n",
       " '고려한': 989,\n",
       " '현장에서': 990,\n",
       " '파악하': 991,\n",
       " '입법': 992,\n",
       " '증강현실': 993,\n",
       " '야기': 994,\n",
       " '도움을': 995,\n",
       " '계획': 996,\n",
       " '책임을': 997,\n",
       " '갖고': 998,\n",
       " '투자': 999,\n",
       " '비교하여': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41225 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x21468b5a788>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2805 samples, validate on 935 samples\n",
      "Epoch 1/30\n",
      "2805/2805 [==============================] - 77s 28ms/step - loss: 2.3276 - val_loss: 2.9273\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_ls32_v1_01_2.92732.h5\n",
      "Epoch 2/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.3989 - val_loss: 1.8263\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_ls32_v1_02_1.82627.h5\n",
      "Epoch 3/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.3060 - val_loss: 1.1916\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_ls32_v1_03_1.19163.h5\n",
      "Epoch 4/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.1990 - val_loss: 1.1587\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_ls32_v1_04_1.15872.h5\n",
      "Epoch 5/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.1891 - val_loss: 1.0756\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_ls32_v1_05_1.07558.h5\n",
      "Epoch 6/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.1143 - val_loss: 1.0184\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_ls32_v1_06_1.01837.h5\n",
      "Epoch 7/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.0699 - val_loss: 1.0992\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_ls32_v1_07_1.09919.h5\n",
      "Epoch 8/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.0306 - val_loss: 1.0445\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_ls32_v1_08_1.04451.h5\n",
      "Epoch 9/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.9907 - val_loss: 1.0514\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_ls32_v1_09_1.05144.h5\n",
      "Epoch 10/30\n",
      "2805/2805 [==============================] - 74s 26ms/step - loss: 0.9514 - val_loss: 1.0838\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_ls32_v1_10_1.08380.h5\n",
      "Epoch 11/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.9070 - val_loss: 1.0565\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_ls32_v1_11_1.05650.h5\n",
      "time : 837.8243403434753\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(32)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_ls32_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4364000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1632      \n",
      "=================================================================\n",
      "Total params: 4,712,982\n",
      "Trainable params: 589,982\n",
      "Non-trainable params: 4,123,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_ls32_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_ls32_v1_08_1.04451.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.042655952091523"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4219866, 1.4928361, 2.67492  , ..., 0.913846 , 0.8220351,\n",
       "        0.9945699],\n",
       "       [1.4678259, 2.3699043, 2.803337 , ..., 1.4608501, 1.206083 ,\n",
       "        1.8882314],\n",
       "       [2.5014372, 1.5580808, 2.024472 , ..., 1.1391386, 1.6533055,\n",
       "        1.3828422],\n",
       "       ...,\n",
       "       [2.5406265, 1.83417  , 2.6210442, ..., 1.0170183, 1.2420739,\n",
       "        1.3353789],\n",
       "       [2.6651025, 2.3902776, 3.4232507, ..., 1.0669693, 1.1153036,\n",
       "        1.73676  ],\n",
       "       [2.2813208, 1.2612321, 2.2484827, ..., 1.013569 , 0.9204153,\n",
       "        1.2639118]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_ls32_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.86050543e-08, 1.17561560e-09, 7.72402942e-01, ...,\n",
       "        1.15497283e-16, 2.33285249e-11, 2.08149449e-05],\n",
       "       [2.98994287e-20, 1.63802652e-11, 2.44910628e-19, ...,\n",
       "        6.42974748e-15, 4.65143842e-18, 8.51713438e-08],\n",
       "       [3.49241252e-12, 1.52605831e-10, 3.19754744e-11, ...,\n",
       "        1.30859042e-13, 1.05811905e-13, 1.07531379e-08],\n",
       "       ...,\n",
       "       [5.23715793e-11, 1.39197737e-10, 1.16763578e-03, ...,\n",
       "        1.99129389e-17, 1.12485531e-12, 7.48830473e-07],\n",
       "       [1.99910567e-14, 2.01585859e-09, 2.08499240e-09, ...,\n",
       "        5.80876719e-16, 1.68925950e-11, 2.47416949e-07],\n",
       "       [1.11591125e-10, 2.96521496e-09, 1.08539825e-06, ...,\n",
       "        3.54587291e-13, 8.19252374e-11, 8.27300937e-07]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAFpCAYAAABee9lOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi80lEQVR4nO3df4zc9X3n8dfby7hZu1wX1zYKCz44n0uOnIGkmxiO9o4QOfy6BGIRCJhGjVpQ7pLqEpAPE1YF1FDTs3BolaTIRCiq4vIjxDcxVzeWTyc3lWO7mBvbG5M6MZDaHlfFBJzk8Casd9/3x+yYYT3z/X53dr6/nw9pJM98v559D7v75uP35/N5f8zdBQDIpllpBwAA6IwkDQAZRpIGgAwjSQNAhpGkASDDSNIAkGEkaQDoATN7wsxeNbMfdLhuZvYXZnbQzPaZ2fujvC9JGgB64xuSrgm4fq2kJZOPOyX9ZZQ3JUkDQA+4+/ckvR5wyw2S/sobdkoaMLN3h70vSRoAkjEo6XDL8yOTrwU6I7ZwQsyfP9/PP//8tL48gBx54YUXXnP3BTN5j6s/NNd/+vp49zHs+9V+Sb9seWm9u6+fxltYm9dC+3KklqTPP/987d69O60vDyBHzOyfZvoer70+rl1bzu3671fe/dIv3X1oBiEckXRey/NzJR0N+0uUOwAgGZskfWpylcdlkn7m7v8c9pdSG0kDQLJc4z4R27ub2ZOSrpQ038yOSLpfUkWS3P0xSZslXSfpoKQTkj4d5X1J0gBKwSVNhJeAu39/91tDrrukz073fUnSAEpjQvGNpONCTRoAMoyRNIBScLnGc3gSFUkaQGnEWZOOC0kaQCm4pHGSNABkVyFH0mb2hKT/LOlVd//3ba6bpD9XY/3fCUm/7+7/t9eBAsi/81f/zWmv/eTh61OIJD+irO74hmJovwegXNol6KDXe80ljbt3/UhLaJKOq/0egPJIKhGHmZjBIy29qEl3ar932p50M7tTjdG2Fi1a1IMvDSDrlq/blnYIkiaX4OWwJt2LzSyR2++5+3p3H3L3oQULZtR1EEBO/PjVN9MOocGl8Rk80tKLJN1V+z0AxZeVMkee9SJJd9V+D0CxXXz/d9MO4R0aDZYKWJOOq/0egOJa9tBW/fxX0U5BSW4Jnmm8bXU220KTdFzt9wAU03vu26xfRiziJrlG2iVN5G/ekC54AHpn+bptmUzQeca2cAA9E3Ulx6O3XBpvIB0UstwBAFG8577Nke67/bJFuvF9gzFHc7pGgyWSNIASWvbQ1khljiUL5+pLNy5NIKL2JpwkDaBklq/bpn/5xVuh972rz7T1rivjD6iDvI6kmTgE0LXh6kikOrRJ+seHros/oAJiJA2gaxt2Hgq9xyS9koGVHC7TeA7HpSRpAF1Zvm5bpHZFWUjQTdSkAZTCysd3RCpzXLF4XgLRRJPXmjRJGsC0bX8pqMV8w7v6TBvuuDyBaKIyjXv+yh35ixhAqpY9tDX0nrPPnM1EYY8wkgYQ2bKHtoYut7v9skWproXupNEFL3/jUpI0gEiGqyOhCbrPlMkE3URNGkAhrXx8R6Q69CM3Xxp/MF1yz2dNmiQNIFCUEoeUXk+OoiNJA+ho5eM7IiXos8+cnekyR9ME5Q4ARTFcHYlU4jj7zNnadd/yBCKamcY6acodAApguDqib0bY8p3VlRztUZMGUBBRenLM7rMcJej8LsHLX8QAYhelJ8f/uOmS2OMAI2kAU1Rr9dB78rqSY5wGSwDybLg6ElrqyFcd+m20KgWQa1EmC69YPC+XCbppgolDAHkUJUHndQTdxBI8ALm0fN220N7QgwP9uU7QeUaSBkosypZvk7Tq6guTCShGLmPiEEB+ROlqJ0krc7qSo508rpMmSQMl9de7irajMJi7crnjMH8RA5ix5eu2aSJkx0qREnSeMZIGSibKIbJLFs4tYII2uuAByL6wznZnnzlbW++6MplgEuTKZ7mDJA3glP7KrFy0He0W66QBZFa1VtfaLQcC71mz4uKEokmeyzTBEjwAWVSt1XXvxhGNjo13vGfJwrmFWWpXJCRpoOCi9uTYcMflCUWUHsodADIlLEGbpFcevj65gFLkosESgAyp1uqhI+hzBvoTiiYLTOMswQOQBdVaXXc9syfwnv5KXyF6ckSV15F0/iIGEOrejftCdxSuWbGUicIcYCQNFMxwdUSjYxOB9+T1+KuZotwBIFXVWj30+Kv+yqwCbvkO526UOwCkZ7g6os8/vSf0pO8ib1gJM+6zun5EYWbXmNkBMztoZqvbXP8NM3vOzPaa2X4z+3TYe5KkgQKIshZaKm+ZIwlm1ifpq5KulXSRpFvN7KIpt31W0ovufomkKyU9Ymazg96XcgeQc1GW2km0HnUp7i54H5R00N1fliQze0rSDZJenBLGmWZmkn5d0uuSTga9KUkayLFqra4vPL0n8B5T43SVMifoBou7C96gpMMtz49IWjblnq9I2iTpqKQzJd3i7oGzvCRpIMfufia8Bv3lWy6lxKHmOukZjaTnm9nulufr3X19y/N2bz7123O1pD2SrpK0WNJWM/t7d/95py9KkgZyqlqrazzC6Sok6LfNsHfHa+4+FHD9iKTzWp6fq8aIudWnJT3s7i7poJm9Iuk9kv6h05sycQjkVFjb0bLXoFPwvKQlZnbB5GTgJ9UobbQ6JOnDkmRmZ0u6UNLLQW/KSBrImWqtrgef2683TowF3keCfqe4+0m7+0kz+5ykLZL6JD3h7vvN7DOT1x+T9CeSvmFmI2qUR+5x99eC3pckDeRItVbXqmf3aiykznHF4nkJRZQvEzEXD9x9s6TNU157rOXPRyV9ZDrvGSniOBZoA5i+tVsOhCboJQvnlqI39HS5S+NuXT/SEjqSblmgvVyNwvjzZrbJ3VvX/jUXaH/UzBZIOmBmG9z9rViiBkrq6PHRwOuPspIjUFGPz4plgTaA6IarI3py1+HA5XaDA/0k6AKKkqRjWaANIJooW74rs6xUvaG70Zg4zN+CtigRT2eB9jmSLpX0FTP7V6e9kdmdZrbbzHYfO3ZsmqEC5fTXu4IT9EB/RWs/cQmj6AjGJ09n6eaRligj6Z4t0J7cnbNekoaGhsI2SgGQApv3/6Qk5xP2Qg92HKYiykg6lgXaAIBwoSPpuBZoA4imvzKr7Ukr/ZX81VfTlc+adKTNLHEs0AYQzZoVF+uup/eoNU3PUrmb93cr5lalsWDHIZAh1Vpda7cc0NHjozpnoF+rrr7w1IRgp9cRTXMzS96QpIGMqNbqunfjiEbHxiVJ9eOjunfjiCTpxvcNkpR7II/ljvxFDBRQtVbXF57ZcypBN42OjYd2u0OxMZIGUlat1XX3t/bKOyy1C9sKjmji7oIXF5I0kLIHn9uv8YDF0OcM9CcYTbExcQhgWqq1emhfaLZ790aRN7MAiEFzojDIWXMqTBiWHCNpICUPPrf/tInCqe7/6HsTiqYc8ri6gyQNpGD5um2hZQ4Oke0xZ+IQQATL123Tj199s+P1PjM9cjNd7XrNxcQhgBDVWj0wQUsiQccojyPp/BVogBwL25gy0M9EId6JkTSQgGZPjnrIxpQHPsZEYVzyugSPJA3EbGpPjk6WLJzLKDpmJGkAp1m75UCkBL31riuTCaik2BYOoK2g3huDtB1NFKs7AJzmnIH+trXowYF+bV99VQoRIU9Y3QHEbNXVF6q/0veO1/orffTkSJo3atLdPtLCSBrosXanq6xZsZSTVVLG6g4AHU9XWbNiKaWNDMhjkqbcAfTQFzfu43QV9BQjaaBHhqsjOjE20fYap6ukjyV4QMk9uetwx2ucrpINTpIGyqdaq+uBTfs13umQQnG6SlawThoomeHqiL6581DgPWZiJUcGuDNxCJRKtVYPTdCStHLZogSiQVExkga6dNfTe0Lvuf2yRfrSjUvjDwaRUJMGSmK4OqL26zjeNjjQT4LOFFZ3AKUQpcxR6TMmCzOIkTRQcNVaXaue3Rt639qbOAIra/K6LZyJQ2AaHnxuv8bGOy+1kzjlG73FSBqIqFqr640TY4H3LFk4lzp0VnljGV7ekKSBCJqNk4KwkiP72MwCFNDKx3do+0uvB94z0F8hQWeci4lDoHCWr9umH7/6ZuA9lVnGKd+IDUka6KBaq4cm6D4zrf0EKznygXXSQKGE9YDur/RpzYqlJOgcYeIQKJCwHtAk6PzJY02addJAB0E9oK9YPI8EnTPujSTd7SMtJGmgg3anfEuNtdAb7rg8hYhQRpQ7gA6aI2VO+S4OJg6BHKvW6m0TMkm5OJg4BHJquDqiDTsPqfk7XD8+emqHIUm6OJg4BHJo5eM79M2WBN00OjYeugwP+eHqftIwzeTOSBqlFrajMGwZHhA3kjRKa7g6ErqjMGgZHvInhyVpkjTKKcrpKiZxukqReD5r0iRplE6UtqOStJLm/cWTw6E0E4conbVbDmh0bDzwnisWz6P1KKbNzK4xswNmdtDMVne450oz22Nm+83s78Lek5E0SidsMpAdhcUVZ7nDzPokfVXScklHJD1vZpvc/cWWewYkfU3SNe5+yMwWhr0vSRql0dysEvQvXk5XKbaYN7N8UNJBd39ZkszsKUk3SHqx5Z7bJG1090ONePzVsDeNVO6IYwgPJKlZh653GEX3V/r06C2XkqALrHkyywzWSc83s90tjzunfIlBSYdbnh+ZfK3Vb0k6y8y2mdkLZvapsLhDR9JxDeGBJAXVoQfpyVEOLmlm5Y7X3H0o4Hq7N586dj9D0m9L+rCkfkk7zGynu/+o05tGKXfEMoQHktSpDm2Stq++KtlgUFRHJJ3X8vxcSUfb3POau78p6U0z+56kSyR1TNJRyh09G8Kb2Z3NfyocO3YswpcGeqPTphQ2q5RLo6d0d48Inpe0xMwuMLPZkj4padOUe74j6XfN7AwzmyNpmaQfBr1plJF0z4bw7r5e0npJGhoayuGKReRJa1e7gTkVVWaZxibe/rHrr/SxWaVsYsw67n7SzD4naYukPklPuPt+M/vM5PXH3P2HZvZdSfskTUj6urv/IOh9oyTpWIbwQJyaE4XNOvQbJ8ZU6TMN9Ff0s9ExekOXUvyNktx9s6TNU157bMrztZLWRn3PKEn61BBeUl2NIfxtU+75jqSvmNkZkmarMYT/ctQggF5rN1E4Nu6a+2tnaM/9H0kpKqQuh/9+D03ScQ3hgbhUa/WOS+3oaoe8ibSZJY4hPBCHlY/v0PaXXu94nYnCEqPBEpCu4epIYIJmohCFLHcAefHkrsOB19esWMpEYenlbyRNFzwUxnjAYtbBgX4SNHKJkTRyb7g6EjqKpswBSZQ7gKQNV0dCT1i5YvE8RtFoIEkDyQoaQfeZ6dZl59HZDg0zb7CUCpI0ci2oDv3SmusSjAR5EHM/6VgwcYhc67P2I6NOrwN5w0gaudLoybFPo2MTgffduuy8wOsoqRyOpEnSyI1qra67nt6jdunZ1Pj9ow6NQNSkgfis3XKgbYKWpFlm1KARyhhJA/FY+fiOjk2TpOAJREDS5OqOtIOYPiYOkXlhTZMkJgpRXIykkXlhCVpiohBRGDVpoNeGqyOB12eZdNuyRUwUIpocljtI0sisaq2uDSFbvl9ec31C0aAQcpikqUkjk6q1uu5+Zm/g79QVi+clFg+QFkbSyJzh6og27DwUmKArs6QNd1yeWEwoiByOpEnSyJRqrR7a1c4krf3EpYnEgwKhwRIwcw9s2h943SStvGwRrUfRFTazADN0fHSs47U+Mz1y8yUkaHSPJA10p1qra+2WA4H3kKBRRiRppC7KROHc2X0kaJQSSRqpaq6FDlzJ0Wd66ONsVsHMUZMGpmntlgOBCXpwoF+rrr6QUTR6g9UdQHTVWj2ws93gQL+2r74qwYhQaHTBA6JrnLDSuS+HSVp19YXJBQRkFCNppGLtlgMaHRtve4210IhNDkfSJGkkqrnULqjM8eVbLiVBIxZMHAIBmiWOTiNoqVGHJkEjNjlM0tSkkZgHn9sfmKD7K33UoYEpGEkjEdVaXW+c6Lzlm6V2SEQOR9IkaSQiaMs3S+2QBHNq0kBHRwMmCilxIDFsZgHeqbmao9MAZqC/QokDyWEkDbwtrHFSf6VPD3zsvYnGBOQNSRqxCGucxEQh0kBNGpgUVOIwiYlCpIMkDTQETRSeM9CfYCTAJFZ3oOyGqyN6ctdhjXvn3wQaJwHTQ5JGTwxXRyKd8k3jJKSKkTTKqFqrByZoU6PEwUQhUkeSRtmE9YWWpFcevj6haIBgeaxJ02AJMxLUFxrAzJGkMSNBqzgkaU6FHzFgJvgNwowELaebZdKfrrg4wWiAED6DR0pI0piRVVdfqP5K32mvnzWnonU3c8IKMsTf7oTXzSMtTBxiRppJeO2WAzp6fJRVHMi2HE4ckqQxYze+b5CkjHwgSaPImm1HGTEDyYlUkzaza8zsgJkdNLPVAfd9wMzGzeym3oWILBiujugLT+9R/fioXFL9+Kju3Tiiaq2edmhAJKZ81qRDk7SZ9Un6qqRrJV0k6VYzu6jDfX8maUuvg0S6OrUdHR0bDzwWC8icgq7u+KCkg+7+sru/JekpSTe0ue+PJH1b0qs9jA8ZENR2NGydNJAZOV3dESVJD0o63PL8yORrp5jZoKSPS3os6I3M7E4z221mu48dOzbdWJES2o4C0cRRGo6SpNud3Dj1/yuPSrrH3QP3B7v7encfcvehBQsWRPjSyIJOiZi2o8idGMsdcZWGoyTpI5LOa3l+rqSjU+4ZkvSUmf1E0k2SvmZmN0YJANnXbsMKbUeRS/HWpGMpDUdZgve8pCVmdoGkuqRPSrqt9QZ3v6D5ZzP7hqT/5e7VKAEg+9iwgqKYYW15vpntbnm+3t3XtzxvVxpe9o6v/3Zp+CpJH4jyRUOTtLufNLPPqTE075P0hLvvN7PPTF4PrEOjGNiwgkKYWZJ+zd2HAq5PqzRs1u7200XazOLumyVtnvJa2+Ts7r8f6Ssjk9iwAnRtOqVhSZov6TozOxlUeWDHISQ1kvODz+3XGyfGTr3W3LAiiUSN/It/vXMspWG64EHVWl2rnt37jgTdxIYVFEmc66Td/aSkZmn4h5KeaZaGm+XhbjCShu5+Zo/GA34I2bCCwoh5U0ocpWGSdMktX7ctMEFLbFhBcXDGIXKlWqvrx6++GXhPf6WPDStAihhJl1hYrdkkrVmxlElDFEcOR9Ik6RILqzV/+RaOv0KBpNzNrlsk6RJqroUO+nldsnAuCRqFYmq/2yTrSNIlU63Vde/GEY2Ode6FtWThXG2968rkggLQEUm6ZNZuOdAxQQ+ywxBFR7kDWVat1VXvUIc2SdtXX5VsQEDC8rgEjyRdEsPVEW3YeajjddZCoxRI0sii4eqIvhmQoFkLjdLIYZJmM0vBNQ+RDcJaaCC7GEkXWNgIWmpMFpKgUQopHyjbLZJ0QUVJ0JxRiNIhSSMrntx1OPQezihE2TCSRiZUa3WNe+efxuYhsl+6cWlyQQFZQJJG2sKW2kn05ADyhCRdIM2VHEGDhdspcaDEKHcgNdVaXXc/szc0QVPiQGnRBQ9paTZNCqpDDw70k6ABkjTS8MWN+zQ6NtHxOkvtgPwiSedYtVbXqm/tUUB+PrWSgzo0ys5ETRoJqtbq+vzTewLv6TPTIzdfQoIGmkjSSMpdIQlaEgkamMIC5m2yiiSdUwEVDkmSmUjQQKucru6gC15BrVy2KO0QAPQAI+kcqdbqevC5/XrjxFjgfVcsnsdyO6ANJg4Rmyhd7STp7DNna8MdlycQEZBDJGnEoVqrR0rQnPINBGMkjVjcu3Ff4HWT9MrD1ycTDJBnOUzSTBxm3HB1JHA3ocQhskCRMZLOsCjnE0ps+QYi4fgs9NraLQdC/3VG61FgGkjS6JVqra768dHAe2g9CkSX194d1KQzqNl6NAgJGigHRtIZ02ze36k3NOcTAjNA7w7MRKP1aOcELXE+ITATeSx3kKQz5N6N+zQ2EXy6Cgka6FJOGyyRpDNi5eM7AtdD91f6WGoHzJCFtY/MICYOM2C4OqLtL70eeM+aFUsZRQMlxEg6ZVEaJ501p0KCBnqBcgemI2pnu/s/+t4EogGKj4lDTMuGXeEJmh2FQI+4WIKH6Qn7eaF5P9BbeRxJM3GYUbdftojm/QBI0mmaU2n/n39OZRYjaCAOPoNHSih3JKxaq2vtlgM6enxUA3MqOjFlbfQsk/50xcUpRQcUV14bLJGkE9RsnDQ6Ni5JeuPEmCp9prmzz9DPRsd0zkC/Vl19IROFQBzciztxaGbXSPpzSX2Svu7uD0+5vlLSPZNP/5+k/+Lue3sZaBGs3XLgVIJuGht3zf21M7Tn/o+kFBWALAtN0mbWJ+mrkpZLOiLpeTPb5O4vttz2iqT/5O5vmNm1ktZLWhZHwHnULHF06g99NKRvNIDeKGq544OSDrr7y5JkZk9JukHSqSTt7t9vuX+npHN7GWSeDVdHtGHnocB5B84oBBKSwyQdZXXHoKTDLc+PTL7WyR9I+tuZBFUUzTMKg34uaJwEJMe8+0daooykrc1rbUM2sw+pkaR/p8P1OyXdKUmLFi2KGGI+NZv3B31vB5koBJLjkgJaAWdVlCR9RNJ5Lc/PlXR06k1mdrGkr0u61t1/2u6N3H29GvVqDQ0N5e+/VkTNVRxBzfsHB/q1ffVVCUYFII+ilDuel7TEzC4ws9mSPilpU+sNZrZI0kZJv+fuP+p9mPnSbhVHK5MocQBpKOJmFnc/aWafk7RFjSV4T7j7fjP7zOT1xyT9saTflPQ1M5Okk+4+FF/Y2Ra0WqN5RiElDiB5RV3dIXffLGnzlNcea/nzH0r6w96Glj/NpXadfg76zPTIzZeQoIG05HAzC707eqRaq2vVs3s7roXur/SRoIGUxb26w8yuMbMDZnbQzFa3ub7SzPZNPr5vZpeEvSfbwnvkwef2a2y8/XeSVRxA8cW18Y8k3SNvnBjreI1VHEAGxD8BGMvGP5I0gFJodMGLNUu32/gXNEqOtPGPJN0jA/0VHR89fTQ90F9JIRoAbU2E3xJgvpntbnm+fnLvR1PPNv61YuKwRx742HtVmfXO71FllumBj3GILFAQr7n7UMtj/ZTr0934d0OnjX+tGEl3obVx/9Qe0J1eB5C+mMsdpzb+SaqrsfHvtnd8/S42/pGkp2nl4zu0/aXXTz2vHx/VF57eI0m68X2DJGUgq2KeOIxr4x9JehqWr9umH7/65mmvu6T//uxeEjSQafGfzBLHxj+SdETD1ZG2CbrprQ5rpAFkRx63hTNxGNGGXYfSDgFACTGSjqBaq+dxyz+AqXL4i0ySDlGt1fX5yYnBIFcsnhd/MAC655LNbJ10KkjSAaaToDfccXn8AQGYGUbSxVGt1bXqW3tD73v0lktZ1QEgNiTpDh7YtF9jIeehnTWnQoIG8iR/A2mSdDvVWr1tH46p7v8oW76BPIl5x2EsSNJTNA+RDXPF4nmMooG8IUnnX9ghspJ0+2WL9KUblyYUEYCecM20C14qSNKTmk2TOh1/JUmVPtPamzgCC0BySNJqJOi7v7VX4wEThX1GggbyzOTUpPPqnm/vC0zQ/ZU+rVmxlAQN5B1JOn+GqyP61cnOhSoOkQUKhCSdL8PVEX1zZ3DjJA6RBQoipxOHpe2CV63VQxN0uwPLACBJpR1J3/c/w9dCr7xsUQKRAEgKE4c5Ua3V9eZbwWuhr1g8j7XQQNGQpLNvuDqiDSFlDjarAEUU//FZcShVko5Sh5ZEggaQGaVJ0lF7Q99OHRooJhcj6azqdMr3VJQ5gILL4RK8wifplY/viJSgad4PFB+rOzJo+0uvh97TX5lFggbKIIdJutCbWc5f/TeR7luz4uKYIwGA7hR2JL3y8R2R7qN5P1ASLinkSLwsKmSSrtbqkcocTBQCZcI66UxgJQeAjkjS6YqaoCU2rACllMMkXaiJw6gJ+icPXx9zJADQG4UZSf/be6Ot5CBBAyXFxGF6lj20VScj/LdnyzdQZi55/rYc5j5JL1+3Tf/yi7dC7zvDqEMDpUdNOllRJwpN0sE1lDkA5E9uR9LVWj1Sgn5Xn+kfH7ougYgAZBo16WRFaTsqiQQN4G05LHfkMklH7cmxZOHcmCMBkCsk6fi9577Nke57V59p611XxhsMgBzJ57bwXE0cLntoq345Hv4fmTo0gKLIzUj64vu/q5//KviEb6mxkoMEDeA0LmmCddKxWL5uW6QELUmvsKMQQCc5LHfkIklH7cnx6C2XxhsIgHzLYZKOVJM2s2vM7ICZHTSz1W2um5n9xeT1fWb2/l4FGHUlx9lnzqZ5P4AA3lgn3e0jJaFJ2sz6JH1V0rWSLpJ0q5ldNOW2ayUtmXzcKekvexFc1AQtSbvuW96LLwkAmRJlJP1BSQfd/WV3f0vSU5JumHLPDZL+yht2Shows3f3ONaO6GwHIJRL7hNdP9ISJUkPSjrc8vzI5GvTvUdmdqeZ7Taz3ceOHZturG2RoAFEVsRyhxqr2qaaGnGUe+Tu6919yN2HFixYECW+QGefOXvG7wGgRNy7f6QkSpI+Ium8lufnSjraxT09Rx0aQNFFSdLPS1piZheY2WxJn5S0aco9myR9anKVx2WSfubu/zzT4IJKGZQ5AEyLe2MzS7ePlISuk3b3k2b2OUlbJPVJesLd95vZZyavPyZps6TrJB2UdELSp3sVIMkYQM/kcJ10pM0s7r5ZjUTc+tpjLX92SZ/tbWgA0FvOtnAAyCq64AEAeoyRNIBy4PgsAMi4FHcOdoskDaAUXJLncCRNTRpAObg3RtLdPiKIo2MoSRoAeiCujqEkaQCl4RPe9SOCWDqGkqQBlEe85Y6edQxtldrE4QsvvPCamf3TNP7KfEmvxRVPQvgM6ct7/FI5P8O/nukX/IXe2PK//dn5M3iLd5nZ7pbn6919fcvznnUMbZVaknb3afUqNbPd7j4UVzxJ4DOkL+/xS3yGbrn7NTF/iVg6hlLuAIDeiKVjKOukAaAH4uoYmqckvT78lszjM6Qv7/FLfIbMiqNjqHkOu0IBQFlQkwaADMtcko5jW2XSInyGlZOx7zOz75vZJWnE2UlY/C33fcDMxs3spiTjiyLKZzCzK81sj5ntN7O/SzrGMBF+jn7DzJ4zs72Tn6FnJyL1gpk9YWavmtkPOlzP/O9yJrh7Zh5qFNtfkvRvJM2WtFfSRVPuuU7S36qx3vAySbvSjruLz/AfJJ01+edrs/QZosTfct//UaP+dlPacXfxPRiQ9KKkRZPPF6Yddxef4YuS/mzyzwskvS5pdtqxt8T3HyW9X9IPOlzP9O9yVh5ZG0nHsq0yYaGfwd2/7+5vTD7dqcZayayI8j2QpD+S9G1JryYZXERRPsNtkja6+yFJcvesfY4on8ElnWlmJunX1UjSJ5MNszN3/54aMXWS9d/lTMhako5lW2XCphvfH6gxmsiK0PjNbFDSxyU9pmyK8j34LUlnmdk2M3vBzD6VWHTRRPkMX5H079TYDDEi6b+556phctZ/lzMha0vwYtlWmbDI8ZnZh9RI0r8Ta0TTEyX+RyXd4+7jjUFc5kT5DGdI+m1JH5bUL2mHme109x/FHVxEUT7D1ZL2SLpK0mJJW83s79395zHH1itZ/13OhKwl6Vi2VSYsUnxmdrGkr0u61t1/mlBsUUSJf0jSU5MJer6k68zspLtXE4kwXNSfo9fc/U1Jb5rZ9yRdIikrSTrKZ/i0pIe9UeA9aGavSHqPpH9IJsQZy/rvciZkrdwRy7bKhIV+BjNbJGmjpN/L0MitKTR+d7/A3c939/MlPSvpv2YoQUvRfo6+I+l3zewMM5sjaZmkHyYcZ5Aon+GQGv8SkJmdLelCSS8nGuXMZP13ORMyNZL2mLZVJiniZ/hjSb8p6WuTo9GTnpGGORHjz7Qon8Hdf2hm35W0T9KEpK+7e9ulYmmI+H34E0nfMLMRNUoH97h7ZrrjmdmTkq6UNN/Mjki6X1JFysfvclaw4xAAMixr5Q4AQAuSNABkGEkaADKMJA0AGUaSBoAMI0kDQIaRpAEgw0jSAJBh/x+SfPNr/oVXAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3D프린팅</th>\n",
       "      <th>4차산업</th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>STEAM교육</th>\n",
       "      <th>가상현실</th>\n",
       "      <th>감성</th>\n",
       "      <th>감성분석</th>\n",
       "      <th>감정</th>\n",
       "      <th>강한인공지능</th>\n",
       "      <th>강화학습</th>\n",
       "      <th>...</th>\n",
       "      <th>핀테크</th>\n",
       "      <th>학습</th>\n",
       "      <th>학습동기</th>\n",
       "      <th>학습성과</th>\n",
       "      <th>학업성취도</th>\n",
       "      <th>합성곱신경망</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>헬스케어</th>\n",
       "      <th>혁신</th>\n",
       "      <th>협업</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3D프린팅  4차산업  4차산업혁명  STEAM교육  가상현실  감성  감성분석  감정  강한인공지능  강화학습  ...  핀테크  \\\n",
       "0        0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "1        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "2        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "3        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "4        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "..     ...   ...     ...      ...   ...  ..   ...  ..     ...   ...  ...  ...   \n",
       "930      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "931      0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "932      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "933      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "934      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "\n",
       "     학습  학습동기  학습성과  학업성취도  합성곱신경망  핵심역량  헬스케어  혁신  협업  \n",
       "0     0     0     0      0       0     0     0   0   0  \n",
       "1     0     0     0      0       0     0     0   0   0  \n",
       "2     0     0     0      0       0     0     0   0   0  \n",
       "3     0     0     0      0       0     0     0   0   0  \n",
       "4     0     0     0      0       0     0     0   0   0  \n",
       "..   ..   ...   ...    ...     ...   ...   ...  ..  ..  \n",
       "930   0     0     0      0       0     0     0   0   0  \n",
       "931   0     0     0      0       0     0     0   0   0  \n",
       "932   0     0     0      0       0     0     0   0   0  \n",
       "933   0     0     0      0       0     0     0   0   0  \n",
       "934   0     0     0      0       0     0     0   0   0  \n",
       "\n",
       "[935 rows x 262 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/paper_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(935, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.06844919786096257\n",
      "precision :  0.5667506297229219\n",
      "recall :  0.13546056592414207\n",
      "f1 :  0.21865889212827985\n",
      "------------------------\n",
      "hamming_loss :  0.006564069069682002\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.06844919786096257\n",
      "precision :  0.23957219251336898\n",
      "recall :  0.1382174688057041\n",
      "f1 :  0.16618792971734148\n",
      "------------------------\n",
      "hamming_loss :  0.006564069069682002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ccf08da81ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wrong example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m attention_extractor = Model(inputs=[document_input],\n\u001b[0m\u001b[0;32m      3\u001b[0m                             outputs=[word_attention, sentence_attention])\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_input' is not defined"
     ]
    }
   ],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
