{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13335135398576285096\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10720402020665658983\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8430264316126707894\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11387387533072640523\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_ls32_v2_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_ls32_v2_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_ls32_v2_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...</td>\n",
       "      <td>0.417401</td>\n",
       "      <td>3.110558</td>\n",
       "      <td>3.668839</td>\n",
       "      <td>1.226133</td>\n",
       "      <td>2.162574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931701</td>\n",
       "      <td>2.592113</td>\n",
       "      <td>...</td>\n",
       "      <td>3.868774</td>\n",
       "      <td>3.319746</td>\n",
       "      <td>3.433081</td>\n",
       "      <td>2.390619</td>\n",
       "      <td>4.531190</td>\n",
       "      <td>2.798172</td>\n",
       "      <td>2.228583</td>\n",
       "      <td>1.412827</td>\n",
       "      <td>0.902569</td>\n",
       "      <td>4.032192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...</td>\n",
       "      <td>0.156090</td>\n",
       "      <td>1.817906</td>\n",
       "      <td>2.516934</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.786605</td>\n",
       "      <td>1.056361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765907</td>\n",
       "      <td>2.722389</td>\n",
       "      <td>2.902149</td>\n",
       "      <td>1.056934</td>\n",
       "      <td>3.805281</td>\n",
       "      <td>2.013745</td>\n",
       "      <td>0.807450</td>\n",
       "      <td>1.169613</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>1.259672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...</td>\n",
       "      <td>2.615420</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>3.032917</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>4.051877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>2.249975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535463</td>\n",
       "      <td>1.525661</td>\n",
       "      <td>3.134440</td>\n",
       "      <td>3.392141</td>\n",
       "      <td>3.054707</td>\n",
       "      <td>2.136985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086341</td>\n",
       "      <td>2.693710</td>\n",
       "      <td>3.209113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...</td>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>1.078584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...</td>\n",
       "      <td>3.056171</td>\n",
       "      <td>2.104629</td>\n",
       "      <td>2.814471</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>2.857896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006338</td>\n",
       "      <td>1.256253</td>\n",
       "      <td>...</td>\n",
       "      <td>2.394616</td>\n",
       "      <td>2.801673</td>\n",
       "      <td>2.485481</td>\n",
       "      <td>3.802172</td>\n",
       "      <td>4.070567</td>\n",
       "      <td>2.348916</td>\n",
       "      <td>2.177757</td>\n",
       "      <td>0.869026</td>\n",
       "      <td>1.684833</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2800</td>\n",
       "      <td>딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...</td>\n",
       "      <td>4.186645</td>\n",
       "      <td>3.224278</td>\n",
       "      <td>2.117567</td>\n",
       "      <td>0.419262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.746918</td>\n",
       "      <td>1.778923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820696</td>\n",
       "      <td>3.612397</td>\n",
       "      <td>4.454446</td>\n",
       "      <td>1.590904</td>\n",
       "      <td>2.417366</td>\n",
       "      <td>5.644652</td>\n",
       "      <td>4.679737</td>\n",
       "      <td>1.634320</td>\n",
       "      <td>1.236829</td>\n",
       "      <td>0.237118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2801</td>\n",
       "      <td>본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...</td>\n",
       "      <td>3.364617</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>1.230430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383199</td>\n",
       "      <td>1.191509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606773</td>\n",
       "      <td>4.367097</td>\n",
       "      <td>3.565836</td>\n",
       "      <td>3.955093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233802</td>\n",
       "      <td>1.044027</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>3.691920</td>\n",
       "      <td>2.591480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2802</td>\n",
       "      <td>인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...</td>\n",
       "      <td>1.978602</td>\n",
       "      <td>1.928831</td>\n",
       "      <td>2.123523</td>\n",
       "      <td>0.511366</td>\n",
       "      <td>1.142202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.150192</td>\n",
       "      <td>2.086830</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064874</td>\n",
       "      <td>2.610252</td>\n",
       "      <td>3.291699</td>\n",
       "      <td>0.881856</td>\n",
       "      <td>1.587655</td>\n",
       "      <td>2.168864</td>\n",
       "      <td>2.272126</td>\n",
       "      <td>1.206674</td>\n",
       "      <td>1.673436</td>\n",
       "      <td>2.926039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2803</td>\n",
       "      <td>인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...</td>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255934</td>\n",
       "      <td>4.824238</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...</td>\n",
       "      <td>2.148395</td>\n",
       "      <td>1.330493</td>\n",
       "      <td>6.214635</td>\n",
       "      <td>0.701584</td>\n",
       "      <td>2.780770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.274260</td>\n",
       "      <td>1.540647</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185889</td>\n",
       "      <td>3.204329</td>\n",
       "      <td>0.845317</td>\n",
       "      <td>3.219305</td>\n",
       "      <td>3.225749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905107</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>2.276694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...  0.417401   \n",
       "1              1  고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...  0.156090   \n",
       "2              2  마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...  2.615420   \n",
       "3              3  현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...  2.049675   \n",
       "4              4  최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...  3.056171   \n",
       "...          ...                                                ...       ...   \n",
       "2800        2800  딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...  4.186645   \n",
       "2801        2801  본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...  3.364617   \n",
       "2802        2802  인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...  1.978602   \n",
       "2803        2803  인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...  2.831361   \n",
       "2804        2804  현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...  2.148395   \n",
       "\n",
       "             1         2         3         4    5         6         7  ...  \\\n",
       "0     3.110558  3.668839  1.226133  2.162574  0.0  3.931701  2.592113  ...   \n",
       "1     1.817906  2.516934  0.445787  0.861615  0.0  1.786605  1.056361  ...   \n",
       "2     0.419531  3.032917  0.012062  4.051877  0.0  0.107185  2.249975  ...   \n",
       "3     1.346292  3.854792  0.000000  0.622733  0.0  2.288307  1.360127  ...   \n",
       "4     2.104629  2.814471  0.420903  2.857896  0.0  2.006338  1.256253  ...   \n",
       "...        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "2800  3.224278  2.117567  0.419262  0.000000  0.0  2.746918  1.778923  ...   \n",
       "2801  0.964592  0.363475  0.003237  1.230430  0.0  2.383199  1.191509  ...   \n",
       "2802  1.928831  2.123523  0.511366  1.142202  0.0  2.150192  2.086830  ...   \n",
       "2803  2.731905  3.412751  0.971666  2.699568  0.0  3.641780  2.886727  ...   \n",
       "2804  1.330493  6.214635  0.701584  2.780770  0.0  3.274260  1.540647  ...   \n",
       "\n",
       "            22        23        24        25        26        27        28  \\\n",
       "0     3.868774  3.319746  3.433081  2.390619  4.531190  2.798172  2.228583   \n",
       "1     0.765907  2.722389  2.902149  1.056934  3.805281  2.013745  0.807450   \n",
       "2     1.535463  1.525661  3.134440  3.392141  3.054707  2.136985  0.000000   \n",
       "3     0.000000  2.582102  3.751017  0.447963  2.649111  2.317543  0.984748   \n",
       "4     2.394616  2.801673  2.485481  3.802172  4.070567  2.348916  2.177757   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2800  0.820696  3.612397  4.454446  1.590904  2.417366  5.644652  4.679737   \n",
       "2801  1.606773  4.367097  3.565836  3.955093  0.000000  1.233802  1.044027   \n",
       "2802  2.064874  2.610252  3.291699  0.881856  1.587655  2.168864  2.272126   \n",
       "2803  3.224768  2.851137  4.704193  2.255934  4.824238  2.652613  3.096685   \n",
       "2804  2.185889  3.204329  0.845317  3.219305  3.225749  0.000000  0.000000   \n",
       "\n",
       "            29        30        31  \n",
       "0     1.412827  0.902569  4.032192  \n",
       "1     1.169613  0.953063  1.259672  \n",
       "2     1.086341  2.693710  3.209113  \n",
       "3     0.844156  0.903332  1.078584  \n",
       "4     0.869026  1.684833  1.638000  \n",
       "...        ...       ...       ...  \n",
       "2800  1.634320  1.236829  0.237118  \n",
       "2801  0.285247  3.691920  2.591480  \n",
       "2802  1.206674  1.673436  2.926039  \n",
       "2803  1.063173  1.317709  2.316168  \n",
       "2804  0.905107  0.900056  2.276694  \n",
       "\n",
       "[2805 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...</td>\n",
       "      <td>1.160812</td>\n",
       "      <td>0.702376</td>\n",
       "      <td>1.826283</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>2.379605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>2.613026</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>2.660992</td>\n",
       "      <td>3.650507</td>\n",
       "      <td>1.895083</td>\n",
       "      <td>1.215869</td>\n",
       "      <td>1.655062</td>\n",
       "      <td>1.252426</td>\n",
       "      <td>1.994516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...</td>\n",
       "      <td>1.830713</td>\n",
       "      <td>1.299031</td>\n",
       "      <td>2.827974</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>3.418776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.422769</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050494</td>\n",
       "      <td>2.773801</td>\n",
       "      <td>2.208181</td>\n",
       "      <td>3.877333</td>\n",
       "      <td>4.353286</td>\n",
       "      <td>0.376468</td>\n",
       "      <td>1.152847</td>\n",
       "      <td>0.281889</td>\n",
       "      <td>1.411207</td>\n",
       "      <td>1.251945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...</td>\n",
       "      <td>0.723097</td>\n",
       "      <td>3.877661</td>\n",
       "      <td>3.058774</td>\n",
       "      <td>0.566229</td>\n",
       "      <td>3.005013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>1.975427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238015</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>1.527651</td>\n",
       "      <td>3.695491</td>\n",
       "      <td>4.489433</td>\n",
       "      <td>1.267462</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>1.831583</td>\n",
       "      <td>1.644332</td>\n",
       "      <td>3.562235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...</td>\n",
       "      <td>1.319847</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>3.826420</td>\n",
       "      <td>0.593425</td>\n",
       "      <td>3.193208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417923</td>\n",
       "      <td>2.732662</td>\n",
       "      <td>2.437556</td>\n",
       "      <td>2.723172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.527535</td>\n",
       "      <td>0.437404</td>\n",
       "      <td>2.085263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...</td>\n",
       "      <td>2.897877</td>\n",
       "      <td>0.160974</td>\n",
       "      <td>2.582344</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>3.052699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078064</td>\n",
       "      <td>4.584823</td>\n",
       "      <td>1.536940</td>\n",
       "      <td>3.385062</td>\n",
       "      <td>4.425127</td>\n",
       "      <td>3.917932</td>\n",
       "      <td>1.746897</td>\n",
       "      <td>2.050241</td>\n",
       "      <td>1.952030</td>\n",
       "      <td>1.620024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...</td>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701067</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341525</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...</td>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255933</td>\n",
       "      <td>4.824239</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...</td>\n",
       "      <td>2.594126</td>\n",
       "      <td>1.276027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376698</td>\n",
       "      <td>2.051559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.165917</td>\n",
       "      <td>2.785203</td>\n",
       "      <td>...</td>\n",
       "      <td>3.747175</td>\n",
       "      <td>1.908190</td>\n",
       "      <td>4.824211</td>\n",
       "      <td>1.065796</td>\n",
       "      <td>2.344577</td>\n",
       "      <td>2.191438</td>\n",
       "      <td>2.762595</td>\n",
       "      <td>0.569525</td>\n",
       "      <td>1.726421</td>\n",
       "      <td>1.344647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...</td>\n",
       "      <td>2.014281</td>\n",
       "      <td>2.630730</td>\n",
       "      <td>4.114912</td>\n",
       "      <td>0.681983</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169341</td>\n",
       "      <td>1.979973</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057004</td>\n",
       "      <td>2.688292</td>\n",
       "      <td>2.035194</td>\n",
       "      <td>2.976359</td>\n",
       "      <td>0.179143</td>\n",
       "      <td>3.286419</td>\n",
       "      <td>1.043921</td>\n",
       "      <td>0.200325</td>\n",
       "      <td>0.232417</td>\n",
       "      <td>2.168765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...</td>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.078585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...  1.160812   \n",
       "1             1  최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...  1.830713   \n",
       "2             2  가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...  0.723097   \n",
       "3             3  문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...  1.319847   \n",
       "4             4  최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...  2.897877   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...  1.387571   \n",
       "931         931  제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...  2.831361   \n",
       "932         932  초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...  2.594126   \n",
       "933         933  사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...  2.014281   \n",
       "934         934  이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...  2.049675   \n",
       "\n",
       "            1         2         3         4    5         6         7  ...  \\\n",
       "0    0.702376  1.826283  0.070483  2.379605  0.0  0.315229  0.000000  ...   \n",
       "1    1.299031  2.827974  0.773668  3.418776  0.0  2.422769  0.279148  ...   \n",
       "2    3.877661  3.058774  0.566229  3.005013  0.0  0.051266  1.975427  ...   \n",
       "3    0.874532  3.826420  0.593425  3.193208  0.0  0.000000  2.089211  ...   \n",
       "4    0.160974  2.582344  0.373056  3.052699  0.0  0.876786  0.000000  ...   \n",
       "..        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "930  3.701067  3.436297  0.713277  2.880716  0.0  1.513215  2.407779  ...   \n",
       "931  2.731905  3.412751  0.971666  2.699569  0.0  3.641780  2.886727  ...   \n",
       "932  1.276027  0.000000  0.376698  2.051559  0.0  2.165917  2.785203  ...   \n",
       "933  2.630730  4.114912  0.681983  0.295765  0.0  3.169341  1.979973  ...   \n",
       "934  1.346292  3.854792  0.000000  0.622734  0.0  2.288307  1.360127  ...   \n",
       "\n",
       "           22        23        24        25        26        27        28  \\\n",
       "0    0.659600  2.613026  0.217506  2.660992  3.650507  1.895083  1.215869   \n",
       "1    1.050494  2.773801  2.208181  3.877333  4.353286  0.376468  1.152847   \n",
       "2    0.238015  0.224763  1.527651  3.695491  4.489433  1.267462  0.980352   \n",
       "3    1.499055  0.000000  1.417923  2.732662  2.437556  2.723172  0.000000   \n",
       "4    1.078064  4.584823  1.536940  3.385062  4.425127  3.917932  1.746897   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  1.571257  1.976123  3.341525  2.811006  5.955709  2.899572  2.129996   \n",
       "931  3.224768  2.851137  4.704193  2.255933  4.824239  2.652613  3.096685   \n",
       "932  3.747175  1.908190  4.824211  1.065796  2.344577  2.191438  2.762595   \n",
       "933  1.057004  2.688292  2.035194  2.976359  0.179143  3.286419  1.043921   \n",
       "934  0.000000  2.582102  3.751017  0.447963  2.649111  2.317543  0.984748   \n",
       "\n",
       "           29        30        31  \n",
       "0    1.655062  1.252426  1.994516  \n",
       "1    0.281889  1.411207  1.251945  \n",
       "2    1.831583  1.644332  3.562235  \n",
       "3    1.527535  0.437404  2.085263  \n",
       "4    2.050241  1.952030  1.620024  \n",
       "..        ...       ...       ...  \n",
       "930  2.093030  1.566517  2.736027  \n",
       "931  1.063173  1.317709  2.316168  \n",
       "932  0.569525  1.726421  1.344647  \n",
       "933  0.200325  0.232417  2.168765  \n",
       "934  0.844156  0.903333  1.078585  \n",
       "\n",
       "[935 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...</td>\n",
       "      <td>2.721272</td>\n",
       "      <td>0.645896</td>\n",
       "      <td>4.298009</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>1.257981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.013318</td>\n",
       "      <td>1.731955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354994</td>\n",
       "      <td>2.312873</td>\n",
       "      <td>2.890211</td>\n",
       "      <td>2.014307</td>\n",
       "      <td>1.847732</td>\n",
       "      <td>5.673225</td>\n",
       "      <td>1.020746</td>\n",
       "      <td>0.565236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...</td>\n",
       "      <td>1.959765</td>\n",
       "      <td>0.626602</td>\n",
       "      <td>4.517123</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>3.517265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.748332</td>\n",
       "      <td>1.154613</td>\n",
       "      <td>...</td>\n",
       "      <td>2.489295</td>\n",
       "      <td>3.683540</td>\n",
       "      <td>2.161397</td>\n",
       "      <td>2.854535</td>\n",
       "      <td>5.056381</td>\n",
       "      <td>1.238201</td>\n",
       "      <td>0.931779</td>\n",
       "      <td>1.155392</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>1.745236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...</td>\n",
       "      <td>1.957325</td>\n",
       "      <td>3.521863</td>\n",
       "      <td>2.222190</td>\n",
       "      <td>0.223836</td>\n",
       "      <td>2.106490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.032464</td>\n",
       "      <td>1.760850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079385</td>\n",
       "      <td>2.673229</td>\n",
       "      <td>3.130688</td>\n",
       "      <td>2.876190</td>\n",
       "      <td>3.573605</td>\n",
       "      <td>0.368269</td>\n",
       "      <td>2.141461</td>\n",
       "      <td>1.194386</td>\n",
       "      <td>2.718087</td>\n",
       "      <td>3.641629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...</td>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701068</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341526</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...</td>\n",
       "      <td>0.703739</td>\n",
       "      <td>2.954461</td>\n",
       "      <td>2.771776</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>1.774965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>2.249922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.968887</td>\n",
       "      <td>2.441638</td>\n",
       "      <td>3.184179</td>\n",
       "      <td>1.979293</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>1.360672</td>\n",
       "      <td>0.692212</td>\n",
       "      <td>0.601506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...</td>\n",
       "      <td>2.998761</td>\n",
       "      <td>2.426008</td>\n",
       "      <td>3.340866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.929126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355311</td>\n",
       "      <td>1.899159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710930</td>\n",
       "      <td>2.244099</td>\n",
       "      <td>3.783546</td>\n",
       "      <td>1.620312</td>\n",
       "      <td>4.401006</td>\n",
       "      <td>1.960070</td>\n",
       "      <td>2.434037</td>\n",
       "      <td>1.895536</td>\n",
       "      <td>2.504398</td>\n",
       "      <td>2.101616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...</td>\n",
       "      <td>3.354524</td>\n",
       "      <td>1.159952</td>\n",
       "      <td>3.526752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.501508</td>\n",
       "      <td>1.826950</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144366</td>\n",
       "      <td>2.221884</td>\n",
       "      <td>3.508570</td>\n",
       "      <td>1.472551</td>\n",
       "      <td>2.723095</td>\n",
       "      <td>4.782733</td>\n",
       "      <td>1.848716</td>\n",
       "      <td>1.308293</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>1.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...</td>\n",
       "      <td>2.714454</td>\n",
       "      <td>1.673788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.821686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185407</td>\n",
       "      <td>2.911188</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139254</td>\n",
       "      <td>1.647037</td>\n",
       "      <td>7.096872</td>\n",
       "      <td>1.583680</td>\n",
       "      <td>2.399300</td>\n",
       "      <td>3.760466</td>\n",
       "      <td>1.740469</td>\n",
       "      <td>0.742290</td>\n",
       "      <td>3.041659</td>\n",
       "      <td>1.197816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...</td>\n",
       "      <td>3.213248</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>2.797871</td>\n",
       "      <td>0.109383</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178684</td>\n",
       "      <td>3.220061</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223520</td>\n",
       "      <td>1.225312</td>\n",
       "      <td>4.065963</td>\n",
       "      <td>2.213822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>1.601210</td>\n",
       "      <td>2.577209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>(연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...</td>\n",
       "      <td>2.200617</td>\n",
       "      <td>0.842916</td>\n",
       "      <td>2.497828</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>2.430539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441842</td>\n",
       "      <td>1.346443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628967</td>\n",
       "      <td>4.088872</td>\n",
       "      <td>2.199776</td>\n",
       "      <td>3.532276</td>\n",
       "      <td>1.747651</td>\n",
       "      <td>3.185071</td>\n",
       "      <td>0.429099</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>2.201858</td>\n",
       "      <td>3.067677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...  2.721272   \n",
       "1             1  본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...  1.959765   \n",
       "2             2  오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...  1.957325   \n",
       "3             3  도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...  1.387571   \n",
       "4             4  컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...  0.703739   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...  2.998761   \n",
       "931         931  4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...  3.354524   \n",
       "932         932  본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...  2.714454   \n",
       "933         933  제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...  3.213248   \n",
       "934         934  (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...  2.200617   \n",
       "\n",
       "            1         2         3         4    5         6         7  ...  \\\n",
       "0    0.645896  4.298009  0.091566  1.257981  0.0  2.013318  1.731955  ...   \n",
       "1    0.626602  4.517123  0.869072  3.517265  0.0  2.748332  1.154613  ...   \n",
       "2    3.521863  2.222190  0.223836  2.106490  0.0  2.032464  1.760850  ...   \n",
       "3    3.701068  3.436297  0.713277  2.880716  0.0  1.513215  2.407779  ...   \n",
       "4    2.954461  2.771776  0.833788  1.774965  0.0  0.097611  2.249922  ...   \n",
       "..        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "930  2.426008  3.340866  0.000000  1.929126  0.0  1.355311  1.899159  ...   \n",
       "931  1.159952  3.526752  0.000000  1.252942  0.0  1.501508  1.826950  ...   \n",
       "932  1.673788  0.000000  0.000000  1.821686  0.0  1.185407  2.911188  ...   \n",
       "933  0.995946  2.797871  0.109383  1.458100  0.0  2.178684  3.220061  ...   \n",
       "934  0.842916  2.497828  0.361635  2.430539  0.0  1.441842  1.346443  ...   \n",
       "\n",
       "           22        23        24        25        26        27        28  \\\n",
       "0    1.354994  2.312873  2.890211  2.014307  1.847732  5.673225  1.020746   \n",
       "1    2.489295  3.683540  2.161397  2.854535  5.056381  1.238201  0.931779   \n",
       "2    1.079385  2.673229  3.130688  2.876190  3.573605  0.368269  2.141461   \n",
       "3    1.571257  1.976123  3.341526  2.811006  5.955709  2.899572  2.129996   \n",
       "4    0.593649  0.000000  1.968887  2.441638  3.184179  1.979293  0.447488   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  0.710930  2.244099  3.783546  1.620312  4.401006  1.960070  2.434037   \n",
       "931  1.144366  2.221884  3.508570  1.472551  2.723095  4.782733  1.848716   \n",
       "932  1.139254  1.647037  7.096872  1.583680  2.399300  3.760466  1.740469   \n",
       "933  1.223520  1.225312  4.065963  2.213822  0.000000  2.059089  0.000000   \n",
       "934  1.628967  4.088872  2.199776  3.532276  1.747651  3.185071  0.429099   \n",
       "\n",
       "           29        30        31  \n",
       "0    0.565236  0.000000  1.063749  \n",
       "1    1.155392  0.996462  1.745236  \n",
       "2    1.194386  2.718087  3.641629  \n",
       "3    2.093030  1.566517  2.736027  \n",
       "4    1.360672  0.692212  0.601506  \n",
       "..        ...       ...       ...  \n",
       "930  1.895536  2.504398  2.101616  \n",
       "931  1.308293  0.793596  1.098957  \n",
       "932  0.742290  3.041659  1.197816  \n",
       "933  0.027858  1.601210  2.577209  \n",
       "934  0.811605  2.201858  3.067677  \n",
       "\n",
       "[935 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...\n",
       "1       고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...\n",
       "2       마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...\n",
       "3       현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...\n",
       "4       최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...\n",
       "                              ...                        \n",
       "2800    딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...\n",
       "2801    본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...\n",
       "2802    인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...\n",
       "2803    인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...\n",
       "2804    현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...\n",
       "Name: abstract, Length: 2805, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417401</td>\n",
       "      <td>3.110558</td>\n",
       "      <td>3.668839</td>\n",
       "      <td>1.226133</td>\n",
       "      <td>2.162574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931701</td>\n",
       "      <td>2.592113</td>\n",
       "      <td>2.431996</td>\n",
       "      <td>2.476200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.868774</td>\n",
       "      <td>3.319746</td>\n",
       "      <td>3.433081</td>\n",
       "      <td>2.390619</td>\n",
       "      <td>4.531190</td>\n",
       "      <td>2.798172</td>\n",
       "      <td>2.228583</td>\n",
       "      <td>1.412827</td>\n",
       "      <td>0.902569</td>\n",
       "      <td>4.032192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156090</td>\n",
       "      <td>1.817906</td>\n",
       "      <td>2.516934</td>\n",
       "      <td>0.445787</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.786605</td>\n",
       "      <td>1.056361</td>\n",
       "      <td>3.568340</td>\n",
       "      <td>2.172769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765907</td>\n",
       "      <td>2.722389</td>\n",
       "      <td>2.902149</td>\n",
       "      <td>1.056934</td>\n",
       "      <td>3.805281</td>\n",
       "      <td>2.013745</td>\n",
       "      <td>0.807450</td>\n",
       "      <td>1.169613</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>1.259672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.615420</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>3.032917</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>4.051877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>2.249975</td>\n",
       "      <td>1.793349</td>\n",
       "      <td>3.025448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535463</td>\n",
       "      <td>1.525661</td>\n",
       "      <td>3.134440</td>\n",
       "      <td>3.392141</td>\n",
       "      <td>3.054707</td>\n",
       "      <td>2.136985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.086341</td>\n",
       "      <td>2.693710</td>\n",
       "      <td>3.209113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>2.699560</td>\n",
       "      <td>2.448431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>1.078584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.056171</td>\n",
       "      <td>2.104629</td>\n",
       "      <td>2.814471</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>2.857896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.006338</td>\n",
       "      <td>1.256253</td>\n",
       "      <td>0.640941</td>\n",
       "      <td>2.060637</td>\n",
       "      <td>...</td>\n",
       "      <td>2.394616</td>\n",
       "      <td>2.801673</td>\n",
       "      <td>2.485481</td>\n",
       "      <td>3.802172</td>\n",
       "      <td>4.070567</td>\n",
       "      <td>2.348916</td>\n",
       "      <td>2.177757</td>\n",
       "      <td>0.869026</td>\n",
       "      <td>1.684833</td>\n",
       "      <td>1.638000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>4.186645</td>\n",
       "      <td>3.224278</td>\n",
       "      <td>2.117567</td>\n",
       "      <td>0.419262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.746918</td>\n",
       "      <td>1.778923</td>\n",
       "      <td>0.206681</td>\n",
       "      <td>4.238903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820696</td>\n",
       "      <td>3.612397</td>\n",
       "      <td>4.454446</td>\n",
       "      <td>1.590904</td>\n",
       "      <td>2.417366</td>\n",
       "      <td>5.644652</td>\n",
       "      <td>4.679737</td>\n",
       "      <td>1.634320</td>\n",
       "      <td>1.236829</td>\n",
       "      <td>0.237118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>3.364617</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>1.230430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.383199</td>\n",
       "      <td>1.191509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.663036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.606773</td>\n",
       "      <td>4.367097</td>\n",
       "      <td>3.565836</td>\n",
       "      <td>3.955093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233802</td>\n",
       "      <td>1.044027</td>\n",
       "      <td>0.285247</td>\n",
       "      <td>3.691920</td>\n",
       "      <td>2.591480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1.978602</td>\n",
       "      <td>1.928831</td>\n",
       "      <td>2.123523</td>\n",
       "      <td>0.511366</td>\n",
       "      <td>1.142202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.150192</td>\n",
       "      <td>2.086830</td>\n",
       "      <td>0.591417</td>\n",
       "      <td>3.308824</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064874</td>\n",
       "      <td>2.610252</td>\n",
       "      <td>3.291699</td>\n",
       "      <td>0.881856</td>\n",
       "      <td>1.587655</td>\n",
       "      <td>2.168864</td>\n",
       "      <td>2.272126</td>\n",
       "      <td>1.206674</td>\n",
       "      <td>1.673436</td>\n",
       "      <td>2.926039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>1.724109</td>\n",
       "      <td>2.706757</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255934</td>\n",
       "      <td>4.824238</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2.148395</td>\n",
       "      <td>1.330493</td>\n",
       "      <td>6.214635</td>\n",
       "      <td>0.701584</td>\n",
       "      <td>2.780770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.274260</td>\n",
       "      <td>1.540647</td>\n",
       "      <td>3.870544</td>\n",
       "      <td>1.940017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.185889</td>\n",
       "      <td>3.204329</td>\n",
       "      <td>0.845317</td>\n",
       "      <td>3.219305</td>\n",
       "      <td>3.225749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905107</td>\n",
       "      <td>0.900056</td>\n",
       "      <td>2.276694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4    5         6   \\\n",
       "0     0.417401  3.110558  3.668839  1.226133  2.162574  0.0  3.931701   \n",
       "1     0.156090  1.817906  2.516934  0.445787  0.861615  0.0  1.786605   \n",
       "2     2.615420  0.419531  3.032917  0.012062  4.051877  0.0  0.107185   \n",
       "3     2.049675  1.346292  3.854792  0.000000  0.622733  0.0  2.288307   \n",
       "4     3.056171  2.104629  2.814471  0.420903  2.857896  0.0  2.006338   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "2800  4.186645  3.224278  2.117567  0.419262  0.000000  0.0  2.746918   \n",
       "2801  3.364617  0.964592  0.363475  0.003237  1.230430  0.0  2.383199   \n",
       "2802  1.978602  1.928831  2.123523  0.511366  1.142202  0.0  2.150192   \n",
       "2803  2.831361  2.731905  3.412751  0.971666  2.699568  0.0  3.641780   \n",
       "2804  2.148395  1.330493  6.214635  0.701584  2.780770  0.0  3.274260   \n",
       "\n",
       "            7         8         9   ...        22        23        24  \\\n",
       "0     2.592113  2.431996  2.476200  ...  3.868774  3.319746  3.433081   \n",
       "1     1.056361  3.568340  2.172769  ...  0.765907  2.722389  2.902149   \n",
       "2     2.249975  1.793349  3.025448  ...  1.535463  1.525661  3.134440   \n",
       "3     1.360127  2.699560  2.448431  ...  0.000000  2.582102  3.751017   \n",
       "4     1.256253  0.640941  2.060637  ...  2.394616  2.801673  2.485481   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2800  1.778923  0.206681  4.238903  ...  0.820696  3.612397  4.454446   \n",
       "2801  1.191509  0.000000  5.663036  ...  1.606773  4.367097  3.565836   \n",
       "2802  2.086830  0.591417  3.308824  ...  2.064874  2.610252  3.291699   \n",
       "2803  2.886727  1.724109  2.706757  ...  3.224768  2.851137  4.704193   \n",
       "2804  1.540647  3.870544  1.940017  ...  2.185889  3.204329  0.845317   \n",
       "\n",
       "            25        26        27        28        29        30        31  \n",
       "0     2.390619  4.531190  2.798172  2.228583  1.412827  0.902569  4.032192  \n",
       "1     1.056934  3.805281  2.013745  0.807450  1.169613  0.953063  1.259672  \n",
       "2     3.392141  3.054707  2.136985  0.000000  1.086341  2.693710  3.209113  \n",
       "3     0.447963  2.649111  2.317543  0.984748  0.844156  0.903332  1.078584  \n",
       "4     3.802172  4.070567  2.348916  2.177757  0.869026  1.684833  1.638000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2800  1.590904  2.417366  5.644652  4.679737  1.634320  1.236829  0.237118  \n",
       "2801  3.955093  0.000000  1.233802  1.044027  0.285247  3.691920  2.591480  \n",
       "2802  0.881856  1.587655  2.168864  2.272126  1.206674  1.673436  2.926039  \n",
       "2803  2.255934  4.824238  2.652613  3.096685  1.063173  1.317709  2.316168  \n",
       "2804  3.219305  3.225749  0.000000  0.000000  0.905107  0.900056  2.276694  \n",
       "\n",
       "[2805 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...\n",
       "1      최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...\n",
       "2      가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...\n",
       "3      문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...\n",
       "4      최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...\n",
       "                             ...                        \n",
       "930    인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...\n",
       "931    제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...\n",
       "932    초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...\n",
       "933    사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...\n",
       "934    이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.160812</td>\n",
       "      <td>0.702376</td>\n",
       "      <td>1.826283</td>\n",
       "      <td>0.070483</td>\n",
       "      <td>2.379605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745975</td>\n",
       "      <td>1.606460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>2.613026</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>2.660992</td>\n",
       "      <td>3.650507</td>\n",
       "      <td>1.895083</td>\n",
       "      <td>1.215869</td>\n",
       "      <td>1.655062</td>\n",
       "      <td>1.252426</td>\n",
       "      <td>1.994516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.830713</td>\n",
       "      <td>1.299031</td>\n",
       "      <td>2.827974</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>3.418776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.422769</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>0.451877</td>\n",
       "      <td>0.110715</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050494</td>\n",
       "      <td>2.773801</td>\n",
       "      <td>2.208181</td>\n",
       "      <td>3.877333</td>\n",
       "      <td>4.353286</td>\n",
       "      <td>0.376468</td>\n",
       "      <td>1.152847</td>\n",
       "      <td>0.281889</td>\n",
       "      <td>1.411207</td>\n",
       "      <td>1.251945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723097</td>\n",
       "      <td>3.877661</td>\n",
       "      <td>3.058774</td>\n",
       "      <td>0.566229</td>\n",
       "      <td>3.005013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>1.975427</td>\n",
       "      <td>0.217108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238015</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>1.527651</td>\n",
       "      <td>3.695491</td>\n",
       "      <td>4.489433</td>\n",
       "      <td>1.267462</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>1.831583</td>\n",
       "      <td>1.644332</td>\n",
       "      <td>3.562235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.319847</td>\n",
       "      <td>0.874532</td>\n",
       "      <td>3.826420</td>\n",
       "      <td>0.593425</td>\n",
       "      <td>3.193208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089211</td>\n",
       "      <td>1.337028</td>\n",
       "      <td>0.508158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417923</td>\n",
       "      <td>2.732662</td>\n",
       "      <td>2.437556</td>\n",
       "      <td>2.723172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.527535</td>\n",
       "      <td>0.437404</td>\n",
       "      <td>2.085263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.897877</td>\n",
       "      <td>0.160974</td>\n",
       "      <td>2.582344</td>\n",
       "      <td>0.373056</td>\n",
       "      <td>3.052699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.993815</td>\n",
       "      <td>4.044471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078064</td>\n",
       "      <td>4.584823</td>\n",
       "      <td>1.536940</td>\n",
       "      <td>3.385062</td>\n",
       "      <td>4.425127</td>\n",
       "      <td>3.917932</td>\n",
       "      <td>1.746897</td>\n",
       "      <td>2.050241</td>\n",
       "      <td>1.952030</td>\n",
       "      <td>1.620024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701067</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>2.422989</td>\n",
       "      <td>1.501756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341525</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2.831361</td>\n",
       "      <td>2.731905</td>\n",
       "      <td>3.412751</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>2.699569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.641780</td>\n",
       "      <td>2.886727</td>\n",
       "      <td>1.724109</td>\n",
       "      <td>2.706757</td>\n",
       "      <td>...</td>\n",
       "      <td>3.224768</td>\n",
       "      <td>2.851137</td>\n",
       "      <td>4.704193</td>\n",
       "      <td>2.255933</td>\n",
       "      <td>4.824239</td>\n",
       "      <td>2.652613</td>\n",
       "      <td>3.096685</td>\n",
       "      <td>1.063173</td>\n",
       "      <td>1.317709</td>\n",
       "      <td>2.316168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.594126</td>\n",
       "      <td>1.276027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376698</td>\n",
       "      <td>2.051559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.165917</td>\n",
       "      <td>2.785203</td>\n",
       "      <td>0.166379</td>\n",
       "      <td>3.525016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.747175</td>\n",
       "      <td>1.908190</td>\n",
       "      <td>4.824211</td>\n",
       "      <td>1.065796</td>\n",
       "      <td>2.344577</td>\n",
       "      <td>2.191438</td>\n",
       "      <td>2.762595</td>\n",
       "      <td>0.569525</td>\n",
       "      <td>1.726421</td>\n",
       "      <td>1.344647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2.014281</td>\n",
       "      <td>2.630730</td>\n",
       "      <td>4.114912</td>\n",
       "      <td>0.681983</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.169341</td>\n",
       "      <td>1.979973</td>\n",
       "      <td>1.175908</td>\n",
       "      <td>2.783127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057004</td>\n",
       "      <td>2.688292</td>\n",
       "      <td>2.035194</td>\n",
       "      <td>2.976359</td>\n",
       "      <td>0.179143</td>\n",
       "      <td>3.286419</td>\n",
       "      <td>1.043921</td>\n",
       "      <td>0.200325</td>\n",
       "      <td>0.232417</td>\n",
       "      <td>2.168765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2.049675</td>\n",
       "      <td>1.346292</td>\n",
       "      <td>3.854792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288307</td>\n",
       "      <td>1.360127</td>\n",
       "      <td>2.699560</td>\n",
       "      <td>2.448431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.582102</td>\n",
       "      <td>3.751017</td>\n",
       "      <td>0.447963</td>\n",
       "      <td>2.649111</td>\n",
       "      <td>2.317543</td>\n",
       "      <td>0.984748</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.078585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4    5         6   \\\n",
       "0    1.160812  0.702376  1.826283  0.070483  2.379605  0.0  0.315229   \n",
       "1    1.830713  1.299031  2.827974  0.773668  3.418776  0.0  2.422769   \n",
       "2    0.723097  3.877661  3.058774  0.566229  3.005013  0.0  0.051266   \n",
       "3    1.319847  0.874532  3.826420  0.593425  3.193208  0.0  0.000000   \n",
       "4    2.897877  0.160974  2.582344  0.373056  3.052699  0.0  0.876786   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "930  1.387571  3.701067  3.436297  0.713277  2.880716  0.0  1.513215   \n",
       "931  2.831361  2.731905  3.412751  0.971666  2.699569  0.0  3.641780   \n",
       "932  2.594126  1.276027  0.000000  0.376698  2.051559  0.0  2.165917   \n",
       "933  2.014281  2.630730  4.114912  0.681983  0.295765  0.0  3.169341   \n",
       "934  2.049675  1.346292  3.854792  0.000000  0.622734  0.0  2.288307   \n",
       "\n",
       "           7         8         9   ...        22        23        24  \\\n",
       "0    0.000000  0.745975  1.606460  ...  0.659600  2.613026  0.217506   \n",
       "1    0.279148  0.451877  0.110715  ...  1.050494  2.773801  2.208181   \n",
       "2    1.975427  0.217108  0.000000  ...  0.238015  0.224763  1.527651   \n",
       "3    2.089211  1.337028  0.508158  ...  1.499055  0.000000  1.417923   \n",
       "4    0.000000  1.993815  4.044471  ...  1.078064  4.584823  1.536940   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  2.407779  2.422989  1.501756  ...  1.571257  1.976123  3.341525   \n",
       "931  2.886727  1.724109  2.706757  ...  3.224768  2.851137  4.704193   \n",
       "932  2.785203  0.166379  3.525016  ...  3.747175  1.908190  4.824211   \n",
       "933  1.979973  1.175908  2.783127  ...  1.057004  2.688292  2.035194   \n",
       "934  1.360127  2.699560  2.448431  ...  0.000000  2.582102  3.751017   \n",
       "\n",
       "           25        26        27        28        29        30        31  \n",
       "0    2.660992  3.650507  1.895083  1.215869  1.655062  1.252426  1.994516  \n",
       "1    3.877333  4.353286  0.376468  1.152847  0.281889  1.411207  1.251945  \n",
       "2    3.695491  4.489433  1.267462  0.980352  1.831583  1.644332  3.562235  \n",
       "3    2.732662  2.437556  2.723172  0.000000  1.527535  0.437404  2.085263  \n",
       "4    3.385062  4.425127  3.917932  1.746897  2.050241  1.952030  1.620024  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "930  2.811006  5.955709  2.899572  2.129996  2.093030  1.566517  2.736027  \n",
       "931  2.255933  4.824239  2.652613  3.096685  1.063173  1.317709  2.316168  \n",
       "932  1.065796  2.344577  2.191438  2.762595  0.569525  1.726421  1.344647  \n",
       "933  2.976359  0.179143  3.286419  1.043921  0.200325  0.232417  2.168765  \n",
       "934  0.447963  2.649111  2.317543  0.984748  0.844156  0.903333  1.078585  \n",
       "\n",
       "[935 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...\n",
       "1      본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...\n",
       "2      오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...\n",
       "3      도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...\n",
       "4      컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...\n",
       "                             ...                        \n",
       "930    포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...\n",
       "931    4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...\n",
       "932    본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...\n",
       "933    제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...\n",
       "934    (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.721272</td>\n",
       "      <td>0.645896</td>\n",
       "      <td>4.298009</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>1.257981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.013318</td>\n",
       "      <td>1.731955</td>\n",
       "      <td>2.479199</td>\n",
       "      <td>3.847471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354994</td>\n",
       "      <td>2.312873</td>\n",
       "      <td>2.890211</td>\n",
       "      <td>2.014307</td>\n",
       "      <td>1.847732</td>\n",
       "      <td>5.673225</td>\n",
       "      <td>1.020746</td>\n",
       "      <td>0.565236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.063749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.959765</td>\n",
       "      <td>0.626602</td>\n",
       "      <td>4.517123</td>\n",
       "      <td>0.869072</td>\n",
       "      <td>3.517265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.748332</td>\n",
       "      <td>1.154613</td>\n",
       "      <td>3.767540</td>\n",
       "      <td>2.511817</td>\n",
       "      <td>...</td>\n",
       "      <td>2.489295</td>\n",
       "      <td>3.683540</td>\n",
       "      <td>2.161397</td>\n",
       "      <td>2.854535</td>\n",
       "      <td>5.056381</td>\n",
       "      <td>1.238201</td>\n",
       "      <td>0.931779</td>\n",
       "      <td>1.155392</td>\n",
       "      <td>0.996462</td>\n",
       "      <td>1.745236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.957325</td>\n",
       "      <td>3.521863</td>\n",
       "      <td>2.222190</td>\n",
       "      <td>0.223836</td>\n",
       "      <td>2.106490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.032464</td>\n",
       "      <td>1.760850</td>\n",
       "      <td>0.163494</td>\n",
       "      <td>1.658984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.079385</td>\n",
       "      <td>2.673229</td>\n",
       "      <td>3.130688</td>\n",
       "      <td>2.876190</td>\n",
       "      <td>3.573605</td>\n",
       "      <td>0.368269</td>\n",
       "      <td>2.141461</td>\n",
       "      <td>1.194386</td>\n",
       "      <td>2.718087</td>\n",
       "      <td>3.641629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.387571</td>\n",
       "      <td>3.701068</td>\n",
       "      <td>3.436297</td>\n",
       "      <td>0.713277</td>\n",
       "      <td>2.880716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513215</td>\n",
       "      <td>2.407779</td>\n",
       "      <td>2.422989</td>\n",
       "      <td>1.501756</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571257</td>\n",
       "      <td>1.976123</td>\n",
       "      <td>3.341526</td>\n",
       "      <td>2.811006</td>\n",
       "      <td>5.955709</td>\n",
       "      <td>2.899572</td>\n",
       "      <td>2.129996</td>\n",
       "      <td>2.093030</td>\n",
       "      <td>1.566517</td>\n",
       "      <td>2.736027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.703739</td>\n",
       "      <td>2.954461</td>\n",
       "      <td>2.771776</td>\n",
       "      <td>0.833788</td>\n",
       "      <td>1.774965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>2.249922</td>\n",
       "      <td>1.318498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.968887</td>\n",
       "      <td>2.441638</td>\n",
       "      <td>3.184179</td>\n",
       "      <td>1.979293</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>1.360672</td>\n",
       "      <td>0.692212</td>\n",
       "      <td>0.601506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2.998761</td>\n",
       "      <td>2.426008</td>\n",
       "      <td>3.340866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.929126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355311</td>\n",
       "      <td>1.899159</td>\n",
       "      <td>1.465890</td>\n",
       "      <td>2.361195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710930</td>\n",
       "      <td>2.244099</td>\n",
       "      <td>3.783546</td>\n",
       "      <td>1.620312</td>\n",
       "      <td>4.401006</td>\n",
       "      <td>1.960070</td>\n",
       "      <td>2.434037</td>\n",
       "      <td>1.895536</td>\n",
       "      <td>2.504398</td>\n",
       "      <td>2.101616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>3.354524</td>\n",
       "      <td>1.159952</td>\n",
       "      <td>3.526752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.501508</td>\n",
       "      <td>1.826950</td>\n",
       "      <td>1.973675</td>\n",
       "      <td>3.578372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144366</td>\n",
       "      <td>2.221884</td>\n",
       "      <td>3.508570</td>\n",
       "      <td>1.472551</td>\n",
       "      <td>2.723095</td>\n",
       "      <td>4.782733</td>\n",
       "      <td>1.848716</td>\n",
       "      <td>1.308293</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>1.098957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.714454</td>\n",
       "      <td>1.673788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.821686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185407</td>\n",
       "      <td>2.911188</td>\n",
       "      <td>0.637718</td>\n",
       "      <td>3.822897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139254</td>\n",
       "      <td>1.647037</td>\n",
       "      <td>7.096872</td>\n",
       "      <td>1.583680</td>\n",
       "      <td>2.399300</td>\n",
       "      <td>3.760466</td>\n",
       "      <td>1.740469</td>\n",
       "      <td>0.742290</td>\n",
       "      <td>3.041659</td>\n",
       "      <td>1.197816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>3.213248</td>\n",
       "      <td>0.995946</td>\n",
       "      <td>2.797871</td>\n",
       "      <td>0.109383</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.178684</td>\n",
       "      <td>3.220061</td>\n",
       "      <td>0.931835</td>\n",
       "      <td>3.105134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.223520</td>\n",
       "      <td>1.225312</td>\n",
       "      <td>4.065963</td>\n",
       "      <td>2.213822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.059089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>1.601210</td>\n",
       "      <td>2.577209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2.200617</td>\n",
       "      <td>0.842916</td>\n",
       "      <td>2.497828</td>\n",
       "      <td>0.361635</td>\n",
       "      <td>2.430539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441842</td>\n",
       "      <td>1.346443</td>\n",
       "      <td>1.778603</td>\n",
       "      <td>4.711728</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628967</td>\n",
       "      <td>4.088872</td>\n",
       "      <td>2.199776</td>\n",
       "      <td>3.532276</td>\n",
       "      <td>1.747651</td>\n",
       "      <td>3.185071</td>\n",
       "      <td>0.429099</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>2.201858</td>\n",
       "      <td>3.067677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4    5         6   \\\n",
       "0    2.721272  0.645896  4.298009  0.091566  1.257981  0.0  2.013318   \n",
       "1    1.959765  0.626602  4.517123  0.869072  3.517265  0.0  2.748332   \n",
       "2    1.957325  3.521863  2.222190  0.223836  2.106490  0.0  2.032464   \n",
       "3    1.387571  3.701068  3.436297  0.713277  2.880716  0.0  1.513215   \n",
       "4    0.703739  2.954461  2.771776  0.833788  1.774965  0.0  0.097611   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "930  2.998761  2.426008  3.340866  0.000000  1.929126  0.0  1.355311   \n",
       "931  3.354524  1.159952  3.526752  0.000000  1.252942  0.0  1.501508   \n",
       "932  2.714454  1.673788  0.000000  0.000000  1.821686  0.0  1.185407   \n",
       "933  3.213248  0.995946  2.797871  0.109383  1.458100  0.0  2.178684   \n",
       "934  2.200617  0.842916  2.497828  0.361635  2.430539  0.0  1.441842   \n",
       "\n",
       "           7         8         9   ...        22        23        24  \\\n",
       "0    1.731955  2.479199  3.847471  ...  1.354994  2.312873  2.890211   \n",
       "1    1.154613  3.767540  2.511817  ...  2.489295  3.683540  2.161397   \n",
       "2    1.760850  0.163494  1.658984  ...  1.079385  2.673229  3.130688   \n",
       "3    2.407779  2.422989  1.501756  ...  1.571257  1.976123  3.341526   \n",
       "4    2.249922  1.318498  0.000000  ...  0.593649  0.000000  1.968887   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  1.899159  1.465890  2.361195  ...  0.710930  2.244099  3.783546   \n",
       "931  1.826950  1.973675  3.578372  ...  1.144366  2.221884  3.508570   \n",
       "932  2.911188  0.637718  3.822897  ...  1.139254  1.647037  7.096872   \n",
       "933  3.220061  0.931835  3.105134  ...  1.223520  1.225312  4.065963   \n",
       "934  1.346443  1.778603  4.711728  ...  1.628967  4.088872  2.199776   \n",
       "\n",
       "           25        26        27        28        29        30        31  \n",
       "0    2.014307  1.847732  5.673225  1.020746  0.565236  0.000000  1.063749  \n",
       "1    2.854535  5.056381  1.238201  0.931779  1.155392  0.996462  1.745236  \n",
       "2    2.876190  3.573605  0.368269  2.141461  1.194386  2.718087  3.641629  \n",
       "3    2.811006  5.955709  2.899572  2.129996  2.093030  1.566517  2.736027  \n",
       "4    2.441638  3.184179  1.979293  0.447488  1.360672  0.692212  0.601506  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "930  1.620312  4.401006  1.960070  2.434037  1.895536  2.504398  2.101616  \n",
       "931  1.472551  2.723095  4.782733  1.848716  1.308293  0.793596  1.098957  \n",
       "932  1.583680  2.399300  3.760466  1.740469  0.742290  3.041659  1.197816  \n",
       "933  2.213822  0.000000  2.059089  0.000000  0.027858  1.601210  2.577209  \n",
       "934  3.532276  1.747651  3.185071  0.429099  0.811605  2.201858  3.067677  \n",
       "\n",
       "[935 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2805/2805 [01:14<00:00, 37.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:25<00:00, 37.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:25<00:00, 36.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['로지',\n",
       "  '스틱',\n",
       "  '회귀분석은',\n",
       "  '통계학',\n",
       "  '등의',\n",
       "  '분야에서',\n",
       "  '예측을',\n",
       "  '위한',\n",
       "  '기술',\n",
       "  '혹은',\n",
       "  '변수',\n",
       "  '간의',\n",
       "  '상관관계',\n",
       "  '를',\n",
       "  '설명',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '오랫동안',\n",
       "  '사용',\n",
       "  '되어',\n",
       "  '왔다',\n",
       "  '이러한',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법에서',\n",
       "  '현재',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '들',\n",
       "  '은',\n",
       "  '목적',\n",
       "  '값에',\n",
       "  '대하여',\n",
       "  '동일한',\n",
       "  '중요도를',\n",
       "  '가지고',\n",
       "  '있다',\n",
       "  '본',\n",
       "  '연구에서는',\n",
       "  '이러한',\n",
       "  '가중치',\n",
       "  '계산',\n",
       "  '을',\n",
       "  '좀더',\n",
       "  '세분화',\n",
       "  '하여',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '의',\n",
       "  '값이',\n",
       "  '서로',\n",
       "  '다른',\n",
       "  '중요도를',\n",
       "  '가지는',\n",
       "  '새로운',\n",
       "  '학습',\n",
       "  '방법을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '알고리즘의',\n",
       "  '성능을',\n",
       "  '최대',\n",
       "  '화하는',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '가중치',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '계산',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '점진적',\n",
       "  '하강법을',\n",
       "  '이용하여',\n",
       "  '개발',\n",
       "  '하였다',\n",
       "  '본',\n",
       "  '연구에서',\n",
       "  '제안된',\n",
       "  '방법은',\n",
       "  '다양한',\n",
       "  '데이터를',\n",
       "  '이용하여',\n",
       "  '실험',\n",
       "  '하였고',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '기반',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법은',\n",
       "  '기존의',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '보다',\n",
       "  '우수한',\n",
       "  '학습',\n",
       "  '능력을',\n",
       "  '보임을',\n",
       "  '알',\n",
       "  '수',\n",
       "  '있었다'],\n",
       " ['최근에',\n",
       "  '이르러',\n",
       "  '기계학습',\n",
       "  '및',\n",
       "  '데이터마이닝',\n",
       "  '은',\n",
       "  '수많은',\n",
       "  '질병',\n",
       "  '예측',\n",
       "  '및',\n",
       "  '진단에',\n",
       "  '활용되고',\n",
       "  '있다',\n",
       "  '만성질환',\n",
       "  '은',\n",
       "  '전체',\n",
       "  '사망률',\n",
       "  '의',\n",
       "  '약',\n",
       "  '80',\n",
       "  '를',\n",
       "  '차지하는',\n",
       "  '질병',\n",
       "  '으로',\n",
       "  '점점',\n",
       "  '증가',\n",
       "  '하는',\n",
       "  '추세',\n",
       "  '이다',\n",
       "  '만성질환',\n",
       "  '관련',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '연구',\n",
       "  '한',\n",
       "  '기존',\n",
       "  '연구들은',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '구성하는',\n",
       "  '데이터로',\n",
       "  '혈당',\n",
       "  '혈압',\n",
       "  '인슐린',\n",
       "  '수치',\n",
       "  '등의',\n",
       "  '건강검진',\n",
       "  '수준의',\n",
       "  '데이터를',\n",
       "  '이용',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '논문은',\n",
       "  '만성질환',\n",
       "  '의',\n",
       "  '위험',\n",
       "  '요인인',\n",
       "  '이상',\n",
       "  '지질혈증과',\n",
       "  '안면',\n",
       "  '정보의',\n",
       "  '연관성을',\n",
       "  '검증',\n",
       "  '하고',\n",
       "  '기계학습',\n",
       "  '기반',\n",
       "  '안면',\n",
       "  '정보를',\n",
       "  '이용한',\n",
       "  '이상',\n",
       "  '지질혈증',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '세계',\n",
       "  '최초로',\n",
       "  '개발',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '연구는',\n",
       "  '5390',\n",
       "  '명의',\n",
       "  '임상',\n",
       "  '데이터',\n",
       "  '중',\n",
       "  '안면',\n",
       "  '정보와',\n",
       "  '중성지방혈증',\n",
       "  '정보를',\n",
       "  '바탕으로',\n",
       "  '수행',\n",
       "  '하였다',\n",
       "  '중성지방혈증은',\n",
       "  '이상',\n",
       "  '지질혈증을',\n",
       "  '판단하는',\n",
       "  '척도',\n",
       "  '이다',\n",
       "  '연구의',\n",
       "  '결과로',\n",
       "  '얼굴',\n",
       "  '의',\n",
       "  '하악',\n",
       "  '간의',\n",
       "  '거리를',\n",
       "  '나타내는',\n",
       "  '4314300001',\n",
       "  '0652',\n",
       "  '와',\n",
       "  '고중성지방혈증이',\n",
       "  '매우',\n",
       "  '높은',\n",
       "  '연관성을',\n",
       "  '가진',\n",
       "  '것을',\n",
       "  '밝혀냈고',\n",
       "  '이를',\n",
       "  '기반으로',\n",
       "  '구축',\n",
       "  '한',\n",
       "  '모델은',\n",
       "  '0662',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '획득',\n",
       "  '하였다',\n",
       "  '이러한',\n",
       "  '연구결과는',\n",
       "  '향후',\n",
       "  '질병',\n",
       "  '역학',\n",
       "  '및',\n",
       "  '대중',\n",
       "  '보건',\n",
       "  '영역의',\n",
       "  '스크',\n",
       "  '리닝',\n",
       "  '단계에서',\n",
       "  '안면정보만으로',\n",
       "  '다양할',\n",
       "  '질병',\n",
       "  '을',\n",
       "  '예측할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '기반을',\n",
       "  '제',\n",
       "  '공할',\n",
       "  '수',\n",
       "  '있을',\n",
       "  '것이',\n",
       "  '다'],\n",
       " ['가상',\n",
       "  '발전소',\n",
       "  '시장에',\n",
       "  '전력을',\n",
       "  '안정적으로',\n",
       "  '공급',\n",
       "  '하기',\n",
       "  '위해서는',\n",
       "  '발전',\n",
       "  '량에',\n",
       "  '대한',\n",
       "  '정확한',\n",
       "  '예측이',\n",
       "  '필요하다',\n",
       "  '하지만',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량은',\n",
       "  '기상',\n",
       "  '환경에',\n",
       "  '영향을',\n",
       "  '받아',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '편차가',\n",
       "  '심하기',\n",
       "  '때문에',\n",
       "  '안정적',\n",
       "  '인',\n",
       "  '예측이',\n",
       "  '어렵다',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '기반',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델을',\n",
       "  '제안',\n",
       "  '한다',\n",
       "  '우리는',\n",
       "  '기상',\n",
       "  '데이터와',\n",
       "  '기상',\n",
       "  '예보',\n",
       "  '데이터를',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델에',\n",
       "  '입력',\n",
       "  '하여',\n",
       "  '성능을',\n",
       "  '향상',\n",
       "  '시킨다',\n",
       "  '또한',\n",
       "  '상관계수',\n",
       "  '를',\n",
       "  '기준으로',\n",
       "  '우선순위',\n",
       "  '를',\n",
       "  '설정하',\n",
       "  '여',\n",
       "  '변수를',\n",
       "  '선택',\n",
       "  '한다',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '상관관계',\n",
       "  '와',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측',\n",
       "  '결과를',\n",
       "  '비교하여',\n",
       "  '태양광',\n",
       "  '에너지',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측에',\n",
       "  '활용',\n",
       "  '되는',\n",
       "  '최적의',\n",
       "  '기상',\n",
       "  '요인을',\n",
       "  '검토',\n",
       "  '한다'],\n",
       " ['문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '주어진',\n",
       "  '문서로부터',\n",
       "  '주요',\n",
       "  '내용을',\n",
       "  '추출',\n",
       "  '하거나',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '축약',\n",
       "  '하는',\n",
       "  '작업을',\n",
       "  '말',\n",
       "  '한다',\n",
       "  '최근',\n",
       "  '연구에서는',\n",
       "  '대량의',\n",
       "  '문서를',\n",
       "  '딥러닝',\n",
       "  '기법을',\n",
       "  '적용하여',\n",
       "  '요약',\n",
       "  '문',\n",
       "  '자체',\n",
       "  '를',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '발전',\n",
       "  '하고',\n",
       "  '있다',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '미리',\n",
       "  '생성',\n",
       "  '된',\n",
       "  '위드',\n",
       "  '임베딩',\n",
       "  '정보를',\n",
       "  '사용하는데',\n",
       "  '전문',\n",
       "  '용어와',\n",
       "  '같이',\n",
       "  '저빈도',\n",
       "  '핵심',\n",
       "  '어휘',\n",
       "  '는',\n",
       "  '입베딩',\n",
       "  '된',\n",
       "  '사전',\n",
       "  '에',\n",
       "  '없는',\n",
       "  '문제가',\n",
       "  '발생',\n",
       "  '한다',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '신경망',\n",
       "  '모델의',\n",
       "  '문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '에서',\n",
       "  '미등록',\n",
       "  '어휘',\n",
       "  '의',\n",
       "  '출현',\n",
       "  '은',\n",
       "  '요약',\n",
       "  '성능',\n",
       "  '저하',\n",
       "  '의',\n",
       "  '요인',\n",
       "  '이다',\n",
       "  '이를',\n",
       "  '해결',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '요약',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '에서',\n",
       "  '새로',\n",
       "  '출현',\n",
       "  '한',\n",
       "  '단어',\n",
       "  '를',\n",
       "  '복사',\n",
       "  '하여',\n",
       "  '요약',\n",
       "  '문을',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방법을',\n",
       "  '사용',\n",
       "  '한다',\n",
       "  '기존의',\n",
       "  '연구',\n",
       "  '와는',\n",
       "  '달리',\n",
       "  '정확한',\n",
       "  '포인',\n",
       "  '팅',\n",
       "  '정보와',\n",
       "  '선택',\n",
       "  '적',\n",
       "  '복사',\n",
       "  '지시',\n",
       "  '정보를',\n",
       "  '명시적',\n",
       "  '으로',\n",
       "  '제공하는',\n",
       "  '방법으로',\n",
       "  '제안',\n",
       "  '하였다',\n",
       "  '학습',\n",
       "  '데이터는',\n",
       "  '논문의',\n",
       "  '초록과',\n",
       "  '제목을',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '와',\n",
       "  '정답',\n",
       "  '요약',\n",
       "  '으로',\n",
       "  '사용',\n",
       "  '하였다',\n",
       "  '제안한',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '기반',\n",
       "  '모델을',\n",
       "  '통해서',\n",
       "  '자동',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '을',\n",
       "  '수행',\n",
       "  '한',\n",
       "  '결과',\n",
       "  '단어',\n",
       "  '제현',\n",
       "  '기반의',\n",
       "  '1',\n",
       "  '이',\n",
       "  '4701',\n",
       "  '로',\n",
       "  '나타났으며',\n",
       "  '또한',\n",
       "  '어순',\n",
       "  '기반의',\n",
       "  '이',\n",
       "  '2955',\n",
       "  '로',\n",
       "  '향상',\n",
       "  '되었다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3740/3740 [00:00<00:00, 4194.60it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그러므로',\n",
       " '선박,',\n",
       " '빌딩,',\n",
       " '기차,',\n",
       " '비행기',\n",
       " '등',\n",
       " 'Modbus를',\n",
       " '이용하는',\n",
       " '모든',\n",
       " '장비들과',\n",
       " '연결이',\n",
       " '가능하여',\n",
       " '환경변수의',\n",
       " '측정',\n",
       " '및',\n",
       " '원격제어가',\n",
       " '가능하게',\n",
       " '된다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3740/3740 [00:00<00:00, 14217.09it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 자발적 산업표준 통신 프로토콜이다',\n",
       " '그러므로 선박, 빌딩, 기차, 비행기 등 Modbus를 이용하는 모든 장비들과 연결이 가능하여 환경변수의 측정 및 원격제어가 가능하게 된다',\n",
       " '본 논문에서 는 퍼지제어 시스템을 이용하여 외부환경요인을 각각 조합한 불확실한 내용을 정량적인 값으로 변환하여 LED 조명으로 표현하기 위해 알고 리즘을 설계하고, 설계한 알고리즘에 Modbus 통신 프로토콜을 추가하여 선박의 통합관리 시스템에서 외부환경요인 확인 및 원격제어가 가능 한 감성조명용 LED 제어기 회로를 설계 및 구현 하였다',\n",
       " '외부환경요소인 온도, 습도, 조도 값을 센서를 통해 제어기로 받아들이고 이 값들을 퍼지제어 알고리즘을 통해 LED로 표현된다',\n",
       " 'Modbus는 Serial 통신으로 RS485를 이용하여 다른 기기와 연결 되어 온도, 습도, 조도 상태 및 LED 출력 값 확인이 가능하고 또한 사용자가 원격으로 RGB 값을 변경 할 수 있기 때문에 원하는 색으로 변경이 가능하게 된다',\n",
       " '제작한 제 어기로 온도, 습도, 조도에 따라 LED 조명색상이 변화 되는 것을 확인 하였다.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  34\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.831550802139038\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  391\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 19.31136906794128\n",
      "문장 내의 단어 개수 중앙값 : 18.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2805, 20, 200)\n",
      "train_Y_data.shape: (2805, 32)\n",
      "val_X_data.shape: (935, 20, 200)\n",
      "val_Y_data.shape: (935, 32)\n",
      "test_X_data.shape: (935, 20, 200)\n",
      "test_Y_data.shape: (935, 32)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '을': 2,\n",
       " '에': 3,\n",
       " '이': 4,\n",
       " '수': 5,\n",
       " '있다': 6,\n",
       " '하였다': 7,\n",
       " '를': 8,\n",
       " '한다': 9,\n",
       " '하고': 10,\n",
       " '할': 11,\n",
       " '본': 12,\n",
       " '대한': 13,\n",
       " '과': 14,\n",
       " '적': 15,\n",
       " '및': 16,\n",
       " '는': 17,\n",
       " '하는': 18,\n",
       " '있는': 19,\n",
       " '한': 20,\n",
       " '은': 21,\n",
       " '가': 22,\n",
       " '으로': 23,\n",
       " '것이': 24,\n",
       " '와': 25,\n",
       " '위해': 26,\n",
       " '통해': 27,\n",
       " '된': 28,\n",
       " '인': 29,\n",
       " '위한': 30,\n",
       " '로': 31,\n",
       " '인공지능': 32,\n",
       " '분석': 33,\n",
       " '하기': 34,\n",
       " '다': 35,\n",
       " '학습': 36,\n",
       " '들': 37,\n",
       " '이다': 38,\n",
       " '연구': 39,\n",
       " '에서': 40,\n",
       " '그': 41,\n",
       " '활용': 42,\n",
       " '이러한': 43,\n",
       " '다양한': 44,\n",
       " '이를': 45,\n",
       " '4': 46,\n",
       " '하여': 47,\n",
       " '것으로': 48,\n",
       " '교육': 49,\n",
       " '연구는': 50,\n",
       " '기술': 51,\n",
       " '고': 52,\n",
       " '제안': 53,\n",
       " '될': 54,\n",
       " '차': 55,\n",
       " '적용': 56,\n",
       " '또한': 57,\n",
       " '데이터': 58,\n",
       " '개발': 59,\n",
       " '사용': 60,\n",
       " '결과': 61,\n",
       " '된다': 62,\n",
       " '새로운': 63,\n",
       " '산업혁명': 64,\n",
       " '따라': 65,\n",
       " '예측': 66,\n",
       " '되고': 67,\n",
       " '경우': 68,\n",
       " '관련': 69,\n",
       " '도': 70,\n",
       " '되는': 71,\n",
       " '스마트': 72,\n",
       " '연구에서는': 73,\n",
       " '그리고': 74,\n",
       " '정보': 75,\n",
       " '되었다': 76,\n",
       " '기반': 77,\n",
       " '대해': 78,\n",
       " '인간': 79,\n",
       " '제': 80,\n",
       " '등': 81,\n",
       " '논문에서는': 82,\n",
       " '데이터를': 83,\n",
       " '영향을': 84,\n",
       " '제시': 85,\n",
       " '같은': 86,\n",
       " '최근': 87,\n",
       " '이에': 88,\n",
       " '3': 89,\n",
       " '분류': 90,\n",
       " '따라서': 91,\n",
       " '해': 92,\n",
       " '가장': 93,\n",
       " '이용하여': 94,\n",
       " '서': 95,\n",
       " '수행': 96,\n",
       " '확인': 97,\n",
       " '평가': 98,\n",
       " '인간의': 99,\n",
       " '되어': 100,\n",
       " '보다': 101,\n",
       " '사물인터넷': 102,\n",
       " '중': 103,\n",
       " '가지': 104,\n",
       " '연구의': 105,\n",
       " '특히': 106,\n",
       " '지': 107,\n",
       " '성': 108,\n",
       " '위하여': 109,\n",
       " '서비스': 110,\n",
       " '문제': 111,\n",
       " '기존': 112,\n",
       " '2': 113,\n",
       " '정보를': 114,\n",
       " '있었다': 115,\n",
       " '융합': 116,\n",
       " '인식': 117,\n",
       " '미래': 118,\n",
       " '제공': 119,\n",
       " '있으며': 120,\n",
       " '수업': 121,\n",
       " '나타났다': 122,\n",
       " '결과를': 123,\n",
       " '하고자': 124,\n",
       " '발생': 125,\n",
       " '설계': 126,\n",
       " '모델을': 127,\n",
       " '높은': 128,\n",
       " '것을': 129,\n",
       " '더': 130,\n",
       " '핵심': 131,\n",
       " '그러나': 132,\n",
       " '따른': 133,\n",
       " '비교': 134,\n",
       " '많은': 135,\n",
       " '아니라': 136,\n",
       " '방법을': 137,\n",
       " '대상으로': 138,\n",
       " '사회': 139,\n",
       " '관한': 140,\n",
       " '기존의': 141,\n",
       " '여': 142,\n",
       " '디자인': 143,\n",
       " '증가': 144,\n",
       " '진행': 145,\n",
       " '생성': 146,\n",
       " '해결': 147,\n",
       " '등의': 148,\n",
       " '산업': 149,\n",
       " '해야': 150,\n",
       " '기술의': 151,\n",
       " '각': 152,\n",
       " '인공지능의': 153,\n",
       " '기반으로': 154,\n",
       " '실험': 155,\n",
       " '변화': 156,\n",
       " '현재': 157,\n",
       " '구성': 158,\n",
       " '있을': 159,\n",
       " '하였으며': 160,\n",
       " '성능을': 161,\n",
       " '다른': 162,\n",
       " '에서는': 163,\n",
       " '발전': 164,\n",
       " '빅데이터': 165,\n",
       " '통한': 166,\n",
       " '기반의': 167,\n",
       " '1': 168,\n",
       " '바탕으로': 169,\n",
       " '딥러닝': 170,\n",
       " '활용하여': 171,\n",
       " '실제': 172,\n",
       " '연구가': 173,\n",
       " '미치는': 174,\n",
       " '문제를': 175,\n",
       " '기술을': 176,\n",
       " '등을': 177,\n",
       " '통하여': 178,\n",
       " '때': 179,\n",
       " '활용한': 180,\n",
       " '위해서는': 181,\n",
       " '개선': 182,\n",
       " '분석을': 183,\n",
       " '둘째': 184,\n",
       " '첫째': 185,\n",
       " '논문은': 186,\n",
       " '때문에': 187,\n",
       " '디지털': 188,\n",
       " '중요한': 189,\n",
       " '검토': 190,\n",
       " '수집': 191,\n",
       " '이용한': 192,\n",
       " '공학': 193,\n",
       " '의미': 194,\n",
       " '향후': 195,\n",
       " '필요': 196,\n",
       " '음악': 197,\n",
       " '논의': 198,\n",
       " '중심으로': 199,\n",
       " '도출': 200,\n",
       " '며': 201,\n",
       " '향상': 202,\n",
       " '이용': 203,\n",
       " '사회적': 204,\n",
       " '접근': 205,\n",
       " '후': 206,\n",
       " '시스템을': 207,\n",
       " '개의': 208,\n",
       " '연구를': 209,\n",
       " '간': 210,\n",
       " '했다': 211,\n",
       " '화': 212,\n",
       " '하지만': 213,\n",
       " '에는': 214,\n",
       " '필요하다': 215,\n",
       " '검증': 216,\n",
       " '에게': 217,\n",
       " '구축': 218,\n",
       " '주요': 219,\n",
       " '자': 220,\n",
       " '개': 221,\n",
       " '네트워크': 222,\n",
       " '사용자': 223,\n",
       " '필요한': 224,\n",
       " '있어': 225,\n",
       " '두': 226,\n",
       " '관리': 227,\n",
       " '기계학습': 228,\n",
       " '있도록': 229,\n",
       " '기초': 230,\n",
       " '이는': 231,\n",
       " '국내': 232,\n",
       " '시스템': 233,\n",
       " '하는데': 234,\n",
       " '이나': 235,\n",
       " '여러': 236,\n",
       " '인공지능이': 237,\n",
       " '다음': 238,\n",
       " '기법을': 239,\n",
       " '사물': 240,\n",
       " '것은': 241,\n",
       " '함께': 242,\n",
       " '존재': 243,\n",
       " '함으로써': 244,\n",
       " '교육의': 245,\n",
       " '한국': 246,\n",
       " '교수': 247,\n",
       " '하였고': 248,\n",
       " '과학': 249,\n",
       " '개인': 250,\n",
       " '측정': 251,\n",
       " '방안을': 252,\n",
       " '고려': 253,\n",
       " '나': 254,\n",
       " '판단': 255,\n",
       " '성능': 256,\n",
       " '법적': 257,\n",
       " '매우': 258,\n",
       " '관련된': 259,\n",
       " '알고리즘': 260,\n",
       " '어떻게': 261,\n",
       " '대하여': 262,\n",
       " '로봇': 263,\n",
       " '구현': 264,\n",
       " '하며': 265,\n",
       " '셋째': 266,\n",
       " '큰': 267,\n",
       " '모든': 268,\n",
       " '지식': 269,\n",
       " '있다는': 270,\n",
       " '도입': 271,\n",
       " '이미지': 272,\n",
       " '또는': 273,\n",
       " '인해': 274,\n",
       " '보안': 275,\n",
       " '운영': 276,\n",
       " '처리': 277,\n",
       " '되어야': 278,\n",
       " '개인정보': 279,\n",
       " '변화를': 280,\n",
       " '조사': 281,\n",
       " '지원': 282,\n",
       " '형': 283,\n",
       " '대학': 284,\n",
       " '요구': 285,\n",
       " '기계': 286,\n",
       " '특성을': 287,\n",
       " '데이터의': 288,\n",
       " '사용하여': 289,\n",
       " '탐색': 290,\n",
       " '알고리즘을': 291,\n",
       " '생각': 292,\n",
       " '실시': 293,\n",
       " '지능': 294,\n",
       " '연결': 295,\n",
       " '있어서': 296,\n",
       " '하면서': 297,\n",
       " '방법': 298,\n",
       " '개념': 299,\n",
       " '해당': 300,\n",
       " '센서': 301,\n",
       " '가능한': 302,\n",
       " '5': 303,\n",
       " '적용하여': 304,\n",
       " '특징': 305,\n",
       " '가능성을': 306,\n",
       " '환경': 307,\n",
       " '있음을': 308,\n",
       " '대': 309,\n",
       " '사전': 310,\n",
       " '영상': 311,\n",
       " '선택': 312,\n",
       " '게': 313,\n",
       " '확장': 314,\n",
       " '간의': 315,\n",
       " '국가': 316,\n",
       " '있고': 317,\n",
       " '인공지능에': 318,\n",
       " '없는': 319,\n",
       " '인터넷': 320,\n",
       " '통합': 321,\n",
       " '대응': 322,\n",
       " '과정에서': 323,\n",
       " '이고': 324,\n",
       " '현실': 325,\n",
       " '보였다': 326,\n",
       " '모두': 327,\n",
       " '이해': 328,\n",
       " '하지': 329,\n",
       " '결과는': 330,\n",
       " '역할을': 331,\n",
       " '관점에서': 332,\n",
       " '기술이': 333,\n",
       " '소프트웨어': 334,\n",
       " '모델': 335,\n",
       " '즉': 336,\n",
       " '비해': 337,\n",
       " '감성': 338,\n",
       " '참여': 339,\n",
       " '표현': 340,\n",
       " '시': 341,\n",
       " '포함': 342,\n",
       " '규제': 343,\n",
       " '에서의': 344,\n",
       " '학교': 345,\n",
       " '보호': 346,\n",
       " '인공지능을': 347,\n",
       " '인지': 348,\n",
       " '서비스를': 349,\n",
       " '의한': 350,\n",
       " '프로그램': 351,\n",
       " '내용': 352,\n",
       " '텍스트': 353,\n",
       " '일반': 354,\n",
       " '정의': 355,\n",
       " '등장': 356,\n",
       " '모형을': 357,\n",
       " '문제점': 358,\n",
       " '생산': 359,\n",
       " '경험': 360,\n",
       " '제안하는': 361,\n",
       " '체계': 362,\n",
       " '만': 363,\n",
       " '분야에서': 364,\n",
       " '데': 365,\n",
       " '부터': 366,\n",
       " '라는': 367,\n",
       " '자료를': 368,\n",
       " '전공': 369,\n",
       " '기능': 370,\n",
       " '이와': 371,\n",
       " '추출': 372,\n",
       " '과정을': 373,\n",
       " '심층': 374,\n",
       " '전체': 375,\n",
       " '연구에서': 376,\n",
       " '시스템의': 377,\n",
       " '까지': 378,\n",
       " '의해': 379,\n",
       " '정책': 380,\n",
       " '목적은': 381,\n",
       " '활동': 382,\n",
       " '컴퓨터': 383,\n",
       " '확보': 384,\n",
       " '결정': 385,\n",
       " '설명': 386,\n",
       " '크게': 387,\n",
       " '볼': 388,\n",
       " '모델의': 389,\n",
       " '상호작용': 390,\n",
       " '이며': 391,\n",
       " '때문': 392,\n",
       " '어떤': 393,\n",
       " '환경에서': 394,\n",
       " '자기': 395,\n",
       " '가지고': 396,\n",
       " '세': 397,\n",
       " '역량': 398,\n",
       " '전': 399,\n",
       " '중심': 400,\n",
       " '더욱': 401,\n",
       " '뿐': 402,\n",
       " '사용자의': 403,\n",
       " '상황': 404,\n",
       " '한계': 405,\n",
       " '창의적': 406,\n",
       " '제품': 407,\n",
       " '우리': 408,\n",
       " '먼저': 409,\n",
       " '분야': 410,\n",
       " '의료': 411,\n",
       " '학년': 412,\n",
       " '온라인': 413,\n",
       " '확대': 414,\n",
       " '세계': 415,\n",
       " '측면에서': 416,\n",
       " '예술': 417,\n",
       " '교육을': 418,\n",
       " '이라는': 419,\n",
       " '전문가': 420,\n",
       " '인간과': 421,\n",
       " '특성': 422,\n",
       " '콘텐츠': 423,\n",
       " '시대에': 424,\n",
       " '행동': 425,\n",
       " '효과를': 426,\n",
       " '정확도를': 427,\n",
       " '관계': 428,\n",
       " '사고': 429,\n",
       " '머신러닝': 430,\n",
       " '점에서': 431,\n",
       " '분야의': 432,\n",
       " '디바이스': 433,\n",
       " '한다는': 434,\n",
       " '시도': 435,\n",
       " '모바일': 436,\n",
       " '교과': 437,\n",
       " '총': 438,\n",
       " '내용을': 439,\n",
       " '제작': 440,\n",
       " '탐지': 441,\n",
       " '분석하여': 442,\n",
       " '야': 443,\n",
       " '문화': 444,\n",
       " '공간': 445,\n",
       " '관계를': 446,\n",
       " '평균': 447,\n",
       " '마련': 448,\n",
       " '자료': 449,\n",
       " '인공지능과': 450,\n",
       " '같다': 451,\n",
       " '입력': 452,\n",
       " '구': 453,\n",
       " '문제가': 454,\n",
       " '자동': 455,\n",
       " '학생들의': 456,\n",
       " '직접': 457,\n",
       " '토대로': 458,\n",
       " '영향': 459,\n",
       " '학생': 460,\n",
       " '등이': 461,\n",
       " '제공하는': 462,\n",
       " '기술적': 463,\n",
       " '시대의': 464,\n",
       " '않은': 465,\n",
       " '차이가': 466,\n",
       " '제안한': 467,\n",
       " '파악': 468,\n",
       " '이상': 469,\n",
       " '이후': 470,\n",
       " '우리나라': 471,\n",
       " '하게': 472,\n",
       " '시작': 473,\n",
       " '제안된': 474,\n",
       " '현': 475,\n",
       " '유의': 476,\n",
       " '학습을': 477,\n",
       " '방향을': 478,\n",
       " '감정': 479,\n",
       " '형성': 480,\n",
       " '신경망': 481,\n",
       " '별': 482,\n",
       " '많이': 483,\n",
       " '같이': 484,\n",
       " '사이버': 485,\n",
       " '위치': 486,\n",
       " '동시에': 487,\n",
       " '인한': 488,\n",
       " '되지': 489,\n",
       " '화된': 490,\n",
       " '기업': 491,\n",
       " '프로그램을': 492,\n",
       " '측면': 493,\n",
       " '에도': 494,\n",
       " '혁신': 495,\n",
       " '방법은': 496,\n",
       " '유형': 497,\n",
       " '적합한': 498,\n",
       " '실험을': 499,\n",
       " '변화에': 500,\n",
       " '교사': 501,\n",
       " '시스템은': 502,\n",
       " '법률': 503,\n",
       " '플랫폼': 504,\n",
       " '연계': 505,\n",
       " '영역': 506,\n",
       " '기대': 507,\n",
       " '사례를': 508,\n",
       " '마지막으로': 509,\n",
       " '의사결정': 510,\n",
       " '이루어지': 511,\n",
       " '어떠한': 512,\n",
       " '상호': 513,\n",
       " '상': 514,\n",
       " '선정': 515,\n",
       " '설정': 516,\n",
       " '제어': 517,\n",
       " '면': 518,\n",
       " '개별': 519,\n",
       " '가치': 520,\n",
       " '등에': 521,\n",
       " '고찰': 522,\n",
       " '알': 523,\n",
       " '통신': 524,\n",
       " '단어': 525,\n",
       " '기능을': 526,\n",
       " '관련하여': 527,\n",
       " '컴퓨팅': 528,\n",
       " '스마트폰': 529,\n",
       " '언어': 530,\n",
       " '전문': 531,\n",
       " '특정': 532,\n",
       " '시킬': 533,\n",
       " '계산': 534,\n",
       " '인공지능은': 535,\n",
       " '결합': 536,\n",
       " '우선': 537,\n",
       " '교수학습': 538,\n",
       " '과제': 539,\n",
       " '수학': 540,\n",
       " '었다': 541,\n",
       " '학습자': 542,\n",
       " '더불어': 543,\n",
       " '로봇의': 544,\n",
       " '발달': 545,\n",
       " '능력': 546,\n",
       " '점을': 547,\n",
       " '있지만': 548,\n",
       " '내': 549,\n",
       " '감소': 550,\n",
       " '모형': 551,\n",
       " '시간': 552,\n",
       " '인공': 553,\n",
       " '창의성': 554,\n",
       " '문장': 555,\n",
       " '모색': 556,\n",
       " '중국': 557,\n",
       " '방식을': 558,\n",
       " '책임': 559,\n",
       " '라고': 560,\n",
       " '금융': 561,\n",
       " '않고': 562,\n",
       " '분야에': 563,\n",
       " '글쓰기': 564,\n",
       " '보인다': 565,\n",
       " '발생하는': 566,\n",
       " '효과적인': 567,\n",
       " '전자': 568,\n",
       " '구조': 569,\n",
       " '특징을': 570,\n",
       " '없이': 571,\n",
       " '차원': 572,\n",
       " '나아가': 573,\n",
       " '지능형': 574,\n",
       " '협력': 575,\n",
       " '가치를': 576,\n",
       " '응용': 577,\n",
       " '효과적으로': 578,\n",
       " '공유': 579,\n",
       " '부분': 580,\n",
       " '검색': 581,\n",
       " '확인할': 582,\n",
       " '아닌': 583,\n",
       " '기술은': 584,\n",
       " '없다': 585,\n",
       " '소비자': 586,\n",
       " '에서도': 587,\n",
       " '권리': 588,\n",
       " '시대': 589,\n",
       " '주로': 590,\n",
       " '교육과정': 591,\n",
       " '자동차': 592,\n",
       " '클라우드': 593,\n",
       " '기본': 594,\n",
       " '위험': 595,\n",
       " '검출': 596,\n",
       " '사례': 597,\n",
       " '단계': 598,\n",
       " '약': 599,\n",
       " '살펴보았다': 600,\n",
       " '러닝': 601,\n",
       " '하도록': 602,\n",
       " '능력을': 603,\n",
       " '하거나': 604,\n",
       " '잘': 605,\n",
       " '목적으로': 606,\n",
       " '성과': 607,\n",
       " '우리는': 608,\n",
       " '가상': 609,\n",
       " '중심의': 610,\n",
       " '윤리적': 611,\n",
       " '확산': 612,\n",
       " '정보의': 613,\n",
       " '윤리': 614,\n",
       " '과의': 615,\n",
       " '함에': 616,\n",
       " '있게': 617,\n",
       " '기술과': 618,\n",
       " '목적을': 619,\n",
       " '탐구': 620,\n",
       " '학생들이': 621,\n",
       " '진행되고': 622,\n",
       " '효과': 623,\n",
       " '혹은': 624,\n",
       " '미국': 625,\n",
       " '모델은': 626,\n",
       " '인간이': 627,\n",
       " '않는': 628,\n",
       " '고려하여': 629,\n",
       " '력': 630,\n",
       " '강조': 631,\n",
       " '과학기술': 632,\n",
       " '수용': 633,\n",
       " '시사점을': 634,\n",
       " '산업의': 635,\n",
       " '방법으로': 636,\n",
       " '목적': 637,\n",
       " '영화': 638,\n",
       " '인정': 639,\n",
       " '개인의': 640,\n",
       " '역할': 641,\n",
       " '객체': 642,\n",
       " '반영': 643,\n",
       " '추정': 644,\n",
       " '블록체인': 645,\n",
       " '스스로': 646,\n",
       " '6': 647,\n",
       " '현대': 648,\n",
       " '통해서': 649,\n",
       " '차량': 650,\n",
       " '창작': 651,\n",
       " '좋은': 652,\n",
       " '주장': 653,\n",
       " '활성화': 654,\n",
       " '중에서': 655,\n",
       " '기법': 656,\n",
       " '사용하는': 657,\n",
       " '연구결과': 658,\n",
       " '서로': 659,\n",
       " '요소를': 660,\n",
       " '실시간': 661,\n",
       " '진단': 662,\n",
       " '하면': 663,\n",
       " '강화': 664,\n",
       " '실행': 665,\n",
       " '문제해결': 666,\n",
       " '양성': 667,\n",
       " '과정': 668,\n",
       " '분석한': 669,\n",
       " '이런': 670,\n",
       " '방법이': 671,\n",
       " '모니터링': 672,\n",
       " '요소': 673,\n",
       " '사': 674,\n",
       " '속에서': 675,\n",
       " '상태': 676,\n",
       " '주목': 677,\n",
       " '향상을': 678,\n",
       " '역량을': 679,\n",
       " '이들': 680,\n",
       " '있다고': 681,\n",
       " '이론적': 682,\n",
       " '식': 683,\n",
       " '집중': 684,\n",
       " '이미': 685,\n",
       " '아직': 686,\n",
       " '추가': 687,\n",
       " '안전': 688,\n",
       " '개념을': 689,\n",
       " '한국어': 690,\n",
       " '평가를': 691,\n",
       " '줄': 692,\n",
       " '한편': 693,\n",
       " '유의미한': 694,\n",
       " '기업의': 695,\n",
       " '대상': 696,\n",
       " '가능성이': 697,\n",
       " '개발된': 698,\n",
       " '학습자의': 699,\n",
       " '하나의': 700,\n",
       " '있기': 701,\n",
       " '종합': 702,\n",
       " '웹': 703,\n",
       " '활용하는': 704,\n",
       " '접목': 705,\n",
       " '경제': 706,\n",
       " '시각': 707,\n",
       " '첨단': 708,\n",
       " '빅': 709,\n",
       " '현장': 710,\n",
       " '보조공학': 711,\n",
       " '가진': 712,\n",
       " '초기': 713,\n",
       " '되기': 714,\n",
       " '드론': 715,\n",
       " '모형의': 716,\n",
       " '교육에': 717,\n",
       " '개정': 718,\n",
       " '프로젝트': 719,\n",
       " '추천': 720,\n",
       " '창의': 721,\n",
       " '시장': 722,\n",
       " '각각': 723,\n",
       " '지역': 724,\n",
       " '것인지': 725,\n",
       " '자신의': 726,\n",
       " '변화가': 727,\n",
       " '주제': 728,\n",
       " '진로': 729,\n",
       " '구분': 730,\n",
       " '법': 731,\n",
       " '데이터에': 732,\n",
       " '기대한다': 733,\n",
       " '체험': 734,\n",
       " '우수한': 735,\n",
       " '배경': 736,\n",
       " '창출': 737,\n",
       " '어려운': 738,\n",
       " '방식으로': 739,\n",
       " '효율적인': 740,\n",
       " '실현': 741,\n",
       " '논문에서': 742,\n",
       " '되었으며': 743,\n",
       " '장애': 744,\n",
       " '대학의': 745,\n",
       " '낮은': 746,\n",
       " '불구하고': 747,\n",
       " '갖는': 748,\n",
       " '살펴보고': 749,\n",
       " '에너지': 750,\n",
       " '적절한': 751,\n",
       " '대비': 752,\n",
       " '한계를': 753,\n",
       " '데이터가': 754,\n",
       " '의미를': 755,\n",
       " '물론': 756,\n",
       " '통계적': 757,\n",
       " '보완': 758,\n",
       " '높게': 759,\n",
       " '예상': 760,\n",
       " '유사한': 761,\n",
       " '관점': 762,\n",
       " '국제': 763,\n",
       " '수정': 764,\n",
       " '교육이': 765,\n",
       " '자동화': 766,\n",
       " '달성': 767,\n",
       " '집단': 768,\n",
       " '도덕': 769,\n",
       " '왔다': 770,\n",
       " '기술에': 771,\n",
       " '전송': 772,\n",
       " '공공': 773,\n",
       " '앞으로': 774,\n",
       " '쟁점': 775,\n",
       " '수업을': 776,\n",
       " '해석': 777,\n",
       " '사회의': 778,\n",
       " '상황에서': 779,\n",
       " '수집된': 780,\n",
       " '아니': 781,\n",
       " '시뮬레이션': 782,\n",
       " '효율적으로': 783,\n",
       " '사람': 784,\n",
       " '대체': 785,\n",
       " '미디어': 786,\n",
       " '발견': 787,\n",
       " '명의': 788,\n",
       " '교육적': 789,\n",
       " '형태의': 790,\n",
       " '전통적인': 791,\n",
       " '부여': 792,\n",
       " '다중': 793,\n",
       " '서비스의': 794,\n",
       " '환경을': 795,\n",
       " '영역에서': 796,\n",
       " '추론': 797,\n",
       " '달리': 798,\n",
       " '필요성': 799,\n",
       " '형태로': 800,\n",
       " '하여야': 801,\n",
       " '최적화': 802,\n",
       " '되면서': 803,\n",
       " '차이를': 804,\n",
       " '유지': 805,\n",
       " '뿐만': 806,\n",
       " '패턴': 807,\n",
       " '관심이': 808,\n",
       " '설치': 809,\n",
       " '역시': 810,\n",
       " '구체적으로': 811,\n",
       " '방법에': 812,\n",
       " '피드백': 813,\n",
       " '지만': 814,\n",
       " '지식을': 815,\n",
       " '최종': 816,\n",
       " '그에': 817,\n",
       " '소통': 818,\n",
       " '포스트휴먼': 819,\n",
       " '기기': 820,\n",
       " '전망': 821,\n",
       " '신체': 822,\n",
       " '요인': 823,\n",
       " '노력': 824,\n",
       " '사이의': 825,\n",
       " '영역을': 826,\n",
       " '수준': 827,\n",
       " '등으로': 828,\n",
       " '10': 829,\n",
       " '이상의': 830,\n",
       " '도움이': 831,\n",
       " '으로는': 832,\n",
       " '생활': 833,\n",
       " '구체적인': 834,\n",
       " '상황을': 835,\n",
       " '발전에': 836,\n",
       " '넷째': 837,\n",
       " '있으나': 838,\n",
       " '소개': 839,\n",
       " '개발을': 840,\n",
       " '작성': 841,\n",
       " '긍정적인': 842,\n",
       " '침해': 843,\n",
       " '본질': 844,\n",
       " '전략을': 845,\n",
       " '무선': 846,\n",
       " '수준의': 847,\n",
       " '하나인': 848,\n",
       " '명을': 849,\n",
       " '식별': 850,\n",
       " '속': 851,\n",
       " '문제에': 852,\n",
       " '검사': 853,\n",
       " '논의가': 854,\n",
       " '만을': 855,\n",
       " '새롭게': 856,\n",
       " '계': 857,\n",
       " '게임': 858,\n",
       " '인하여': 859,\n",
       " '문서': 860,\n",
       " '현행': 861,\n",
       " '방식': 862,\n",
       " '우리의': 863,\n",
       " '연구에': 864,\n",
       " '것에': 865,\n",
       " '실천': 866,\n",
       " '빠르게': 867,\n",
       " '이용해': 868,\n",
       " '챗봇': 869,\n",
       " '속성': 870,\n",
       " '국내외': 871,\n",
       " '전략': 872,\n",
       " '활용되고': 873,\n",
       " '인식을': 874,\n",
       " '의의': 875,\n",
       " '대표적인': 876,\n",
       " '번째': 877,\n",
       " '추진': 878,\n",
       " '경제적': 879,\n",
       " '사용자가': 880,\n",
       " '점이': 881,\n",
       " '응답': 882,\n",
       " '시켜': 883,\n",
       " '지속적으로': 884,\n",
       " '대해서는': 885,\n",
       " '하나': 886,\n",
       " '군집': 887,\n",
       " '현재의': 888,\n",
       " '도시': 889,\n",
       " '관심을': 890,\n",
       " '근거': 891,\n",
       " '보았다': 892,\n",
       " '직업': 893,\n",
       " '선행': 894,\n",
       " '논의를': 895,\n",
       " '기': 896,\n",
       " '변수': 897,\n",
       " '특허': 898,\n",
       " '되며': 899,\n",
       " '의사소통': 900,\n",
       " '않다': 901,\n",
       " '제한': 902,\n",
       " '파악하고': 903,\n",
       " '데이터는': 904,\n",
       " '알고리즘의': 905,\n",
       " '작동': 906,\n",
       " '도로': 907,\n",
       " '방법의': 908,\n",
       " '실정': 909,\n",
       " '표준': 910,\n",
       " '구조를': 911,\n",
       " '긍정적': 912,\n",
       " '과거': 913,\n",
       " '주는': 914,\n",
       " '대부분': 915,\n",
       " '함을': 916,\n",
       " '진화': 917,\n",
       " '문제는': 918,\n",
       " '하려는': 919,\n",
       " '도덕적': 920,\n",
       " '반면': 921,\n",
       " '중요하다': 922,\n",
       " '경험을': 923,\n",
       " '상대적으로': 924,\n",
       " '딥': 925,\n",
       " '작업': 926,\n",
       " '전력': 927,\n",
       " '저장': 928,\n",
       " '동작': 929,\n",
       " '인공신경망': 930,\n",
       " '필요성이': 931,\n",
       " '테스트': 932,\n",
       " '생명': 933,\n",
       " '도출하': 934,\n",
       " '환경에': 935,\n",
       " '목적이': 936,\n",
       " '시키기': 937,\n",
       " '성능이': 938,\n",
       " '지적': 939,\n",
       " '활발히': 940,\n",
       " '오늘날': 941,\n",
       " '마음': 942,\n",
       " '자연': 943,\n",
       " '테크놀로지': 944,\n",
       " '규정': 945,\n",
       " '오류': 946,\n",
       " '정확한': 947,\n",
       " '것': 948,\n",
       " '훈련': 949,\n",
       " '목표': 950,\n",
       " '증대': 951,\n",
       " '이미지를': 952,\n",
       " '값을': 953,\n",
       " '어느': 954,\n",
       " '보장': 955,\n",
       " '논문': 956,\n",
       " '일부': 957,\n",
       " '으로서': 958,\n",
       " '실시간으로': 959,\n",
       " '프라이버시': 960,\n",
       " '받고': 961,\n",
       " '학습에': 962,\n",
       " '보다는': 963,\n",
       " '시대를': 964,\n",
       " '포함한': 965,\n",
       " '인성': 966,\n",
       " '교육공학': 967,\n",
       " '공할': 968,\n",
       " '20': 969,\n",
       " '기반한': 970,\n",
       " '웨어러블': 971,\n",
       " '시키는': 972,\n",
       " '서버': 973,\n",
       " '준비': 974,\n",
       " '기준': 975,\n",
       " '되었고': 976,\n",
       " '촉진': 977,\n",
       " '시키고': 978,\n",
       " '인간을': 979,\n",
       " '번역': 980,\n",
       " '프로그래밍': 981,\n",
       " '분석하는': 982,\n",
       " '문헌': 983,\n",
       " '수도': 984,\n",
       " '영역에': 985,\n",
       " '자율': 986,\n",
       " '점': 987,\n",
       " '제조': 988,\n",
       " '고려한': 989,\n",
       " '현장에서': 990,\n",
       " '파악하': 991,\n",
       " '입법': 992,\n",
       " '증강현실': 993,\n",
       " '야기': 994,\n",
       " '도움을': 995,\n",
       " '계획': 996,\n",
       " '책임을': 997,\n",
       " '갖고': 998,\n",
       " '투자': 999,\n",
       " '비교하여': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41225 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x299e1012348>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2805 samples, validate on 935 samples\n",
      "Epoch 1/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 2.3957 - val_loss: 2.8475\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_ls32_v2_01_2.84753.h5\n",
      "Epoch 2/30\n",
      "2805/2805 [==============================] - 74s 27ms/step - loss: 1.4936 - val_loss: 1.7468\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_ls32_v2_02_1.74680.h5\n",
      "Epoch 3/30\n",
      "2805/2805 [==============================] - 74s 27ms/step - loss: 1.2915 - val_loss: 1.3395\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_ls32_v2_03_1.33954.h5\n",
      "Epoch 4/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.2222 - val_loss: 1.0953\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_ls32_v2_04_1.09527.h5\n",
      "Epoch 5/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.2048 - val_loss: 1.0569\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_ls32_v2_05_1.05694.h5\n",
      "Epoch 6/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.1439 - val_loss: 1.0447\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_ls32_v2_06_1.04467.h5\n",
      "Epoch 7/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.1176 - val_loss: 1.1738\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_ls32_v2_07_1.17378.h5\n",
      "Epoch 8/30\n",
      "2805/2805 [==============================] - 74s 26ms/step - loss: 1.1050 - val_loss: 1.3812\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_ls32_v2_08_1.38120.h5\n",
      "Epoch 9/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 1.0468 - val_loss: 1.0488\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_ls32_v2_09_1.04882.h5\n",
      "Epoch 10/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.0053 - val_loss: 1.0899\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_ls32_v2_10_1.08989.h5\n",
      "Epoch 11/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.9762 - val_loss: 1.0318\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_ls32_v2_11_1.03181.h5\n",
      "Epoch 12/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.9558 - val_loss: 1.0899\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_rae_ls32_v2_12_1.08995.h5\n",
      "Epoch 13/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.9267 - val_loss: 1.0126\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_rae_ls32_v2_13_1.01260.h5\n",
      "Epoch 14/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.8628 - val_loss: 1.0262\n",
      "\n",
      "Epoch 00014: saving model to ./save_models/han_rae_ls32_v2_14_1.02620.h5\n",
      "Epoch 15/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.8335 - val_loss: 1.0438\n",
      "\n",
      "Epoch 00015: saving model to ./save_models/han_rae_ls32_v2_15_1.04385.h5\n",
      "Epoch 16/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.8152 - val_loss: 1.0246\n",
      "\n",
      "Epoch 00016: saving model to ./save_models/han_rae_ls32_v2_16_1.02460.h5\n",
      "Epoch 17/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.7723 - val_loss: 1.0716\n",
      "\n",
      "Epoch 00017: saving model to ./save_models/han_rae_ls32_v2_17_1.07159.h5\n",
      "Epoch 18/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.7376 - val_loss: 1.0505\n",
      "\n",
      "Epoch 00018: saving model to ./save_models/han_rae_ls32_v2_18_1.05054.h5\n",
      "time : 1357.606252670288\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(32)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_ls32_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4364000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1632      \n",
      "=================================================================\n",
      "Total params: 4,712,982\n",
      "Trainable params: 589,982\n",
      "Non-trainable params: 4,123,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_ls32_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_ls32_v2_13_1.01260.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0268135700633818"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2059464 , 1.0061374 , 3.0679789 , ..., 0.8893148 , 0.52476096,\n",
       "        1.2751282 ],\n",
       "       [1.6988945 , 1.8856325 , 3.0079417 , ..., 1.1612796 , 1.0843785 ,\n",
       "        1.843551  ],\n",
       "       [2.7079678 , 1.5195215 , 2.5486298 , ..., 0.8632359 , 1.2943883 ,\n",
       "        1.333095  ],\n",
       "       ...,\n",
       "       [2.4840503 , 1.7110479 , 2.6175103 , ..., 1.0519266 , 1.1289648 ,\n",
       "        1.2943443 ],\n",
       "       [2.6840994 , 2.4023824 , 3.3900805 , ..., 1.4196709 , 0.81447697,\n",
       "        1.7536443 ],\n",
       "       [2.102539  , 1.1205896 , 2.8470774 , ..., 0.88432914, 0.7598258 ,\n",
       "        1.3885909 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_ls32_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.49800256e-07, 2.97177053e-07, 1.55021285e-03, ...,\n",
       "        1.22088910e-11, 5.61870661e-10, 2.49752566e-06],\n",
       "       [2.49132785e-21, 5.63941960e-13, 1.09766074e-23, ...,\n",
       "        8.62132021e-14, 1.99023047e-17, 6.12471007e-09],\n",
       "       [8.22711083e-12, 6.95611846e-10, 1.58482644e-17, ...,\n",
       "        1.55777420e-12, 2.60818957e-15, 8.87333540e-10],\n",
       "       ...,\n",
       "       [6.29411684e-14, 2.20860778e-11, 2.71747267e-05, ...,\n",
       "        4.95194288e-17, 9.04842867e-11, 1.94355408e-07],\n",
       "       [6.60478229e-16, 2.01347133e-10, 4.22592655e-11, ...,\n",
       "        5.68620621e-18, 5.87404257e-13, 2.64726737e-07],\n",
       "       [7.81798792e-11, 1.48179546e-09, 4.21956287e-07, ...,\n",
       "        2.20206462e-13, 3.83407802e-12, 1.44906642e-06]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3D프린팅</th>\n",
       "      <th>4차산업</th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>STEAM교육</th>\n",
       "      <th>가상현실</th>\n",
       "      <th>감성</th>\n",
       "      <th>감성분석</th>\n",
       "      <th>감정</th>\n",
       "      <th>강한인공지능</th>\n",
       "      <th>강화학습</th>\n",
       "      <th>...</th>\n",
       "      <th>핀테크</th>\n",
       "      <th>학습</th>\n",
       "      <th>학습동기</th>\n",
       "      <th>학습성과</th>\n",
       "      <th>학업성취도</th>\n",
       "      <th>합성곱신경망</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>헬스케어</th>\n",
       "      <th>혁신</th>\n",
       "      <th>협업</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3D프린팅  4차산업  4차산업혁명  STEAM교육  가상현실  감성  감성분석  감정  강한인공지능  강화학습  ...  핀테크  \\\n",
       "0        0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "1        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "2        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "3        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "4        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "..     ...   ...     ...      ...   ...  ..   ...  ..     ...   ...  ...  ...   \n",
       "930      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "931      0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "932      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "933      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "934      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "\n",
       "     학습  학습동기  학습성과  학업성취도  합성곱신경망  핵심역량  헬스케어  혁신  협업  \n",
       "0     0     0     0      0       0     0     0   0   0  \n",
       "1     0     0     0      0       0     0     0   0   0  \n",
       "2     0     0     0      0       0     0     0   0   0  \n",
       "3     0     0     0      0       0     0     0   0   0  \n",
       "4     0     0     0      0       0     0     0   0   0  \n",
       "..   ..   ...   ...    ...     ...   ...   ...  ..  ..  \n",
       "930   0     0     0      0       0     0     0   0   0  \n",
       "931   0     0     0      0       0     0     0   0   0  \n",
       "932   0     0     0      0       0     0     0   0   0  \n",
       "933   0     0     0      0       0     0     0   0   0  \n",
       "934   0     0     0      0       0     0     0   0   0  \n",
       "\n",
       "[935 rows x 262 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/paper_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(935, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.09090909090909091\n",
      "precision :  0.6098765432098765\n",
      "recall :  0.14870559903672487\n",
      "f1 :  0.23910939012584706\n",
      "------------------------\n",
      "hamming_loss :  0.006417112299465241\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.09090909090909091\n",
      "precision :  0.26149732620320854\n",
      "recall :  0.1603565062388592\n",
      "f1 :  0.18814871403106695\n",
      "------------------------\n",
      "hamming_loss :  0.006417112299465241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ccf08da81ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wrong example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m attention_extractor = Model(inputs=[document_input],\n\u001b[0m\u001b[0;32m      3\u001b[0m                             outputs=[word_attention, sentence_attention])\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_input' is not defined"
     ]
    }
   ],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
