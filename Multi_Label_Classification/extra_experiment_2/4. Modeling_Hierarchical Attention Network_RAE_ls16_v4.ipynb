{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6259488551031149848\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8727519614949257164\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12765936875594633957\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13242959197136218243\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_ls16_v1_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_ls16_v1_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_ls16_v1_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...</td>\n",
       "      <td>7.400500</td>\n",
       "      <td>0.793967</td>\n",
       "      <td>2.494239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.407842</td>\n",
       "      <td>6.835240</td>\n",
       "      <td>5.448450</td>\n",
       "      <td>3.640915</td>\n",
       "      <td>5.075698</td>\n",
       "      <td>2.362760</td>\n",
       "      <td>4.594933</td>\n",
       "      <td>4.380576</td>\n",
       "      <td>5.947162</td>\n",
       "      <td>1.284449</td>\n",
       "      <td>4.938036</td>\n",
       "      <td>1.547717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.966697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.120683</td>\n",
       "      <td>1.474833</td>\n",
       "      <td>1.177635</td>\n",
       "      <td>1.103740</td>\n",
       "      <td>3.678716</td>\n",
       "      <td>3.653130</td>\n",
       "      <td>3.246857</td>\n",
       "      <td>3.516527</td>\n",
       "      <td>3.723137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.345977</td>\n",
       "      <td>1.525130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...</td>\n",
       "      <td>3.334064</td>\n",
       "      <td>3.784647</td>\n",
       "      <td>3.703305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.005097</td>\n",
       "      <td>5.966960</td>\n",
       "      <td>5.604037</td>\n",
       "      <td>4.534294</td>\n",
       "      <td>0.569795</td>\n",
       "      <td>8.734940</td>\n",
       "      <td>5.818432</td>\n",
       "      <td>2.395892</td>\n",
       "      <td>2.674205</td>\n",
       "      <td>4.386520</td>\n",
       "      <td>3.549230</td>\n",
       "      <td>0.383841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...</td>\n",
       "      <td>1.383306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319890</td>\n",
       "      <td>1.390207</td>\n",
       "      <td>2.974515</td>\n",
       "      <td>0.794156</td>\n",
       "      <td>4.410546</td>\n",
       "      <td>2.164357</td>\n",
       "      <td>3.124495</td>\n",
       "      <td>4.687232</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>2.351454</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>4.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...</td>\n",
       "      <td>1.975997</td>\n",
       "      <td>2.589316</td>\n",
       "      <td>2.528453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.549310</td>\n",
       "      <td>5.451760</td>\n",
       "      <td>1.901620</td>\n",
       "      <td>4.162091</td>\n",
       "      <td>2.070534</td>\n",
       "      <td>5.313060</td>\n",
       "      <td>4.051775</td>\n",
       "      <td>2.426169</td>\n",
       "      <td>3.152489</td>\n",
       "      <td>2.327195</td>\n",
       "      <td>4.600359</td>\n",
       "      <td>0.543529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2800</td>\n",
       "      <td>딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...</td>\n",
       "      <td>3.692484</td>\n",
       "      <td>1.169623</td>\n",
       "      <td>4.043570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.896584</td>\n",
       "      <td>3.824366</td>\n",
       "      <td>5.341949</td>\n",
       "      <td>2.289419</td>\n",
       "      <td>1.556468</td>\n",
       "      <td>4.329239</td>\n",
       "      <td>4.731332</td>\n",
       "      <td>2.103086</td>\n",
       "      <td>2.979902</td>\n",
       "      <td>4.638704</td>\n",
       "      <td>1.538957</td>\n",
       "      <td>2.240425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2801</td>\n",
       "      <td>본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...</td>\n",
       "      <td>1.485891</td>\n",
       "      <td>2.260214</td>\n",
       "      <td>0.871972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.113371</td>\n",
       "      <td>3.870273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.537723</td>\n",
       "      <td>1.432606</td>\n",
       "      <td>8.612232</td>\n",
       "      <td>6.365145</td>\n",
       "      <td>0.624376</td>\n",
       "      <td>0.279052</td>\n",
       "      <td>2.504393</td>\n",
       "      <td>1.611161</td>\n",
       "      <td>4.503639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2802</td>\n",
       "      <td>인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...</td>\n",
       "      <td>4.194004</td>\n",
       "      <td>2.453261</td>\n",
       "      <td>1.647712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.419639</td>\n",
       "      <td>6.381796</td>\n",
       "      <td>3.689257</td>\n",
       "      <td>3.816385</td>\n",
       "      <td>2.300622</td>\n",
       "      <td>1.321825</td>\n",
       "      <td>1.816383</td>\n",
       "      <td>3.222968</td>\n",
       "      <td>2.310107</td>\n",
       "      <td>3.619156</td>\n",
       "      <td>2.453853</td>\n",
       "      <td>0.038551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2803</td>\n",
       "      <td>인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...</td>\n",
       "      <td>3.915762</td>\n",
       "      <td>0.550987</td>\n",
       "      <td>2.666003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.212716</td>\n",
       "      <td>4.921995</td>\n",
       "      <td>3.173324</td>\n",
       "      <td>4.325376</td>\n",
       "      <td>3.989880</td>\n",
       "      <td>3.104712</td>\n",
       "      <td>4.521141</td>\n",
       "      <td>3.282028</td>\n",
       "      <td>3.189968</td>\n",
       "      <td>3.128338</td>\n",
       "      <td>3.479746</td>\n",
       "      <td>3.622998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...</td>\n",
       "      <td>5.402115</td>\n",
       "      <td>6.246725</td>\n",
       "      <td>2.236925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.492435</td>\n",
       "      <td>3.836646</td>\n",
       "      <td>0.867143</td>\n",
       "      <td>2.024768</td>\n",
       "      <td>3.382565</td>\n",
       "      <td>3.267964</td>\n",
       "      <td>4.965566</td>\n",
       "      <td>0.580251</td>\n",
       "      <td>3.306813</td>\n",
       "      <td>2.057824</td>\n",
       "      <td>3.992243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...  7.400500   \n",
       "1              1  고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...  0.283221   \n",
       "2              2  마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...  3.334064   \n",
       "3              3  현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...  1.383306   \n",
       "4              4  최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...  1.975997   \n",
       "...          ...                                                ...       ...   \n",
       "2800        2800  딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...  3.692484   \n",
       "2801        2801  본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...  1.485891   \n",
       "2802        2802  인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...  4.194004   \n",
       "2803        2803  인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...  3.915762   \n",
       "2804        2804  현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...  5.402115   \n",
       "\n",
       "             1         2    3         4         5         6         7  \\\n",
       "0     0.793967  2.494239  0.0  8.407842  6.835240  5.448450  3.640915   \n",
       "1     0.000000  1.966697  0.0  1.120683  1.474833  1.177635  1.103740   \n",
       "2     3.784647  3.703305  0.0  6.005097  5.966960  5.604037  4.534294   \n",
       "3     0.000000  0.593685  0.0  2.319890  1.390207  2.974515  0.794156   \n",
       "4     2.589316  2.528453  0.0  2.549310  5.451760  1.901620  4.162091   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "2800  1.169623  4.043570  0.0  4.896584  3.824366  5.341949  2.289419   \n",
       "2801  2.260214  0.871972  0.0  3.113371  3.870273  0.000000  4.537723   \n",
       "2802  2.453261  1.647712  0.0  4.419639  6.381796  3.689257  3.816385   \n",
       "2803  0.550987  2.666003  0.0  6.212716  4.921995  3.173324  4.325376   \n",
       "2804  6.246725  2.236925  0.0  2.492435  3.836646  0.867143  2.024768   \n",
       "\n",
       "             8         9        10        11        12        13        14  \\\n",
       "0     5.075698  2.362760  4.594933  4.380576  5.947162  1.284449  4.938036   \n",
       "1     3.678716  3.653130  3.246857  3.516527  3.723137  0.000000  5.345977   \n",
       "2     0.569795  8.734940  5.818432  2.395892  2.674205  4.386520  3.549230   \n",
       "3     4.410546  2.164357  3.124495  4.687232  0.307596  2.351454  2.308253   \n",
       "4     2.070534  5.313060  4.051775  2.426169  3.152489  2.327195  4.600359   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2800  1.556468  4.329239  4.731332  2.103086  2.979902  4.638704  1.538957   \n",
       "2801  1.432606  8.612232  6.365145  0.624376  0.279052  2.504393  1.611161   \n",
       "2802  2.300622  1.321825  1.816383  3.222968  2.310107  3.619156  2.453853   \n",
       "2803  3.989880  3.104712  4.521141  3.282028  3.189968  3.128338  3.479746   \n",
       "2804  3.382565  3.267964  4.965566  0.580251  3.306813  2.057824  3.992243   \n",
       "\n",
       "            15  \n",
       "0     1.547717  \n",
       "1     1.525130  \n",
       "2     0.383841  \n",
       "3     4.721750  \n",
       "4     0.543529  \n",
       "...        ...  \n",
       "2800  2.240425  \n",
       "2801  4.503639  \n",
       "2802  0.038551  \n",
       "2803  3.622998  \n",
       "2804  0.000000  \n",
       "\n",
       "[2805 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...</td>\n",
       "      <td>2.716055</td>\n",
       "      <td>2.246328</td>\n",
       "      <td>1.918941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.945909</td>\n",
       "      <td>1.523503</td>\n",
       "      <td>2.509283</td>\n",
       "      <td>0.978781</td>\n",
       "      <td>0.768399</td>\n",
       "      <td>3.411678</td>\n",
       "      <td>3.204705</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>1.516029</td>\n",
       "      <td>1.672213</td>\n",
       "      <td>1.215431</td>\n",
       "      <td>0.200743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...</td>\n",
       "      <td>0.188179</td>\n",
       "      <td>3.756775</td>\n",
       "      <td>1.736875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.436574</td>\n",
       "      <td>3.219394</td>\n",
       "      <td>0.987233</td>\n",
       "      <td>3.927560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.260923</td>\n",
       "      <td>1.117349</td>\n",
       "      <td>1.463253</td>\n",
       "      <td>2.272121</td>\n",
       "      <td>0.706141</td>\n",
       "      <td>4.232432</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...</td>\n",
       "      <td>1.648056</td>\n",
       "      <td>2.060825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.037456</td>\n",
       "      <td>1.674707</td>\n",
       "      <td>3.980412</td>\n",
       "      <td>0.422224</td>\n",
       "      <td>0.719849</td>\n",
       "      <td>3.312828</td>\n",
       "      <td>2.600056</td>\n",
       "      <td>4.113280</td>\n",
       "      <td>2.516047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.739432</td>\n",
       "      <td>2.534535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...</td>\n",
       "      <td>4.328513</td>\n",
       "      <td>1.414919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.815947</td>\n",
       "      <td>6.402259</td>\n",
       "      <td>1.192407</td>\n",
       "      <td>1.220185</td>\n",
       "      <td>2.057673</td>\n",
       "      <td>1.984623</td>\n",
       "      <td>2.425230</td>\n",
       "      <td>5.916327</td>\n",
       "      <td>3.905957</td>\n",
       "      <td>1.388042</td>\n",
       "      <td>3.977381</td>\n",
       "      <td>1.887881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...</td>\n",
       "      <td>4.168389</td>\n",
       "      <td>1.664589</td>\n",
       "      <td>4.663027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.650980</td>\n",
       "      <td>2.538317</td>\n",
       "      <td>0.406455</td>\n",
       "      <td>2.719093</td>\n",
       "      <td>2.570816</td>\n",
       "      <td>6.136378</td>\n",
       "      <td>6.868094</td>\n",
       "      <td>0.943375</td>\n",
       "      <td>3.902693</td>\n",
       "      <td>3.402886</td>\n",
       "      <td>0.723340</td>\n",
       "      <td>3.636968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...</td>\n",
       "      <td>4.355027</td>\n",
       "      <td>1.190150</td>\n",
       "      <td>2.025228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644762</td>\n",
       "      <td>4.315496</td>\n",
       "      <td>3.297051</td>\n",
       "      <td>2.216343</td>\n",
       "      <td>3.499756</td>\n",
       "      <td>3.984107</td>\n",
       "      <td>5.204399</td>\n",
       "      <td>4.898787</td>\n",
       "      <td>5.794420</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>6.614484</td>\n",
       "      <td>3.523954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...</td>\n",
       "      <td>3.915762</td>\n",
       "      <td>0.550987</td>\n",
       "      <td>2.666003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.212717</td>\n",
       "      <td>4.921996</td>\n",
       "      <td>3.173324</td>\n",
       "      <td>4.325376</td>\n",
       "      <td>3.989880</td>\n",
       "      <td>3.104712</td>\n",
       "      <td>4.521141</td>\n",
       "      <td>3.282028</td>\n",
       "      <td>3.189968</td>\n",
       "      <td>3.128339</td>\n",
       "      <td>3.479746</td>\n",
       "      <td>3.622998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...</td>\n",
       "      <td>4.169472</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.258170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.696071</td>\n",
       "      <td>3.298494</td>\n",
       "      <td>3.831412</td>\n",
       "      <td>3.097543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.396791</td>\n",
       "      <td>2.187004</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>2.311020</td>\n",
       "      <td>1.464791</td>\n",
       "      <td>1.942145</td>\n",
       "      <td>3.606117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...</td>\n",
       "      <td>3.166986</td>\n",
       "      <td>0.698115</td>\n",
       "      <td>5.117628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.312018</td>\n",
       "      <td>4.062506</td>\n",
       "      <td>2.903456</td>\n",
       "      <td>2.925658</td>\n",
       "      <td>3.021342</td>\n",
       "      <td>1.796183</td>\n",
       "      <td>3.347352</td>\n",
       "      <td>1.664982</td>\n",
       "      <td>6.847669</td>\n",
       "      <td>1.429339</td>\n",
       "      <td>3.233646</td>\n",
       "      <td>0.353345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...</td>\n",
       "      <td>1.383306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319889</td>\n",
       "      <td>1.390207</td>\n",
       "      <td>2.974516</td>\n",
       "      <td>0.794156</td>\n",
       "      <td>4.410545</td>\n",
       "      <td>2.164357</td>\n",
       "      <td>3.124495</td>\n",
       "      <td>4.687231</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>2.351454</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>4.721750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...  2.716055   \n",
       "1             1  최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...  0.188179   \n",
       "2             2  가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...  1.648056   \n",
       "3             3  문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...  4.328513   \n",
       "4             4  최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...  4.168389   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...  4.355027   \n",
       "931         931  제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...  3.915762   \n",
       "932         932  초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...  4.169472   \n",
       "933         933  사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...  3.166986   \n",
       "934         934  이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...  1.383306   \n",
       "\n",
       "            1         2    3         4         5         6         7  \\\n",
       "0    2.246328  1.918941  0.0  2.945909  1.523503  2.509283  0.978781   \n",
       "1    3.756775  1.736875  0.0  3.436574  3.219394  0.987233  3.927560   \n",
       "2    2.060825  0.000000  0.0  2.037456  1.674707  3.980412  0.422224   \n",
       "3    1.414919  0.000000  0.0  2.815947  6.402259  1.192407  1.220185   \n",
       "4    1.664589  4.663027  0.0  6.650980  2.538317  0.406455  2.719093   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "930  1.190150  2.025228  0.0  4.644762  4.315496  3.297051  2.216343   \n",
       "931  0.550987  2.666003  0.0  6.212717  4.921996  3.173324  4.325376   \n",
       "932  0.552265  0.258170  0.0  6.696071  3.298494  3.831412  3.097543   \n",
       "933  0.698115  5.117628  0.0  1.312018  4.062506  2.903456  2.925658   \n",
       "934  0.000000  0.593684  0.0  2.319889  1.390207  2.974516  0.794156   \n",
       "\n",
       "            8         9        10        11        12        13        14  \\\n",
       "0    0.768399  3.411678  3.204705  0.416470  1.516029  1.672213  1.215431   \n",
       "1    0.000000  4.260923  1.117349  1.463253  2.272121  0.706141  4.232432   \n",
       "2    0.719849  3.312828  2.600056  4.113280  2.516047  0.000000  6.739432   \n",
       "3    2.057673  1.984623  2.425230  5.916327  3.905957  1.388042  3.977381   \n",
       "4    2.570816  6.136378  6.868094  0.943375  3.902693  3.402886  0.723340   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  3.499756  3.984107  5.204399  4.898787  5.794420  0.995206  6.614484   \n",
       "931  3.989880  3.104712  4.521141  3.282028  3.189968  3.128339  3.479746   \n",
       "932  0.000000  2.396791  2.187004  0.575083  2.311020  1.464791  1.942145   \n",
       "933  3.021342  1.796183  3.347352  1.664982  6.847669  1.429339  3.233646   \n",
       "934  4.410545  2.164357  3.124495  4.687231  0.307596  2.351454  2.308253   \n",
       "\n",
       "           15  \n",
       "0    0.200743  \n",
       "1    0.000000  \n",
       "2    2.534535  \n",
       "3    1.887881  \n",
       "4    3.636968  \n",
       "..        ...  \n",
       "930  3.523954  \n",
       "931  3.622998  \n",
       "932  3.606117  \n",
       "933  0.353345  \n",
       "934  4.721750  \n",
       "\n",
       "[935 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...</td>\n",
       "      <td>3.109257</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>4.238945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.069359</td>\n",
       "      <td>1.314262</td>\n",
       "      <td>5.194553</td>\n",
       "      <td>0.798135</td>\n",
       "      <td>3.708004</td>\n",
       "      <td>2.800227</td>\n",
       "      <td>3.386113</td>\n",
       "      <td>4.885478</td>\n",
       "      <td>4.414466</td>\n",
       "      <td>2.473108</td>\n",
       "      <td>2.571003</td>\n",
       "      <td>2.881237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...</td>\n",
       "      <td>5.282905</td>\n",
       "      <td>3.474550</td>\n",
       "      <td>1.943892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.550474</td>\n",
       "      <td>2.491935</td>\n",
       "      <td>1.962530</td>\n",
       "      <td>2.464110</td>\n",
       "      <td>3.346422</td>\n",
       "      <td>4.429030</td>\n",
       "      <td>5.636681</td>\n",
       "      <td>0.748188</td>\n",
       "      <td>3.827006</td>\n",
       "      <td>0.745328</td>\n",
       "      <td>4.658368</td>\n",
       "      <td>1.671009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...</td>\n",
       "      <td>2.532079</td>\n",
       "      <td>1.085765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125017</td>\n",
       "      <td>5.070262</td>\n",
       "      <td>4.069159</td>\n",
       "      <td>2.666471</td>\n",
       "      <td>3.644066</td>\n",
       "      <td>3.406696</td>\n",
       "      <td>3.163209</td>\n",
       "      <td>4.850121</td>\n",
       "      <td>1.080277</td>\n",
       "      <td>1.251191</td>\n",
       "      <td>5.228837</td>\n",
       "      <td>1.121970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...</td>\n",
       "      <td>4.355028</td>\n",
       "      <td>1.190150</td>\n",
       "      <td>2.025228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644761</td>\n",
       "      <td>4.315497</td>\n",
       "      <td>3.297051</td>\n",
       "      <td>2.216343</td>\n",
       "      <td>3.499756</td>\n",
       "      <td>3.984107</td>\n",
       "      <td>5.204399</td>\n",
       "      <td>4.898787</td>\n",
       "      <td>5.794420</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>6.614484</td>\n",
       "      <td>3.523954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...</td>\n",
       "      <td>4.602422</td>\n",
       "      <td>4.929533</td>\n",
       "      <td>1.838855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.579864</td>\n",
       "      <td>4.315188</td>\n",
       "      <td>3.344093</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>1.534162</td>\n",
       "      <td>3.746244</td>\n",
       "      <td>2.821949</td>\n",
       "      <td>6.012256</td>\n",
       "      <td>6.229089</td>\n",
       "      <td>0.841923</td>\n",
       "      <td>6.791606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...</td>\n",
       "      <td>1.457492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.793102</td>\n",
       "      <td>3.870427</td>\n",
       "      <td>2.918499</td>\n",
       "      <td>2.596539</td>\n",
       "      <td>1.040515</td>\n",
       "      <td>4.695660</td>\n",
       "      <td>3.531010</td>\n",
       "      <td>3.542725</td>\n",
       "      <td>1.514029</td>\n",
       "      <td>1.906495</td>\n",
       "      <td>3.157008</td>\n",
       "      <td>4.240695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...</td>\n",
       "      <td>4.023750</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2.612715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.207034</td>\n",
       "      <td>1.371960</td>\n",
       "      <td>3.777225</td>\n",
       "      <td>0.737728</td>\n",
       "      <td>3.237675</td>\n",
       "      <td>4.472548</td>\n",
       "      <td>5.219839</td>\n",
       "      <td>4.296143</td>\n",
       "      <td>3.230532</td>\n",
       "      <td>2.287765</td>\n",
       "      <td>2.882447</td>\n",
       "      <td>4.646954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...</td>\n",
       "      <td>2.522391</td>\n",
       "      <td>0.946624</td>\n",
       "      <td>1.910630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.051934</td>\n",
       "      <td>5.164859</td>\n",
       "      <td>1.514896</td>\n",
       "      <td>1.940813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.530931</td>\n",
       "      <td>3.769886</td>\n",
       "      <td>2.217740</td>\n",
       "      <td>2.154315</td>\n",
       "      <td>4.887637</td>\n",
       "      <td>0.971270</td>\n",
       "      <td>4.188681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...</td>\n",
       "      <td>4.784645</td>\n",
       "      <td>1.647853</td>\n",
       "      <td>2.949671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.695910</td>\n",
       "      <td>6.294489</td>\n",
       "      <td>2.261566</td>\n",
       "      <td>2.449160</td>\n",
       "      <td>3.040078</td>\n",
       "      <td>5.971372</td>\n",
       "      <td>4.842612</td>\n",
       "      <td>5.574839</td>\n",
       "      <td>3.312207</td>\n",
       "      <td>3.869566</td>\n",
       "      <td>1.133421</td>\n",
       "      <td>1.769843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>(연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...</td>\n",
       "      <td>1.039919</td>\n",
       "      <td>3.065394</td>\n",
       "      <td>3.171070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.400837</td>\n",
       "      <td>2.757856</td>\n",
       "      <td>3.905798</td>\n",
       "      <td>2.892762</td>\n",
       "      <td>3.819060</td>\n",
       "      <td>5.310266</td>\n",
       "      <td>3.268128</td>\n",
       "      <td>4.228437</td>\n",
       "      <td>2.229610</td>\n",
       "      <td>1.910947</td>\n",
       "      <td>4.853198</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...  3.109257   \n",
       "1             1  본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...  5.282905   \n",
       "2             2  오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...  2.532079   \n",
       "3             3  도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...  4.355028   \n",
       "4             4  컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...  4.602422   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...  1.457492   \n",
       "931         931  4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...  4.023750   \n",
       "932         932  본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...  2.522391   \n",
       "933         933  제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...  4.784645   \n",
       "934         934  (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...  1.039919   \n",
       "\n",
       "            1         2    3         4         5         6         7  \\\n",
       "0    0.028045  4.238945  0.0  5.069359  1.314262  5.194553  0.798135   \n",
       "1    3.474550  1.943892  0.0  4.550474  2.491935  1.962530  2.464110   \n",
       "2    1.085765  0.000000  0.0  3.125017  5.070262  4.069159  2.666471   \n",
       "3    1.190150  2.025228  0.0  4.644761  4.315497  3.297051  2.216343   \n",
       "4    4.929533  1.838855  0.0  4.579864  4.315188  3.344093  1.428097   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "930  0.000000  0.483540  0.0  2.793102  3.870427  2.918499  2.596539   \n",
       "931  0.518679  2.612715  0.0  6.207034  1.371960  3.777225  0.737728   \n",
       "932  0.946624  1.910630  0.0  2.051934  5.164859  1.514896  1.940813   \n",
       "933  1.647853  2.949671  0.0  6.695910  6.294489  2.261566  2.449160   \n",
       "934  3.065394  3.171070  0.0  4.400837  2.757856  3.905798  2.892762   \n",
       "\n",
       "            8         9        10        11        12        13        14  \\\n",
       "0    3.708004  2.800227  3.386113  4.885478  4.414466  2.473108  2.571003   \n",
       "1    3.346422  4.429030  5.636681  0.748188  3.827006  0.745328  4.658368   \n",
       "2    3.644066  3.406696  3.163209  4.850121  1.080277  1.251191  5.228837   \n",
       "3    3.499756  3.984107  5.204399  4.898787  5.794420  0.995206  6.614484   \n",
       "4    1.534162  3.746244  2.821949  6.012256  6.229089  0.841923  6.791606   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  1.040515  4.695660  3.531010  3.542725  1.514029  1.906495  3.157008   \n",
       "931  3.237675  4.472548  5.219839  4.296143  3.230532  2.287765  2.882447   \n",
       "932  0.000000  3.530931  3.769886  2.217740  2.154315  4.887637  0.971270   \n",
       "933  3.040078  5.971372  4.842612  5.574839  3.312207  3.869566  1.133421   \n",
       "934  3.819060  5.310266  3.268128  4.228437  2.229610  1.910947  4.853198   \n",
       "\n",
       "           15  \n",
       "0    2.881237  \n",
       "1    1.671009  \n",
       "2    1.121970  \n",
       "3    3.523954  \n",
       "4    0.000000  \n",
       "..        ...  \n",
       "930  4.240695  \n",
       "931  4.646954  \n",
       "932  4.188681  \n",
       "933  1.769843  \n",
       "934  0.000000  \n",
       "\n",
       "[935 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...\n",
       "1       고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...\n",
       "2       마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...\n",
       "3       현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...\n",
       "4       최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...\n",
       "                              ...                        \n",
       "2800    딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...\n",
       "2801    본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...\n",
       "2802    인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...\n",
       "2803    인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...\n",
       "2804    현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...\n",
       "Name: abstract, Length: 2805, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.400500</td>\n",
       "      <td>0.793967</td>\n",
       "      <td>2.494239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.407842</td>\n",
       "      <td>6.835240</td>\n",
       "      <td>5.448450</td>\n",
       "      <td>3.640915</td>\n",
       "      <td>5.075698</td>\n",
       "      <td>2.362760</td>\n",
       "      <td>4.594933</td>\n",
       "      <td>4.380576</td>\n",
       "      <td>5.947162</td>\n",
       "      <td>1.284449</td>\n",
       "      <td>4.938036</td>\n",
       "      <td>1.547717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.966697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.120683</td>\n",
       "      <td>1.474833</td>\n",
       "      <td>1.177635</td>\n",
       "      <td>1.103740</td>\n",
       "      <td>3.678716</td>\n",
       "      <td>3.653130</td>\n",
       "      <td>3.246857</td>\n",
       "      <td>3.516527</td>\n",
       "      <td>3.723137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.345977</td>\n",
       "      <td>1.525130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.334064</td>\n",
       "      <td>3.784647</td>\n",
       "      <td>3.703305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.005097</td>\n",
       "      <td>5.966960</td>\n",
       "      <td>5.604037</td>\n",
       "      <td>4.534294</td>\n",
       "      <td>0.569795</td>\n",
       "      <td>8.734940</td>\n",
       "      <td>5.818432</td>\n",
       "      <td>2.395892</td>\n",
       "      <td>2.674205</td>\n",
       "      <td>4.386520</td>\n",
       "      <td>3.549230</td>\n",
       "      <td>0.383841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.383306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319890</td>\n",
       "      <td>1.390207</td>\n",
       "      <td>2.974515</td>\n",
       "      <td>0.794156</td>\n",
       "      <td>4.410546</td>\n",
       "      <td>2.164357</td>\n",
       "      <td>3.124495</td>\n",
       "      <td>4.687232</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>2.351454</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>4.721750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.975997</td>\n",
       "      <td>2.589316</td>\n",
       "      <td>2.528453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.549310</td>\n",
       "      <td>5.451760</td>\n",
       "      <td>1.901620</td>\n",
       "      <td>4.162091</td>\n",
       "      <td>2.070534</td>\n",
       "      <td>5.313060</td>\n",
       "      <td>4.051775</td>\n",
       "      <td>2.426169</td>\n",
       "      <td>3.152489</td>\n",
       "      <td>2.327195</td>\n",
       "      <td>4.600359</td>\n",
       "      <td>0.543529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>3.692484</td>\n",
       "      <td>1.169623</td>\n",
       "      <td>4.043570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.896584</td>\n",
       "      <td>3.824366</td>\n",
       "      <td>5.341949</td>\n",
       "      <td>2.289419</td>\n",
       "      <td>1.556468</td>\n",
       "      <td>4.329239</td>\n",
       "      <td>4.731332</td>\n",
       "      <td>2.103086</td>\n",
       "      <td>2.979902</td>\n",
       "      <td>4.638704</td>\n",
       "      <td>1.538957</td>\n",
       "      <td>2.240425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>1.485891</td>\n",
       "      <td>2.260214</td>\n",
       "      <td>0.871972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.113371</td>\n",
       "      <td>3.870273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.537723</td>\n",
       "      <td>1.432606</td>\n",
       "      <td>8.612232</td>\n",
       "      <td>6.365145</td>\n",
       "      <td>0.624376</td>\n",
       "      <td>0.279052</td>\n",
       "      <td>2.504393</td>\n",
       "      <td>1.611161</td>\n",
       "      <td>4.503639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>4.194004</td>\n",
       "      <td>2.453261</td>\n",
       "      <td>1.647712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.419639</td>\n",
       "      <td>6.381796</td>\n",
       "      <td>3.689257</td>\n",
       "      <td>3.816385</td>\n",
       "      <td>2.300622</td>\n",
       "      <td>1.321825</td>\n",
       "      <td>1.816383</td>\n",
       "      <td>3.222968</td>\n",
       "      <td>2.310107</td>\n",
       "      <td>3.619156</td>\n",
       "      <td>2.453853</td>\n",
       "      <td>0.038551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>3.915762</td>\n",
       "      <td>0.550987</td>\n",
       "      <td>2.666003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.212716</td>\n",
       "      <td>4.921995</td>\n",
       "      <td>3.173324</td>\n",
       "      <td>4.325376</td>\n",
       "      <td>3.989880</td>\n",
       "      <td>3.104712</td>\n",
       "      <td>4.521141</td>\n",
       "      <td>3.282028</td>\n",
       "      <td>3.189968</td>\n",
       "      <td>3.128338</td>\n",
       "      <td>3.479746</td>\n",
       "      <td>3.622998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>5.402115</td>\n",
       "      <td>6.246725</td>\n",
       "      <td>2.236925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.492435</td>\n",
       "      <td>3.836646</td>\n",
       "      <td>0.867143</td>\n",
       "      <td>2.024768</td>\n",
       "      <td>3.382565</td>\n",
       "      <td>3.267964</td>\n",
       "      <td>4.965566</td>\n",
       "      <td>0.580251</td>\n",
       "      <td>3.306813</td>\n",
       "      <td>2.057824</td>\n",
       "      <td>3.992243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2    3         4         5         6   \\\n",
       "0     7.400500  0.793967  2.494239  0.0  8.407842  6.835240  5.448450   \n",
       "1     0.283221  0.000000  1.966697  0.0  1.120683  1.474833  1.177635   \n",
       "2     3.334064  3.784647  3.703305  0.0  6.005097  5.966960  5.604037   \n",
       "3     1.383306  0.000000  0.593685  0.0  2.319890  1.390207  2.974515   \n",
       "4     1.975997  2.589316  2.528453  0.0  2.549310  5.451760  1.901620   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2800  3.692484  1.169623  4.043570  0.0  4.896584  3.824366  5.341949   \n",
       "2801  1.485891  2.260214  0.871972  0.0  3.113371  3.870273  0.000000   \n",
       "2802  4.194004  2.453261  1.647712  0.0  4.419639  6.381796  3.689257   \n",
       "2803  3.915762  0.550987  2.666003  0.0  6.212716  4.921995  3.173324   \n",
       "2804  5.402115  6.246725  2.236925  0.0  2.492435  3.836646  0.867143   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     3.640915  5.075698  2.362760  4.594933  4.380576  5.947162  1.284449   \n",
       "1     1.103740  3.678716  3.653130  3.246857  3.516527  3.723137  0.000000   \n",
       "2     4.534294  0.569795  8.734940  5.818432  2.395892  2.674205  4.386520   \n",
       "3     0.794156  4.410546  2.164357  3.124495  4.687232  0.307596  2.351454   \n",
       "4     4.162091  2.070534  5.313060  4.051775  2.426169  3.152489  2.327195   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2800  2.289419  1.556468  4.329239  4.731332  2.103086  2.979902  4.638704   \n",
       "2801  4.537723  1.432606  8.612232  6.365145  0.624376  0.279052  2.504393   \n",
       "2802  3.816385  2.300622  1.321825  1.816383  3.222968  2.310107  3.619156   \n",
       "2803  4.325376  3.989880  3.104712  4.521141  3.282028  3.189968  3.128338   \n",
       "2804  2.024768  3.382565  3.267964  4.965566  0.580251  3.306813  2.057824   \n",
       "\n",
       "            14        15  \n",
       "0     4.938036  1.547717  \n",
       "1     5.345977  1.525130  \n",
       "2     3.549230  0.383841  \n",
       "3     2.308253  4.721750  \n",
       "4     4.600359  0.543529  \n",
       "...        ...       ...  \n",
       "2800  1.538957  2.240425  \n",
       "2801  1.611161  4.503639  \n",
       "2802  2.453853  0.038551  \n",
       "2803  3.479746  3.622998  \n",
       "2804  3.992243  0.000000  \n",
       "\n",
       "[2805 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...\n",
       "1      최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...\n",
       "2      가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...\n",
       "3      문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...\n",
       "4      최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...\n",
       "                             ...                        \n",
       "930    인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...\n",
       "931    제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...\n",
       "932    초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...\n",
       "933    사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...\n",
       "934    이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.716055</td>\n",
       "      <td>2.246328</td>\n",
       "      <td>1.918941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.945909</td>\n",
       "      <td>1.523503</td>\n",
       "      <td>2.509283</td>\n",
       "      <td>0.978781</td>\n",
       "      <td>0.768399</td>\n",
       "      <td>3.411678</td>\n",
       "      <td>3.204705</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>1.516029</td>\n",
       "      <td>1.672213</td>\n",
       "      <td>1.215431</td>\n",
       "      <td>0.200743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188179</td>\n",
       "      <td>3.756775</td>\n",
       "      <td>1.736875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.436574</td>\n",
       "      <td>3.219394</td>\n",
       "      <td>0.987233</td>\n",
       "      <td>3.927560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.260923</td>\n",
       "      <td>1.117349</td>\n",
       "      <td>1.463253</td>\n",
       "      <td>2.272121</td>\n",
       "      <td>0.706141</td>\n",
       "      <td>4.232432</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.648056</td>\n",
       "      <td>2.060825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.037456</td>\n",
       "      <td>1.674707</td>\n",
       "      <td>3.980412</td>\n",
       "      <td>0.422224</td>\n",
       "      <td>0.719849</td>\n",
       "      <td>3.312828</td>\n",
       "      <td>2.600056</td>\n",
       "      <td>4.113280</td>\n",
       "      <td>2.516047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.739432</td>\n",
       "      <td>2.534535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.328513</td>\n",
       "      <td>1.414919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.815947</td>\n",
       "      <td>6.402259</td>\n",
       "      <td>1.192407</td>\n",
       "      <td>1.220185</td>\n",
       "      <td>2.057673</td>\n",
       "      <td>1.984623</td>\n",
       "      <td>2.425230</td>\n",
       "      <td>5.916327</td>\n",
       "      <td>3.905957</td>\n",
       "      <td>1.388042</td>\n",
       "      <td>3.977381</td>\n",
       "      <td>1.887881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.168389</td>\n",
       "      <td>1.664589</td>\n",
       "      <td>4.663027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.650980</td>\n",
       "      <td>2.538317</td>\n",
       "      <td>0.406455</td>\n",
       "      <td>2.719093</td>\n",
       "      <td>2.570816</td>\n",
       "      <td>6.136378</td>\n",
       "      <td>6.868094</td>\n",
       "      <td>0.943375</td>\n",
       "      <td>3.902693</td>\n",
       "      <td>3.402886</td>\n",
       "      <td>0.723340</td>\n",
       "      <td>3.636968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>4.355027</td>\n",
       "      <td>1.190150</td>\n",
       "      <td>2.025228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644762</td>\n",
       "      <td>4.315496</td>\n",
       "      <td>3.297051</td>\n",
       "      <td>2.216343</td>\n",
       "      <td>3.499756</td>\n",
       "      <td>3.984107</td>\n",
       "      <td>5.204399</td>\n",
       "      <td>4.898787</td>\n",
       "      <td>5.794420</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>6.614484</td>\n",
       "      <td>3.523954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>3.915762</td>\n",
       "      <td>0.550987</td>\n",
       "      <td>2.666003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.212717</td>\n",
       "      <td>4.921996</td>\n",
       "      <td>3.173324</td>\n",
       "      <td>4.325376</td>\n",
       "      <td>3.989880</td>\n",
       "      <td>3.104712</td>\n",
       "      <td>4.521141</td>\n",
       "      <td>3.282028</td>\n",
       "      <td>3.189968</td>\n",
       "      <td>3.128339</td>\n",
       "      <td>3.479746</td>\n",
       "      <td>3.622998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>4.169472</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.258170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.696071</td>\n",
       "      <td>3.298494</td>\n",
       "      <td>3.831412</td>\n",
       "      <td>3.097543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.396791</td>\n",
       "      <td>2.187004</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>2.311020</td>\n",
       "      <td>1.464791</td>\n",
       "      <td>1.942145</td>\n",
       "      <td>3.606117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>3.166986</td>\n",
       "      <td>0.698115</td>\n",
       "      <td>5.117628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.312018</td>\n",
       "      <td>4.062506</td>\n",
       "      <td>2.903456</td>\n",
       "      <td>2.925658</td>\n",
       "      <td>3.021342</td>\n",
       "      <td>1.796183</td>\n",
       "      <td>3.347352</td>\n",
       "      <td>1.664982</td>\n",
       "      <td>6.847669</td>\n",
       "      <td>1.429339</td>\n",
       "      <td>3.233646</td>\n",
       "      <td>0.353345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>1.383306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319889</td>\n",
       "      <td>1.390207</td>\n",
       "      <td>2.974516</td>\n",
       "      <td>0.794156</td>\n",
       "      <td>4.410545</td>\n",
       "      <td>2.164357</td>\n",
       "      <td>3.124495</td>\n",
       "      <td>4.687231</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>2.351454</td>\n",
       "      <td>2.308253</td>\n",
       "      <td>4.721750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2    3         4         5         6   \\\n",
       "0    2.716055  2.246328  1.918941  0.0  2.945909  1.523503  2.509283   \n",
       "1    0.188179  3.756775  1.736875  0.0  3.436574  3.219394  0.987233   \n",
       "2    1.648056  2.060825  0.000000  0.0  2.037456  1.674707  3.980412   \n",
       "3    4.328513  1.414919  0.000000  0.0  2.815947  6.402259  1.192407   \n",
       "4    4.168389  1.664589  4.663027  0.0  6.650980  2.538317  0.406455   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  4.355027  1.190150  2.025228  0.0  4.644762  4.315496  3.297051   \n",
       "931  3.915762  0.550987  2.666003  0.0  6.212717  4.921996  3.173324   \n",
       "932  4.169472  0.552265  0.258170  0.0  6.696071  3.298494  3.831412   \n",
       "933  3.166986  0.698115  5.117628  0.0  1.312018  4.062506  2.903456   \n",
       "934  1.383306  0.000000  0.593684  0.0  2.319889  1.390207  2.974516   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0    0.978781  0.768399  3.411678  3.204705  0.416470  1.516029  1.672213   \n",
       "1    3.927560  0.000000  4.260923  1.117349  1.463253  2.272121  0.706141   \n",
       "2    0.422224  0.719849  3.312828  2.600056  4.113280  2.516047  0.000000   \n",
       "3    1.220185  2.057673  1.984623  2.425230  5.916327  3.905957  1.388042   \n",
       "4    2.719093  2.570816  6.136378  6.868094  0.943375  3.902693  3.402886   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  2.216343  3.499756  3.984107  5.204399  4.898787  5.794420  0.995206   \n",
       "931  4.325376  3.989880  3.104712  4.521141  3.282028  3.189968  3.128339   \n",
       "932  3.097543  0.000000  2.396791  2.187004  0.575083  2.311020  1.464791   \n",
       "933  2.925658  3.021342  1.796183  3.347352  1.664982  6.847669  1.429339   \n",
       "934  0.794156  4.410545  2.164357  3.124495  4.687231  0.307596  2.351454   \n",
       "\n",
       "           14        15  \n",
       "0    1.215431  0.200743  \n",
       "1    4.232432  0.000000  \n",
       "2    6.739432  2.534535  \n",
       "3    3.977381  1.887881  \n",
       "4    0.723340  3.636968  \n",
       "..        ...       ...  \n",
       "930  6.614484  3.523954  \n",
       "931  3.479746  3.622998  \n",
       "932  1.942145  3.606117  \n",
       "933  3.233646  0.353345  \n",
       "934  2.308253  4.721750  \n",
       "\n",
       "[935 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...\n",
       "1      본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...\n",
       "2      오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...\n",
       "3      도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...\n",
       "4      컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...\n",
       "                             ...                        \n",
       "930    포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...\n",
       "931    4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...\n",
       "932    본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...\n",
       "933    제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...\n",
       "934    (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.109257</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>4.238945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.069359</td>\n",
       "      <td>1.314262</td>\n",
       "      <td>5.194553</td>\n",
       "      <td>0.798135</td>\n",
       "      <td>3.708004</td>\n",
       "      <td>2.800227</td>\n",
       "      <td>3.386113</td>\n",
       "      <td>4.885478</td>\n",
       "      <td>4.414466</td>\n",
       "      <td>2.473108</td>\n",
       "      <td>2.571003</td>\n",
       "      <td>2.881237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.282905</td>\n",
       "      <td>3.474550</td>\n",
       "      <td>1.943892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.550474</td>\n",
       "      <td>2.491935</td>\n",
       "      <td>1.962530</td>\n",
       "      <td>2.464110</td>\n",
       "      <td>3.346422</td>\n",
       "      <td>4.429030</td>\n",
       "      <td>5.636681</td>\n",
       "      <td>0.748188</td>\n",
       "      <td>3.827006</td>\n",
       "      <td>0.745328</td>\n",
       "      <td>4.658368</td>\n",
       "      <td>1.671009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.532079</td>\n",
       "      <td>1.085765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125017</td>\n",
       "      <td>5.070262</td>\n",
       "      <td>4.069159</td>\n",
       "      <td>2.666471</td>\n",
       "      <td>3.644066</td>\n",
       "      <td>3.406696</td>\n",
       "      <td>3.163209</td>\n",
       "      <td>4.850121</td>\n",
       "      <td>1.080277</td>\n",
       "      <td>1.251191</td>\n",
       "      <td>5.228837</td>\n",
       "      <td>1.121970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.355028</td>\n",
       "      <td>1.190150</td>\n",
       "      <td>2.025228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644761</td>\n",
       "      <td>4.315497</td>\n",
       "      <td>3.297051</td>\n",
       "      <td>2.216343</td>\n",
       "      <td>3.499756</td>\n",
       "      <td>3.984107</td>\n",
       "      <td>5.204399</td>\n",
       "      <td>4.898787</td>\n",
       "      <td>5.794420</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>6.614484</td>\n",
       "      <td>3.523954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.602422</td>\n",
       "      <td>4.929533</td>\n",
       "      <td>1.838855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.579864</td>\n",
       "      <td>4.315188</td>\n",
       "      <td>3.344093</td>\n",
       "      <td>1.428097</td>\n",
       "      <td>1.534162</td>\n",
       "      <td>3.746244</td>\n",
       "      <td>2.821949</td>\n",
       "      <td>6.012256</td>\n",
       "      <td>6.229089</td>\n",
       "      <td>0.841923</td>\n",
       "      <td>6.791606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.457492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.793102</td>\n",
       "      <td>3.870427</td>\n",
       "      <td>2.918499</td>\n",
       "      <td>2.596539</td>\n",
       "      <td>1.040515</td>\n",
       "      <td>4.695660</td>\n",
       "      <td>3.531010</td>\n",
       "      <td>3.542725</td>\n",
       "      <td>1.514029</td>\n",
       "      <td>1.906495</td>\n",
       "      <td>3.157008</td>\n",
       "      <td>4.240695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>4.023750</td>\n",
       "      <td>0.518679</td>\n",
       "      <td>2.612715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.207034</td>\n",
       "      <td>1.371960</td>\n",
       "      <td>3.777225</td>\n",
       "      <td>0.737728</td>\n",
       "      <td>3.237675</td>\n",
       "      <td>4.472548</td>\n",
       "      <td>5.219839</td>\n",
       "      <td>4.296143</td>\n",
       "      <td>3.230532</td>\n",
       "      <td>2.287765</td>\n",
       "      <td>2.882447</td>\n",
       "      <td>4.646954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.522391</td>\n",
       "      <td>0.946624</td>\n",
       "      <td>1.910630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.051934</td>\n",
       "      <td>5.164859</td>\n",
       "      <td>1.514896</td>\n",
       "      <td>1.940813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.530931</td>\n",
       "      <td>3.769886</td>\n",
       "      <td>2.217740</td>\n",
       "      <td>2.154315</td>\n",
       "      <td>4.887637</td>\n",
       "      <td>0.971270</td>\n",
       "      <td>4.188681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>4.784645</td>\n",
       "      <td>1.647853</td>\n",
       "      <td>2.949671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.695910</td>\n",
       "      <td>6.294489</td>\n",
       "      <td>2.261566</td>\n",
       "      <td>2.449160</td>\n",
       "      <td>3.040078</td>\n",
       "      <td>5.971372</td>\n",
       "      <td>4.842612</td>\n",
       "      <td>5.574839</td>\n",
       "      <td>3.312207</td>\n",
       "      <td>3.869566</td>\n",
       "      <td>1.133421</td>\n",
       "      <td>1.769843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>1.039919</td>\n",
       "      <td>3.065394</td>\n",
       "      <td>3.171070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.400837</td>\n",
       "      <td>2.757856</td>\n",
       "      <td>3.905798</td>\n",
       "      <td>2.892762</td>\n",
       "      <td>3.819060</td>\n",
       "      <td>5.310266</td>\n",
       "      <td>3.268128</td>\n",
       "      <td>4.228437</td>\n",
       "      <td>2.229610</td>\n",
       "      <td>1.910947</td>\n",
       "      <td>4.853198</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2    3         4         5         6   \\\n",
       "0    3.109257  0.028045  4.238945  0.0  5.069359  1.314262  5.194553   \n",
       "1    5.282905  3.474550  1.943892  0.0  4.550474  2.491935  1.962530   \n",
       "2    2.532079  1.085765  0.000000  0.0  3.125017  5.070262  4.069159   \n",
       "3    4.355028  1.190150  2.025228  0.0  4.644761  4.315497  3.297051   \n",
       "4    4.602422  4.929533  1.838855  0.0  4.579864  4.315188  3.344093   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  1.457492  0.000000  0.483540  0.0  2.793102  3.870427  2.918499   \n",
       "931  4.023750  0.518679  2.612715  0.0  6.207034  1.371960  3.777225   \n",
       "932  2.522391  0.946624  1.910630  0.0  2.051934  5.164859  1.514896   \n",
       "933  4.784645  1.647853  2.949671  0.0  6.695910  6.294489  2.261566   \n",
       "934  1.039919  3.065394  3.171070  0.0  4.400837  2.757856  3.905798   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0    0.798135  3.708004  2.800227  3.386113  4.885478  4.414466  2.473108   \n",
       "1    2.464110  3.346422  4.429030  5.636681  0.748188  3.827006  0.745328   \n",
       "2    2.666471  3.644066  3.406696  3.163209  4.850121  1.080277  1.251191   \n",
       "3    2.216343  3.499756  3.984107  5.204399  4.898787  5.794420  0.995206   \n",
       "4    1.428097  1.534162  3.746244  2.821949  6.012256  6.229089  0.841923   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "930  2.596539  1.040515  4.695660  3.531010  3.542725  1.514029  1.906495   \n",
       "931  0.737728  3.237675  4.472548  5.219839  4.296143  3.230532  2.287765   \n",
       "932  1.940813  0.000000  3.530931  3.769886  2.217740  2.154315  4.887637   \n",
       "933  2.449160  3.040078  5.971372  4.842612  5.574839  3.312207  3.869566   \n",
       "934  2.892762  3.819060  5.310266  3.268128  4.228437  2.229610  1.910947   \n",
       "\n",
       "           14        15  \n",
       "0    2.571003  2.881237  \n",
       "1    4.658368  1.671009  \n",
       "2    5.228837  1.121970  \n",
       "3    6.614484  3.523954  \n",
       "4    6.791606  0.000000  \n",
       "..        ...       ...  \n",
       "930  3.157008  4.240695  \n",
       "931  2.882447  4.646954  \n",
       "932  0.971270  4.188681  \n",
       "933  1.133421  1.769843  \n",
       "934  4.853198  0.000000  \n",
       "\n",
       "[935 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2805/2805 [01:15<00:00, 37.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:25<00:00, 36.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:27<00:00, 34.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['로지',\n",
       "  '스틱',\n",
       "  '회귀분석은',\n",
       "  '통계학',\n",
       "  '등의',\n",
       "  '분야에서',\n",
       "  '예측을',\n",
       "  '위한',\n",
       "  '기술',\n",
       "  '혹은',\n",
       "  '변수',\n",
       "  '간의',\n",
       "  '상관관계',\n",
       "  '를',\n",
       "  '설명',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '오랫동안',\n",
       "  '사용',\n",
       "  '되어',\n",
       "  '왔다',\n",
       "  '이러한',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법에서',\n",
       "  '현재',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '들',\n",
       "  '은',\n",
       "  '목적',\n",
       "  '값에',\n",
       "  '대하여',\n",
       "  '동일한',\n",
       "  '중요도를',\n",
       "  '가지고',\n",
       "  '있다',\n",
       "  '본',\n",
       "  '연구에서는',\n",
       "  '이러한',\n",
       "  '가중치',\n",
       "  '계산',\n",
       "  '을',\n",
       "  '좀더',\n",
       "  '세분화',\n",
       "  '하여',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '의',\n",
       "  '값이',\n",
       "  '서로',\n",
       "  '다른',\n",
       "  '중요도를',\n",
       "  '가지는',\n",
       "  '새로운',\n",
       "  '학습',\n",
       "  '방법을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '알고리즘의',\n",
       "  '성능을',\n",
       "  '최대',\n",
       "  '화하는',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '가중치',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '계산',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '점진적',\n",
       "  '하강법을',\n",
       "  '이용하여',\n",
       "  '개발',\n",
       "  '하였다',\n",
       "  '본',\n",
       "  '연구에서',\n",
       "  '제안된',\n",
       "  '방법은',\n",
       "  '다양한',\n",
       "  '데이터를',\n",
       "  '이용하여',\n",
       "  '실험',\n",
       "  '하였고',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '기반',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법은',\n",
       "  '기존의',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '보다',\n",
       "  '우수한',\n",
       "  '학습',\n",
       "  '능력을',\n",
       "  '보임을',\n",
       "  '알',\n",
       "  '수',\n",
       "  '있었다'],\n",
       " ['최근에',\n",
       "  '이르러',\n",
       "  '기계학습',\n",
       "  '및',\n",
       "  '데이터마이닝',\n",
       "  '은',\n",
       "  '수많은',\n",
       "  '질병',\n",
       "  '예측',\n",
       "  '및',\n",
       "  '진단에',\n",
       "  '활용되고',\n",
       "  '있다',\n",
       "  '만성질환',\n",
       "  '은',\n",
       "  '전체',\n",
       "  '사망률',\n",
       "  '의',\n",
       "  '약',\n",
       "  '80',\n",
       "  '를',\n",
       "  '차지하는',\n",
       "  '질병',\n",
       "  '으로',\n",
       "  '점점',\n",
       "  '증가',\n",
       "  '하는',\n",
       "  '추세',\n",
       "  '이다',\n",
       "  '만성질환',\n",
       "  '관련',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '연구',\n",
       "  '한',\n",
       "  '기존',\n",
       "  '연구들은',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '구성하는',\n",
       "  '데이터로',\n",
       "  '혈당',\n",
       "  '혈압',\n",
       "  '인슐린',\n",
       "  '수치',\n",
       "  '등의',\n",
       "  '건강검진',\n",
       "  '수준의',\n",
       "  '데이터를',\n",
       "  '이용',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '논문은',\n",
       "  '만성질환',\n",
       "  '의',\n",
       "  '위험',\n",
       "  '요인인',\n",
       "  '이상',\n",
       "  '지질혈증과',\n",
       "  '안면',\n",
       "  '정보의',\n",
       "  '연관성을',\n",
       "  '검증',\n",
       "  '하고',\n",
       "  '기계학습',\n",
       "  '기반',\n",
       "  '안면',\n",
       "  '정보를',\n",
       "  '이용한',\n",
       "  '이상',\n",
       "  '지질혈증',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '세계',\n",
       "  '최초로',\n",
       "  '개발',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '연구는',\n",
       "  '5390',\n",
       "  '명의',\n",
       "  '임상',\n",
       "  '데이터',\n",
       "  '중',\n",
       "  '안면',\n",
       "  '정보와',\n",
       "  '중성지방혈증',\n",
       "  '정보를',\n",
       "  '바탕으로',\n",
       "  '수행',\n",
       "  '하였다',\n",
       "  '중성지방혈증은',\n",
       "  '이상',\n",
       "  '지질혈증을',\n",
       "  '판단하는',\n",
       "  '척도',\n",
       "  '이다',\n",
       "  '연구의',\n",
       "  '결과로',\n",
       "  '얼굴',\n",
       "  '의',\n",
       "  '하악',\n",
       "  '간의',\n",
       "  '거리를',\n",
       "  '나타내는',\n",
       "  '4314300001',\n",
       "  '0652',\n",
       "  '와',\n",
       "  '고중성지방혈증이',\n",
       "  '매우',\n",
       "  '높은',\n",
       "  '연관성을',\n",
       "  '가진',\n",
       "  '것을',\n",
       "  '밝혀냈고',\n",
       "  '이를',\n",
       "  '기반으로',\n",
       "  '구축',\n",
       "  '한',\n",
       "  '모델은',\n",
       "  '0662',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '획득',\n",
       "  '하였다',\n",
       "  '이러한',\n",
       "  '연구결과는',\n",
       "  '향후',\n",
       "  '질병',\n",
       "  '역학',\n",
       "  '및',\n",
       "  '대중',\n",
       "  '보건',\n",
       "  '영역의',\n",
       "  '스크',\n",
       "  '리닝',\n",
       "  '단계에서',\n",
       "  '안면정보만으로',\n",
       "  '다양할',\n",
       "  '질병',\n",
       "  '을',\n",
       "  '예측할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '기반을',\n",
       "  '제',\n",
       "  '공할',\n",
       "  '수',\n",
       "  '있을',\n",
       "  '것이',\n",
       "  '다'],\n",
       " ['가상',\n",
       "  '발전소',\n",
       "  '시장에',\n",
       "  '전력을',\n",
       "  '안정적으로',\n",
       "  '공급',\n",
       "  '하기',\n",
       "  '위해서는',\n",
       "  '발전',\n",
       "  '량에',\n",
       "  '대한',\n",
       "  '정확한',\n",
       "  '예측이',\n",
       "  '필요하다',\n",
       "  '하지만',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량은',\n",
       "  '기상',\n",
       "  '환경에',\n",
       "  '영향을',\n",
       "  '받아',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '편차가',\n",
       "  '심하기',\n",
       "  '때문에',\n",
       "  '안정적',\n",
       "  '인',\n",
       "  '예측이',\n",
       "  '어렵다',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '기반',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델을',\n",
       "  '제안',\n",
       "  '한다',\n",
       "  '우리는',\n",
       "  '기상',\n",
       "  '데이터와',\n",
       "  '기상',\n",
       "  '예보',\n",
       "  '데이터를',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델에',\n",
       "  '입력',\n",
       "  '하여',\n",
       "  '성능을',\n",
       "  '향상',\n",
       "  '시킨다',\n",
       "  '또한',\n",
       "  '상관계수',\n",
       "  '를',\n",
       "  '기준으로',\n",
       "  '우선순위',\n",
       "  '를',\n",
       "  '설정하',\n",
       "  '여',\n",
       "  '변수를',\n",
       "  '선택',\n",
       "  '한다',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '상관관계',\n",
       "  '와',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측',\n",
       "  '결과를',\n",
       "  '비교하여',\n",
       "  '태양광',\n",
       "  '에너지',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측에',\n",
       "  '활용',\n",
       "  '되는',\n",
       "  '최적의',\n",
       "  '기상',\n",
       "  '요인을',\n",
       "  '검토',\n",
       "  '한다'],\n",
       " ['문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '주어진',\n",
       "  '문서로부터',\n",
       "  '주요',\n",
       "  '내용을',\n",
       "  '추출',\n",
       "  '하거나',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '축약',\n",
       "  '하는',\n",
       "  '작업을',\n",
       "  '말',\n",
       "  '한다',\n",
       "  '최근',\n",
       "  '연구에서는',\n",
       "  '대량의',\n",
       "  '문서를',\n",
       "  '딥러닝',\n",
       "  '기법을',\n",
       "  '적용하여',\n",
       "  '요약',\n",
       "  '문',\n",
       "  '자체',\n",
       "  '를',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '발전',\n",
       "  '하고',\n",
       "  '있다',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '미리',\n",
       "  '생성',\n",
       "  '된',\n",
       "  '위드',\n",
       "  '임베딩',\n",
       "  '정보를',\n",
       "  '사용하는데',\n",
       "  '전문',\n",
       "  '용어와',\n",
       "  '같이',\n",
       "  '저빈도',\n",
       "  '핵심',\n",
       "  '어휘',\n",
       "  '는',\n",
       "  '입베딩',\n",
       "  '된',\n",
       "  '사전',\n",
       "  '에',\n",
       "  '없는',\n",
       "  '문제가',\n",
       "  '발생',\n",
       "  '한다',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '신경망',\n",
       "  '모델의',\n",
       "  '문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '에서',\n",
       "  '미등록',\n",
       "  '어휘',\n",
       "  '의',\n",
       "  '출현',\n",
       "  '은',\n",
       "  '요약',\n",
       "  '성능',\n",
       "  '저하',\n",
       "  '의',\n",
       "  '요인',\n",
       "  '이다',\n",
       "  '이를',\n",
       "  '해결',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '요약',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '에서',\n",
       "  '새로',\n",
       "  '출현',\n",
       "  '한',\n",
       "  '단어',\n",
       "  '를',\n",
       "  '복사',\n",
       "  '하여',\n",
       "  '요약',\n",
       "  '문을',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방법을',\n",
       "  '사용',\n",
       "  '한다',\n",
       "  '기존의',\n",
       "  '연구',\n",
       "  '와는',\n",
       "  '달리',\n",
       "  '정확한',\n",
       "  '포인',\n",
       "  '팅',\n",
       "  '정보와',\n",
       "  '선택',\n",
       "  '적',\n",
       "  '복사',\n",
       "  '지시',\n",
       "  '정보를',\n",
       "  '명시적',\n",
       "  '으로',\n",
       "  '제공하는',\n",
       "  '방법으로',\n",
       "  '제안',\n",
       "  '하였다',\n",
       "  '학습',\n",
       "  '데이터는',\n",
       "  '논문의',\n",
       "  '초록과',\n",
       "  '제목을',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '와',\n",
       "  '정답',\n",
       "  '요약',\n",
       "  '으로',\n",
       "  '사용',\n",
       "  '하였다',\n",
       "  '제안한',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '기반',\n",
       "  '모델을',\n",
       "  '통해서',\n",
       "  '자동',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '을',\n",
       "  '수행',\n",
       "  '한',\n",
       "  '결과',\n",
       "  '단어',\n",
       "  '제현',\n",
       "  '기반의',\n",
       "  '1',\n",
       "  '이',\n",
       "  '4701',\n",
       "  '로',\n",
       "  '나타났으며',\n",
       "  '또한',\n",
       "  '어순',\n",
       "  '기반의',\n",
       "  '이',\n",
       "  '2955',\n",
       "  '로',\n",
       "  '향상',\n",
       "  '되었다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3740/3740 [00:01<00:00, 3348.45it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그러므로',\n",
       " '선박,',\n",
       " '빌딩,',\n",
       " '기차,',\n",
       " '비행기',\n",
       " '등',\n",
       " 'Modbus를',\n",
       " '이용하는',\n",
       " '모든',\n",
       " '장비들과',\n",
       " '연결이',\n",
       " '가능하여',\n",
       " '환경변수의',\n",
       " '측정',\n",
       " '및',\n",
       " '원격제어가',\n",
       " '가능하게',\n",
       " '된다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3740/3740 [00:00<00:00, 312496.45it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 자발적 산업표준 통신 프로토콜이다',\n",
       " '그러므로 선박, 빌딩, 기차, 비행기 등 Modbus를 이용하는 모든 장비들과 연결이 가능하여 환경변수의 측정 및 원격제어가 가능하게 된다',\n",
       " '본 논문에서 는 퍼지제어 시스템을 이용하여 외부환경요인을 각각 조합한 불확실한 내용을 정량적인 값으로 변환하여 LED 조명으로 표현하기 위해 알고 리즘을 설계하고, 설계한 알고리즘에 Modbus 통신 프로토콜을 추가하여 선박의 통합관리 시스템에서 외부환경요인 확인 및 원격제어가 가능 한 감성조명용 LED 제어기 회로를 설계 및 구현 하였다',\n",
       " '외부환경요소인 온도, 습도, 조도 값을 센서를 통해 제어기로 받아들이고 이 값들을 퍼지제어 알고리즘을 통해 LED로 표현된다',\n",
       " 'Modbus는 Serial 통신으로 RS485를 이용하여 다른 기기와 연결 되어 온도, 습도, 조도 상태 및 LED 출력 값 확인이 가능하고 또한 사용자가 원격으로 RGB 값을 변경 할 수 있기 때문에 원하는 색으로 변경이 가능하게 된다',\n",
       " '제작한 제 어기로 온도, 습도, 조도에 따라 LED 조명색상이 변화 되는 것을 확인 하였다.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  34\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.831550802139038\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  391\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 19.31136906794128\n",
      "문장 내의 단어 개수 중앙값 : 18.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2805, 20, 200)\n",
      "train_Y_data.shape: (2805, 16)\n",
      "val_X_data.shape: (935, 20, 200)\n",
      "val_Y_data.shape: (935, 16)\n",
      "test_X_data.shape: (935, 20, 200)\n",
      "test_Y_data.shape: (935, 16)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '을': 2,\n",
       " '에': 3,\n",
       " '이': 4,\n",
       " '수': 5,\n",
       " '있다': 6,\n",
       " '하였다': 7,\n",
       " '를': 8,\n",
       " '한다': 9,\n",
       " '하고': 10,\n",
       " '할': 11,\n",
       " '본': 12,\n",
       " '대한': 13,\n",
       " '과': 14,\n",
       " '적': 15,\n",
       " '및': 16,\n",
       " '는': 17,\n",
       " '하는': 18,\n",
       " '있는': 19,\n",
       " '한': 20,\n",
       " '은': 21,\n",
       " '가': 22,\n",
       " '으로': 23,\n",
       " '것이': 24,\n",
       " '와': 25,\n",
       " '위해': 26,\n",
       " '통해': 27,\n",
       " '된': 28,\n",
       " '인': 29,\n",
       " '위한': 30,\n",
       " '로': 31,\n",
       " '인공지능': 32,\n",
       " '분석': 33,\n",
       " '하기': 34,\n",
       " '다': 35,\n",
       " '학습': 36,\n",
       " '들': 37,\n",
       " '이다': 38,\n",
       " '연구': 39,\n",
       " '에서': 40,\n",
       " '그': 41,\n",
       " '활용': 42,\n",
       " '이러한': 43,\n",
       " '다양한': 44,\n",
       " '이를': 45,\n",
       " '4': 46,\n",
       " '하여': 47,\n",
       " '것으로': 48,\n",
       " '교육': 49,\n",
       " '연구는': 50,\n",
       " '기술': 51,\n",
       " '고': 52,\n",
       " '제안': 53,\n",
       " '될': 54,\n",
       " '차': 55,\n",
       " '적용': 56,\n",
       " '또한': 57,\n",
       " '데이터': 58,\n",
       " '개발': 59,\n",
       " '사용': 60,\n",
       " '결과': 61,\n",
       " '된다': 62,\n",
       " '새로운': 63,\n",
       " '산업혁명': 64,\n",
       " '따라': 65,\n",
       " '예측': 66,\n",
       " '되고': 67,\n",
       " '경우': 68,\n",
       " '관련': 69,\n",
       " '도': 70,\n",
       " '되는': 71,\n",
       " '스마트': 72,\n",
       " '연구에서는': 73,\n",
       " '그리고': 74,\n",
       " '정보': 75,\n",
       " '되었다': 76,\n",
       " '기반': 77,\n",
       " '대해': 78,\n",
       " '인간': 79,\n",
       " '제': 80,\n",
       " '등': 81,\n",
       " '논문에서는': 82,\n",
       " '데이터를': 83,\n",
       " '영향을': 84,\n",
       " '제시': 85,\n",
       " '같은': 86,\n",
       " '최근': 87,\n",
       " '이에': 88,\n",
       " '3': 89,\n",
       " '분류': 90,\n",
       " '따라서': 91,\n",
       " '해': 92,\n",
       " '가장': 93,\n",
       " '이용하여': 94,\n",
       " '서': 95,\n",
       " '수행': 96,\n",
       " '확인': 97,\n",
       " '평가': 98,\n",
       " '인간의': 99,\n",
       " '되어': 100,\n",
       " '보다': 101,\n",
       " '사물인터넷': 102,\n",
       " '중': 103,\n",
       " '가지': 104,\n",
       " '연구의': 105,\n",
       " '특히': 106,\n",
       " '지': 107,\n",
       " '성': 108,\n",
       " '위하여': 109,\n",
       " '서비스': 110,\n",
       " '문제': 111,\n",
       " '기존': 112,\n",
       " '2': 113,\n",
       " '정보를': 114,\n",
       " '있었다': 115,\n",
       " '융합': 116,\n",
       " '인식': 117,\n",
       " '미래': 118,\n",
       " '제공': 119,\n",
       " '있으며': 120,\n",
       " '수업': 121,\n",
       " '나타났다': 122,\n",
       " '결과를': 123,\n",
       " '하고자': 124,\n",
       " '발생': 125,\n",
       " '설계': 126,\n",
       " '모델을': 127,\n",
       " '높은': 128,\n",
       " '것을': 129,\n",
       " '더': 130,\n",
       " '핵심': 131,\n",
       " '그러나': 132,\n",
       " '따른': 133,\n",
       " '비교': 134,\n",
       " '많은': 135,\n",
       " '아니라': 136,\n",
       " '방법을': 137,\n",
       " '대상으로': 138,\n",
       " '사회': 139,\n",
       " '관한': 140,\n",
       " '기존의': 141,\n",
       " '여': 142,\n",
       " '디자인': 143,\n",
       " '증가': 144,\n",
       " '진행': 145,\n",
       " '생성': 146,\n",
       " '해결': 147,\n",
       " '등의': 148,\n",
       " '산업': 149,\n",
       " '해야': 150,\n",
       " '기술의': 151,\n",
       " '각': 152,\n",
       " '인공지능의': 153,\n",
       " '기반으로': 154,\n",
       " '실험': 155,\n",
       " '변화': 156,\n",
       " '현재': 157,\n",
       " '구성': 158,\n",
       " '있을': 159,\n",
       " '하였으며': 160,\n",
       " '성능을': 161,\n",
       " '다른': 162,\n",
       " '에서는': 163,\n",
       " '발전': 164,\n",
       " '빅데이터': 165,\n",
       " '통한': 166,\n",
       " '기반의': 167,\n",
       " '1': 168,\n",
       " '바탕으로': 169,\n",
       " '딥러닝': 170,\n",
       " '활용하여': 171,\n",
       " '실제': 172,\n",
       " '연구가': 173,\n",
       " '미치는': 174,\n",
       " '문제를': 175,\n",
       " '기술을': 176,\n",
       " '등을': 177,\n",
       " '통하여': 178,\n",
       " '때': 179,\n",
       " '활용한': 180,\n",
       " '위해서는': 181,\n",
       " '개선': 182,\n",
       " '분석을': 183,\n",
       " '둘째': 184,\n",
       " '첫째': 185,\n",
       " '논문은': 186,\n",
       " '때문에': 187,\n",
       " '디지털': 188,\n",
       " '중요한': 189,\n",
       " '검토': 190,\n",
       " '수집': 191,\n",
       " '이용한': 192,\n",
       " '공학': 193,\n",
       " '의미': 194,\n",
       " '향후': 195,\n",
       " '필요': 196,\n",
       " '음악': 197,\n",
       " '논의': 198,\n",
       " '중심으로': 199,\n",
       " '도출': 200,\n",
       " '며': 201,\n",
       " '향상': 202,\n",
       " '이용': 203,\n",
       " '사회적': 204,\n",
       " '접근': 205,\n",
       " '후': 206,\n",
       " '시스템을': 207,\n",
       " '개의': 208,\n",
       " '연구를': 209,\n",
       " '간': 210,\n",
       " '했다': 211,\n",
       " '화': 212,\n",
       " '하지만': 213,\n",
       " '에는': 214,\n",
       " '필요하다': 215,\n",
       " '검증': 216,\n",
       " '에게': 217,\n",
       " '구축': 218,\n",
       " '주요': 219,\n",
       " '자': 220,\n",
       " '개': 221,\n",
       " '네트워크': 222,\n",
       " '사용자': 223,\n",
       " '필요한': 224,\n",
       " '있어': 225,\n",
       " '두': 226,\n",
       " '관리': 227,\n",
       " '기계학습': 228,\n",
       " '있도록': 229,\n",
       " '기초': 230,\n",
       " '이는': 231,\n",
       " '국내': 232,\n",
       " '시스템': 233,\n",
       " '하는데': 234,\n",
       " '이나': 235,\n",
       " '여러': 236,\n",
       " '인공지능이': 237,\n",
       " '다음': 238,\n",
       " '기법을': 239,\n",
       " '사물': 240,\n",
       " '것은': 241,\n",
       " '함께': 242,\n",
       " '존재': 243,\n",
       " '함으로써': 244,\n",
       " '교육의': 245,\n",
       " '한국': 246,\n",
       " '교수': 247,\n",
       " '하였고': 248,\n",
       " '과학': 249,\n",
       " '개인': 250,\n",
       " '측정': 251,\n",
       " '방안을': 252,\n",
       " '고려': 253,\n",
       " '나': 254,\n",
       " '판단': 255,\n",
       " '성능': 256,\n",
       " '법적': 257,\n",
       " '매우': 258,\n",
       " '관련된': 259,\n",
       " '알고리즘': 260,\n",
       " '어떻게': 261,\n",
       " '대하여': 262,\n",
       " '로봇': 263,\n",
       " '구현': 264,\n",
       " '하며': 265,\n",
       " '셋째': 266,\n",
       " '큰': 267,\n",
       " '모든': 268,\n",
       " '지식': 269,\n",
       " '있다는': 270,\n",
       " '도입': 271,\n",
       " '이미지': 272,\n",
       " '또는': 273,\n",
       " '인해': 274,\n",
       " '보안': 275,\n",
       " '운영': 276,\n",
       " '처리': 277,\n",
       " '되어야': 278,\n",
       " '개인정보': 279,\n",
       " '변화를': 280,\n",
       " '조사': 281,\n",
       " '지원': 282,\n",
       " '형': 283,\n",
       " '대학': 284,\n",
       " '요구': 285,\n",
       " '기계': 286,\n",
       " '특성을': 287,\n",
       " '데이터의': 288,\n",
       " '사용하여': 289,\n",
       " '탐색': 290,\n",
       " '알고리즘을': 291,\n",
       " '생각': 292,\n",
       " '실시': 293,\n",
       " '지능': 294,\n",
       " '연결': 295,\n",
       " '있어서': 296,\n",
       " '하면서': 297,\n",
       " '방법': 298,\n",
       " '개념': 299,\n",
       " '해당': 300,\n",
       " '센서': 301,\n",
       " '가능한': 302,\n",
       " '5': 303,\n",
       " '적용하여': 304,\n",
       " '특징': 305,\n",
       " '가능성을': 306,\n",
       " '환경': 307,\n",
       " '있음을': 308,\n",
       " '대': 309,\n",
       " '사전': 310,\n",
       " '영상': 311,\n",
       " '선택': 312,\n",
       " '게': 313,\n",
       " '확장': 314,\n",
       " '간의': 315,\n",
       " '국가': 316,\n",
       " '있고': 317,\n",
       " '인공지능에': 318,\n",
       " '없는': 319,\n",
       " '인터넷': 320,\n",
       " '통합': 321,\n",
       " '대응': 322,\n",
       " '과정에서': 323,\n",
       " '이고': 324,\n",
       " '현실': 325,\n",
       " '보였다': 326,\n",
       " '모두': 327,\n",
       " '이해': 328,\n",
       " '하지': 329,\n",
       " '결과는': 330,\n",
       " '역할을': 331,\n",
       " '관점에서': 332,\n",
       " '기술이': 333,\n",
       " '소프트웨어': 334,\n",
       " '모델': 335,\n",
       " '즉': 336,\n",
       " '비해': 337,\n",
       " '감성': 338,\n",
       " '참여': 339,\n",
       " '표현': 340,\n",
       " '시': 341,\n",
       " '포함': 342,\n",
       " '규제': 343,\n",
       " '에서의': 344,\n",
       " '학교': 345,\n",
       " '보호': 346,\n",
       " '인공지능을': 347,\n",
       " '인지': 348,\n",
       " '서비스를': 349,\n",
       " '의한': 350,\n",
       " '프로그램': 351,\n",
       " '내용': 352,\n",
       " '텍스트': 353,\n",
       " '일반': 354,\n",
       " '정의': 355,\n",
       " '등장': 356,\n",
       " '모형을': 357,\n",
       " '문제점': 358,\n",
       " '생산': 359,\n",
       " '경험': 360,\n",
       " '제안하는': 361,\n",
       " '체계': 362,\n",
       " '만': 363,\n",
       " '분야에서': 364,\n",
       " '데': 365,\n",
       " '부터': 366,\n",
       " '라는': 367,\n",
       " '자료를': 368,\n",
       " '전공': 369,\n",
       " '기능': 370,\n",
       " '이와': 371,\n",
       " '추출': 372,\n",
       " '과정을': 373,\n",
       " '심층': 374,\n",
       " '전체': 375,\n",
       " '연구에서': 376,\n",
       " '시스템의': 377,\n",
       " '까지': 378,\n",
       " '의해': 379,\n",
       " '정책': 380,\n",
       " '목적은': 381,\n",
       " '활동': 382,\n",
       " '컴퓨터': 383,\n",
       " '확보': 384,\n",
       " '결정': 385,\n",
       " '설명': 386,\n",
       " '크게': 387,\n",
       " '볼': 388,\n",
       " '모델의': 389,\n",
       " '상호작용': 390,\n",
       " '이며': 391,\n",
       " '때문': 392,\n",
       " '어떤': 393,\n",
       " '환경에서': 394,\n",
       " '자기': 395,\n",
       " '가지고': 396,\n",
       " '세': 397,\n",
       " '역량': 398,\n",
       " '전': 399,\n",
       " '중심': 400,\n",
       " '더욱': 401,\n",
       " '뿐': 402,\n",
       " '사용자의': 403,\n",
       " '상황': 404,\n",
       " '한계': 405,\n",
       " '창의적': 406,\n",
       " '제품': 407,\n",
       " '우리': 408,\n",
       " '먼저': 409,\n",
       " '분야': 410,\n",
       " '의료': 411,\n",
       " '학년': 412,\n",
       " '온라인': 413,\n",
       " '확대': 414,\n",
       " '세계': 415,\n",
       " '측면에서': 416,\n",
       " '예술': 417,\n",
       " '교육을': 418,\n",
       " '이라는': 419,\n",
       " '전문가': 420,\n",
       " '인간과': 421,\n",
       " '특성': 422,\n",
       " '콘텐츠': 423,\n",
       " '시대에': 424,\n",
       " '행동': 425,\n",
       " '효과를': 426,\n",
       " '정확도를': 427,\n",
       " '관계': 428,\n",
       " '사고': 429,\n",
       " '머신러닝': 430,\n",
       " '점에서': 431,\n",
       " '분야의': 432,\n",
       " '디바이스': 433,\n",
       " '한다는': 434,\n",
       " '시도': 435,\n",
       " '모바일': 436,\n",
       " '교과': 437,\n",
       " '총': 438,\n",
       " '내용을': 439,\n",
       " '제작': 440,\n",
       " '탐지': 441,\n",
       " '분석하여': 442,\n",
       " '야': 443,\n",
       " '문화': 444,\n",
       " '공간': 445,\n",
       " '관계를': 446,\n",
       " '평균': 447,\n",
       " '마련': 448,\n",
       " '자료': 449,\n",
       " '인공지능과': 450,\n",
       " '같다': 451,\n",
       " '입력': 452,\n",
       " '구': 453,\n",
       " '문제가': 454,\n",
       " '자동': 455,\n",
       " '학생들의': 456,\n",
       " '직접': 457,\n",
       " '토대로': 458,\n",
       " '영향': 459,\n",
       " '학생': 460,\n",
       " '등이': 461,\n",
       " '제공하는': 462,\n",
       " '기술적': 463,\n",
       " '시대의': 464,\n",
       " '않은': 465,\n",
       " '차이가': 466,\n",
       " '제안한': 467,\n",
       " '파악': 468,\n",
       " '이상': 469,\n",
       " '이후': 470,\n",
       " '우리나라': 471,\n",
       " '하게': 472,\n",
       " '시작': 473,\n",
       " '제안된': 474,\n",
       " '현': 475,\n",
       " '유의': 476,\n",
       " '학습을': 477,\n",
       " '방향을': 478,\n",
       " '감정': 479,\n",
       " '형성': 480,\n",
       " '신경망': 481,\n",
       " '별': 482,\n",
       " '많이': 483,\n",
       " '같이': 484,\n",
       " '사이버': 485,\n",
       " '위치': 486,\n",
       " '동시에': 487,\n",
       " '인한': 488,\n",
       " '되지': 489,\n",
       " '화된': 490,\n",
       " '기업': 491,\n",
       " '프로그램을': 492,\n",
       " '측면': 493,\n",
       " '에도': 494,\n",
       " '혁신': 495,\n",
       " '방법은': 496,\n",
       " '유형': 497,\n",
       " '적합한': 498,\n",
       " '실험을': 499,\n",
       " '변화에': 500,\n",
       " '교사': 501,\n",
       " '시스템은': 502,\n",
       " '법률': 503,\n",
       " '플랫폼': 504,\n",
       " '연계': 505,\n",
       " '영역': 506,\n",
       " '기대': 507,\n",
       " '사례를': 508,\n",
       " '마지막으로': 509,\n",
       " '의사결정': 510,\n",
       " '이루어지': 511,\n",
       " '어떠한': 512,\n",
       " '상호': 513,\n",
       " '상': 514,\n",
       " '선정': 515,\n",
       " '설정': 516,\n",
       " '제어': 517,\n",
       " '면': 518,\n",
       " '개별': 519,\n",
       " '가치': 520,\n",
       " '등에': 521,\n",
       " '고찰': 522,\n",
       " '알': 523,\n",
       " '통신': 524,\n",
       " '단어': 525,\n",
       " '기능을': 526,\n",
       " '관련하여': 527,\n",
       " '컴퓨팅': 528,\n",
       " '스마트폰': 529,\n",
       " '언어': 530,\n",
       " '전문': 531,\n",
       " '특정': 532,\n",
       " '시킬': 533,\n",
       " '계산': 534,\n",
       " '인공지능은': 535,\n",
       " '결합': 536,\n",
       " '우선': 537,\n",
       " '교수학습': 538,\n",
       " '과제': 539,\n",
       " '수학': 540,\n",
       " '었다': 541,\n",
       " '학습자': 542,\n",
       " '더불어': 543,\n",
       " '로봇의': 544,\n",
       " '발달': 545,\n",
       " '능력': 546,\n",
       " '점을': 547,\n",
       " '있지만': 548,\n",
       " '내': 549,\n",
       " '감소': 550,\n",
       " '모형': 551,\n",
       " '시간': 552,\n",
       " '인공': 553,\n",
       " '창의성': 554,\n",
       " '문장': 555,\n",
       " '모색': 556,\n",
       " '중국': 557,\n",
       " '방식을': 558,\n",
       " '책임': 559,\n",
       " '라고': 560,\n",
       " '금융': 561,\n",
       " '않고': 562,\n",
       " '분야에': 563,\n",
       " '글쓰기': 564,\n",
       " '보인다': 565,\n",
       " '발생하는': 566,\n",
       " '효과적인': 567,\n",
       " '전자': 568,\n",
       " '구조': 569,\n",
       " '특징을': 570,\n",
       " '없이': 571,\n",
       " '차원': 572,\n",
       " '나아가': 573,\n",
       " '지능형': 574,\n",
       " '협력': 575,\n",
       " '가치를': 576,\n",
       " '응용': 577,\n",
       " '효과적으로': 578,\n",
       " '공유': 579,\n",
       " '부분': 580,\n",
       " '검색': 581,\n",
       " '확인할': 582,\n",
       " '아닌': 583,\n",
       " '기술은': 584,\n",
       " '없다': 585,\n",
       " '소비자': 586,\n",
       " '에서도': 587,\n",
       " '권리': 588,\n",
       " '시대': 589,\n",
       " '주로': 590,\n",
       " '교육과정': 591,\n",
       " '자동차': 592,\n",
       " '클라우드': 593,\n",
       " '기본': 594,\n",
       " '위험': 595,\n",
       " '검출': 596,\n",
       " '사례': 597,\n",
       " '단계': 598,\n",
       " '약': 599,\n",
       " '살펴보았다': 600,\n",
       " '러닝': 601,\n",
       " '하도록': 602,\n",
       " '능력을': 603,\n",
       " '하거나': 604,\n",
       " '잘': 605,\n",
       " '목적으로': 606,\n",
       " '성과': 607,\n",
       " '우리는': 608,\n",
       " '가상': 609,\n",
       " '중심의': 610,\n",
       " '윤리적': 611,\n",
       " '확산': 612,\n",
       " '정보의': 613,\n",
       " '윤리': 614,\n",
       " '과의': 615,\n",
       " '함에': 616,\n",
       " '있게': 617,\n",
       " '기술과': 618,\n",
       " '목적을': 619,\n",
       " '탐구': 620,\n",
       " '학생들이': 621,\n",
       " '진행되고': 622,\n",
       " '효과': 623,\n",
       " '혹은': 624,\n",
       " '미국': 625,\n",
       " '모델은': 626,\n",
       " '인간이': 627,\n",
       " '않는': 628,\n",
       " '고려하여': 629,\n",
       " '력': 630,\n",
       " '강조': 631,\n",
       " '과학기술': 632,\n",
       " '수용': 633,\n",
       " '시사점을': 634,\n",
       " '산업의': 635,\n",
       " '방법으로': 636,\n",
       " '목적': 637,\n",
       " '영화': 638,\n",
       " '인정': 639,\n",
       " '개인의': 640,\n",
       " '역할': 641,\n",
       " '객체': 642,\n",
       " '반영': 643,\n",
       " '추정': 644,\n",
       " '블록체인': 645,\n",
       " '스스로': 646,\n",
       " '6': 647,\n",
       " '현대': 648,\n",
       " '통해서': 649,\n",
       " '차량': 650,\n",
       " '창작': 651,\n",
       " '좋은': 652,\n",
       " '주장': 653,\n",
       " '활성화': 654,\n",
       " '중에서': 655,\n",
       " '기법': 656,\n",
       " '사용하는': 657,\n",
       " '연구결과': 658,\n",
       " '서로': 659,\n",
       " '요소를': 660,\n",
       " '실시간': 661,\n",
       " '진단': 662,\n",
       " '하면': 663,\n",
       " '강화': 664,\n",
       " '실행': 665,\n",
       " '문제해결': 666,\n",
       " '양성': 667,\n",
       " '과정': 668,\n",
       " '분석한': 669,\n",
       " '이런': 670,\n",
       " '방법이': 671,\n",
       " '모니터링': 672,\n",
       " '요소': 673,\n",
       " '사': 674,\n",
       " '속에서': 675,\n",
       " '상태': 676,\n",
       " '주목': 677,\n",
       " '향상을': 678,\n",
       " '역량을': 679,\n",
       " '이들': 680,\n",
       " '있다고': 681,\n",
       " '이론적': 682,\n",
       " '식': 683,\n",
       " '집중': 684,\n",
       " '이미': 685,\n",
       " '아직': 686,\n",
       " '추가': 687,\n",
       " '안전': 688,\n",
       " '개념을': 689,\n",
       " '한국어': 690,\n",
       " '평가를': 691,\n",
       " '줄': 692,\n",
       " '한편': 693,\n",
       " '유의미한': 694,\n",
       " '기업의': 695,\n",
       " '대상': 696,\n",
       " '가능성이': 697,\n",
       " '개발된': 698,\n",
       " '학습자의': 699,\n",
       " '하나의': 700,\n",
       " '있기': 701,\n",
       " '종합': 702,\n",
       " '웹': 703,\n",
       " '활용하는': 704,\n",
       " '접목': 705,\n",
       " '경제': 706,\n",
       " '시각': 707,\n",
       " '첨단': 708,\n",
       " '빅': 709,\n",
       " '현장': 710,\n",
       " '보조공학': 711,\n",
       " '가진': 712,\n",
       " '초기': 713,\n",
       " '되기': 714,\n",
       " '드론': 715,\n",
       " '모형의': 716,\n",
       " '교육에': 717,\n",
       " '개정': 718,\n",
       " '프로젝트': 719,\n",
       " '추천': 720,\n",
       " '창의': 721,\n",
       " '시장': 722,\n",
       " '각각': 723,\n",
       " '지역': 724,\n",
       " '것인지': 725,\n",
       " '자신의': 726,\n",
       " '변화가': 727,\n",
       " '주제': 728,\n",
       " '진로': 729,\n",
       " '구분': 730,\n",
       " '법': 731,\n",
       " '데이터에': 732,\n",
       " '기대한다': 733,\n",
       " '체험': 734,\n",
       " '우수한': 735,\n",
       " '배경': 736,\n",
       " '창출': 737,\n",
       " '어려운': 738,\n",
       " '방식으로': 739,\n",
       " '효율적인': 740,\n",
       " '실현': 741,\n",
       " '논문에서': 742,\n",
       " '되었으며': 743,\n",
       " '장애': 744,\n",
       " '대학의': 745,\n",
       " '낮은': 746,\n",
       " '불구하고': 747,\n",
       " '갖는': 748,\n",
       " '살펴보고': 749,\n",
       " '에너지': 750,\n",
       " '적절한': 751,\n",
       " '대비': 752,\n",
       " '한계를': 753,\n",
       " '데이터가': 754,\n",
       " '의미를': 755,\n",
       " '물론': 756,\n",
       " '통계적': 757,\n",
       " '보완': 758,\n",
       " '높게': 759,\n",
       " '예상': 760,\n",
       " '유사한': 761,\n",
       " '관점': 762,\n",
       " '국제': 763,\n",
       " '수정': 764,\n",
       " '교육이': 765,\n",
       " '자동화': 766,\n",
       " '달성': 767,\n",
       " '집단': 768,\n",
       " '도덕': 769,\n",
       " '왔다': 770,\n",
       " '기술에': 771,\n",
       " '전송': 772,\n",
       " '공공': 773,\n",
       " '앞으로': 774,\n",
       " '쟁점': 775,\n",
       " '수업을': 776,\n",
       " '해석': 777,\n",
       " '사회의': 778,\n",
       " '상황에서': 779,\n",
       " '수집된': 780,\n",
       " '아니': 781,\n",
       " '시뮬레이션': 782,\n",
       " '효율적으로': 783,\n",
       " '사람': 784,\n",
       " '대체': 785,\n",
       " '미디어': 786,\n",
       " '발견': 787,\n",
       " '명의': 788,\n",
       " '교육적': 789,\n",
       " '형태의': 790,\n",
       " '전통적인': 791,\n",
       " '부여': 792,\n",
       " '다중': 793,\n",
       " '서비스의': 794,\n",
       " '환경을': 795,\n",
       " '영역에서': 796,\n",
       " '추론': 797,\n",
       " '달리': 798,\n",
       " '필요성': 799,\n",
       " '형태로': 800,\n",
       " '하여야': 801,\n",
       " '최적화': 802,\n",
       " '되면서': 803,\n",
       " '차이를': 804,\n",
       " '유지': 805,\n",
       " '뿐만': 806,\n",
       " '패턴': 807,\n",
       " '관심이': 808,\n",
       " '설치': 809,\n",
       " '역시': 810,\n",
       " '구체적으로': 811,\n",
       " '방법에': 812,\n",
       " '피드백': 813,\n",
       " '지만': 814,\n",
       " '지식을': 815,\n",
       " '최종': 816,\n",
       " '그에': 817,\n",
       " '소통': 818,\n",
       " '포스트휴먼': 819,\n",
       " '기기': 820,\n",
       " '전망': 821,\n",
       " '신체': 822,\n",
       " '요인': 823,\n",
       " '노력': 824,\n",
       " '사이의': 825,\n",
       " '영역을': 826,\n",
       " '수준': 827,\n",
       " '등으로': 828,\n",
       " '10': 829,\n",
       " '이상의': 830,\n",
       " '도움이': 831,\n",
       " '으로는': 832,\n",
       " '생활': 833,\n",
       " '구체적인': 834,\n",
       " '상황을': 835,\n",
       " '발전에': 836,\n",
       " '넷째': 837,\n",
       " '있으나': 838,\n",
       " '소개': 839,\n",
       " '개발을': 840,\n",
       " '작성': 841,\n",
       " '긍정적인': 842,\n",
       " '침해': 843,\n",
       " '본질': 844,\n",
       " '전략을': 845,\n",
       " '무선': 846,\n",
       " '수준의': 847,\n",
       " '하나인': 848,\n",
       " '명을': 849,\n",
       " '식별': 850,\n",
       " '속': 851,\n",
       " '문제에': 852,\n",
       " '검사': 853,\n",
       " '논의가': 854,\n",
       " '만을': 855,\n",
       " '새롭게': 856,\n",
       " '계': 857,\n",
       " '게임': 858,\n",
       " '인하여': 859,\n",
       " '문서': 860,\n",
       " '현행': 861,\n",
       " '방식': 862,\n",
       " '우리의': 863,\n",
       " '연구에': 864,\n",
       " '것에': 865,\n",
       " '실천': 866,\n",
       " '빠르게': 867,\n",
       " '이용해': 868,\n",
       " '챗봇': 869,\n",
       " '속성': 870,\n",
       " '국내외': 871,\n",
       " '전략': 872,\n",
       " '활용되고': 873,\n",
       " '인식을': 874,\n",
       " '의의': 875,\n",
       " '대표적인': 876,\n",
       " '번째': 877,\n",
       " '추진': 878,\n",
       " '경제적': 879,\n",
       " '사용자가': 880,\n",
       " '점이': 881,\n",
       " '응답': 882,\n",
       " '시켜': 883,\n",
       " '지속적으로': 884,\n",
       " '대해서는': 885,\n",
       " '하나': 886,\n",
       " '군집': 887,\n",
       " '현재의': 888,\n",
       " '도시': 889,\n",
       " '관심을': 890,\n",
       " '근거': 891,\n",
       " '보았다': 892,\n",
       " '직업': 893,\n",
       " '선행': 894,\n",
       " '논의를': 895,\n",
       " '기': 896,\n",
       " '변수': 897,\n",
       " '특허': 898,\n",
       " '되며': 899,\n",
       " '의사소통': 900,\n",
       " '않다': 901,\n",
       " '제한': 902,\n",
       " '파악하고': 903,\n",
       " '데이터는': 904,\n",
       " '알고리즘의': 905,\n",
       " '작동': 906,\n",
       " '도로': 907,\n",
       " '방법의': 908,\n",
       " '실정': 909,\n",
       " '표준': 910,\n",
       " '구조를': 911,\n",
       " '긍정적': 912,\n",
       " '과거': 913,\n",
       " '주는': 914,\n",
       " '대부분': 915,\n",
       " '함을': 916,\n",
       " '진화': 917,\n",
       " '문제는': 918,\n",
       " '하려는': 919,\n",
       " '도덕적': 920,\n",
       " '반면': 921,\n",
       " '중요하다': 922,\n",
       " '경험을': 923,\n",
       " '상대적으로': 924,\n",
       " '딥': 925,\n",
       " '작업': 926,\n",
       " '전력': 927,\n",
       " '저장': 928,\n",
       " '동작': 929,\n",
       " '인공신경망': 930,\n",
       " '필요성이': 931,\n",
       " '테스트': 932,\n",
       " '생명': 933,\n",
       " '도출하': 934,\n",
       " '환경에': 935,\n",
       " '목적이': 936,\n",
       " '시키기': 937,\n",
       " '성능이': 938,\n",
       " '지적': 939,\n",
       " '활발히': 940,\n",
       " '오늘날': 941,\n",
       " '마음': 942,\n",
       " '자연': 943,\n",
       " '테크놀로지': 944,\n",
       " '규정': 945,\n",
       " '오류': 946,\n",
       " '정확한': 947,\n",
       " '것': 948,\n",
       " '훈련': 949,\n",
       " '목표': 950,\n",
       " '증대': 951,\n",
       " '이미지를': 952,\n",
       " '값을': 953,\n",
       " '어느': 954,\n",
       " '보장': 955,\n",
       " '논문': 956,\n",
       " '일부': 957,\n",
       " '으로서': 958,\n",
       " '실시간으로': 959,\n",
       " '프라이버시': 960,\n",
       " '받고': 961,\n",
       " '학습에': 962,\n",
       " '보다는': 963,\n",
       " '시대를': 964,\n",
       " '포함한': 965,\n",
       " '인성': 966,\n",
       " '교육공학': 967,\n",
       " '공할': 968,\n",
       " '20': 969,\n",
       " '기반한': 970,\n",
       " '웨어러블': 971,\n",
       " '시키는': 972,\n",
       " '서버': 973,\n",
       " '준비': 974,\n",
       " '기준': 975,\n",
       " '되었고': 976,\n",
       " '촉진': 977,\n",
       " '시키고': 978,\n",
       " '인간을': 979,\n",
       " '번역': 980,\n",
       " '프로그래밍': 981,\n",
       " '분석하는': 982,\n",
       " '문헌': 983,\n",
       " '수도': 984,\n",
       " '영역에': 985,\n",
       " '자율': 986,\n",
       " '점': 987,\n",
       " '제조': 988,\n",
       " '고려한': 989,\n",
       " '현장에서': 990,\n",
       " '파악하': 991,\n",
       " '입법': 992,\n",
       " '증강현실': 993,\n",
       " '야기': 994,\n",
       " '도움을': 995,\n",
       " '계획': 996,\n",
       " '책임을': 997,\n",
       " '갖고': 998,\n",
       " '투자': 999,\n",
       " '비교하여': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41225 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x188b72e95c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2805 samples, validate on 935 samples\n",
      "Epoch 1/30\n",
      "2805/2805 [==============================] - 78s 28ms/step - loss: 4.7364 - val_loss: 4.0727\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_ls16_v4_01_4.07274.h5\n",
      "Epoch 2/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 2.7191 - val_loss: 2.5449\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_ls16_v4_02_2.54489.h5\n",
      "Epoch 3/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 2.4927 - val_loss: 2.1650\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_ls16_v4_03_2.16500.h5\n",
      "Epoch 4/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 2.3634 - val_loss: 2.2237\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_ls16_v4_04_2.22366.h5\n",
      "Epoch 5/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 2.2584 - val_loss: 2.0149\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_ls16_v4_05_2.01493.h5\n",
      "Epoch 6/30\n",
      "2805/2805 [==============================] - 78s 28ms/step - loss: 2.1218 - val_loss: 2.1488\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_ls16_v4_06_2.14884.h5\n",
      "Epoch 7/30\n",
      "2805/2805 [==============================] - 77s 28ms/step - loss: 2.0725 - val_loss: 2.0596\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_ls16_v4_07_2.05956.h5\n",
      "Epoch 8/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 1.9739 - val_loss: 1.9684\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_ls16_v4_08_1.96835.h5\n",
      "Epoch 9/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 1.8966 - val_loss: 2.2362\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_ls16_v4_09_2.23621.h5\n",
      "Epoch 10/30\n",
      "2805/2805 [==============================] - 78s 28ms/step - loss: 1.8479 - val_loss: 2.0853\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_ls16_v4_10_2.08532.h5\n",
      "Epoch 11/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 1.7479 - val_loss: 2.0673\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_ls16_v4_11_2.06734.h5\n",
      "Epoch 12/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 1.6545 - val_loss: 2.1150\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_rae_ls16_v4_12_2.11498.h5\n",
      "Epoch 13/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.6081 - val_loss: 2.0800\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_rae_ls16_v4_13_2.08004.h5\n",
      "time : 1006.4000337123871\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(16)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_ls16_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4364000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                816       \n",
      "=================================================================\n",
      "Total params: 4,712,166\n",
      "Trainable params: 589,166\n",
      "Non-trainable params: 4,123,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_ls16_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_ls16_v4_08_1.96835.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0426910863203163"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5877047 , 0.655882  , 2.9748971 , ..., 2.3856435 , 2.2583268 ,\n",
       "        1.5697037 ],\n",
       "       [3.1491299 , 2.8000815 , 1.9792254 , ..., 1.1267407 , 4.8781877 ,\n",
       "        0.79607457],\n",
       "       [3.2522893 , 1.840681  , 2.8130488 , ..., 2.6725903 , 2.9727693 ,\n",
       "        1.26777   ],\n",
       "       ...,\n",
       "       [3.026676  , 0.7008332 , 2.6572478 , ..., 3.2219236 , 2.3558013 ,\n",
       "        3.289198  ],\n",
       "       [2.7958148 , 0.9271275 , 1.8118439 , ..., 2.4751315 , 3.2245324 ,\n",
       "        2.844216  ],\n",
       "       [2.6588318 , 1.8325435 , 3.6663916 , ..., 2.9123805 , 3.3831742 ,\n",
       "        0.78095835]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_ls16_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.1908731e-03, 1.5093510e-03, 1.3345811e-05, ..., 1.4684700e-04,\n",
       "        5.1765365e-08, 1.0515798e-06],\n",
       "       [4.5478460e-12, 4.0790130e-07, 3.3546134e-19, ..., 1.1384449e-08,\n",
       "        1.3694077e-12, 2.5205482e-08],\n",
       "       [1.4555247e-06, 1.0722706e-05, 1.1634500e-12, ..., 7.0246288e-06,\n",
       "        2.9001784e-10, 2.7274299e-07],\n",
       "       ...,\n",
       "       [1.1095419e-04, 2.0534711e-04, 7.8423676e-05, ..., 1.8566544e-06,\n",
       "        2.5801194e-08, 1.9196086e-06],\n",
       "       [2.6655300e-07, 4.4628949e-05, 9.5080444e-11, ..., 2.9165548e-07,\n",
       "        2.2072473e-07, 1.6658953e-06],\n",
       "       [3.5531439e-03, 7.3390351e-05, 4.0440651e-09, ..., 1.3531691e-07,\n",
       "        1.7572715e-12, 1.2349618e-06]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3D프린팅</th>\n",
       "      <th>4차산업</th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>STEAM교육</th>\n",
       "      <th>가상현실</th>\n",
       "      <th>감성</th>\n",
       "      <th>감성분석</th>\n",
       "      <th>감정</th>\n",
       "      <th>강한인공지능</th>\n",
       "      <th>강화학습</th>\n",
       "      <th>...</th>\n",
       "      <th>핀테크</th>\n",
       "      <th>학습</th>\n",
       "      <th>학습동기</th>\n",
       "      <th>학습성과</th>\n",
       "      <th>학업성취도</th>\n",
       "      <th>합성곱신경망</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>헬스케어</th>\n",
       "      <th>혁신</th>\n",
       "      <th>협업</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3D프린팅  4차산업  4차산업혁명  STEAM교육  가상현실  감성  감성분석  감정  강한인공지능  강화학습  ...  핀테크  \\\n",
       "0        0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "1        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "2        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "3        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "4        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "..     ...   ...     ...      ...   ...  ..   ...  ..     ...   ...  ...  ...   \n",
       "930      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "931      0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "932      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "933      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "934      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "\n",
       "     학습  학습동기  학습성과  학업성취도  합성곱신경망  핵심역량  헬스케어  혁신  협업  \n",
       "0     0     0     0      0       0     0     0   0   0  \n",
       "1     0     0     0      0       0     0     0   0   0  \n",
       "2     0     0     0      0       0     0     0   0   0  \n",
       "3     0     0     0      0       0     0     0   0   0  \n",
       "4     0     0     0      0       0     0     0   0   0  \n",
       "..   ..   ...   ...    ...     ...   ...   ...  ..  ..  \n",
       "930   0     0     0      0       0     0     0   0   0  \n",
       "931   0     0     0      0       0     0     0   0   0  \n",
       "932   0     0     0      0       0     0     0   0   0  \n",
       "933   0     0     0      0       0     0     0   0   0  \n",
       "934   0     0     0      0       0     0     0   0   0  \n",
       "\n",
       "[935 rows x 262 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/paper_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(935, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.09090909090909091\n",
      "precision :  0.48741007194244607\n",
      "recall :  0.16315472606863335\n",
      "f1 :  0.24447451511050974\n",
      "------------------------\n",
      "hamming_loss :  0.006837571947585419\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.09090909090909091\n",
      "precision :  0.28502673796791445\n",
      "recall :  0.17147950089126557\n",
      "f1 :  0.20254138018843904\n",
      "------------------------\n",
      "hamming_loss :  0.006837571947585419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
