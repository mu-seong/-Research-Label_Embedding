{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15327170042330673793\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13847441288646197943\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6035836830993235666\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1941359885872091141\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_ls64_v1_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_ls64_v1_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_ls64_v1_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...</td>\n",
       "      <td>1.859065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768482</td>\n",
       "      <td>4.208251</td>\n",
       "      <td>0.299953</td>\n",
       "      <td>1.829271</td>\n",
       "      <td>0.549787</td>\n",
       "      <td>0.875938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068475</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>4.023951</td>\n",
       "      <td>0.933374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.543880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.928553</td>\n",
       "      <td>1.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...</td>\n",
       "      <td>1.503368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.671269</td>\n",
       "      <td>3.332441</td>\n",
       "      <td>0.379955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420594</td>\n",
       "      <td>2.498717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494116</td>\n",
       "      <td>3.401626</td>\n",
       "      <td>1.402863</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.646207</td>\n",
       "      <td>3.521524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.554926</td>\n",
       "      <td>0.882358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...</td>\n",
       "      <td>2.819702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104125</td>\n",
       "      <td>4.511050</td>\n",
       "      <td>2.193634</td>\n",
       "      <td>2.065551</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>3.954691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989702</td>\n",
       "      <td>0.368869</td>\n",
       "      <td>2.444483</td>\n",
       "      <td>0.601464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.300735</td>\n",
       "      <td>5.817879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816709</td>\n",
       "      <td>4.201205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...</td>\n",
       "      <td>0.950928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.743537</td>\n",
       "      <td>2.777191</td>\n",
       "      <td>1.854041</td>\n",
       "      <td>3.136917</td>\n",
       "      <td>1.585593</td>\n",
       "      <td>1.659128</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188068</td>\n",
       "      <td>1.046049</td>\n",
       "      <td>2.570028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.579502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306474</td>\n",
       "      <td>0.238258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...</td>\n",
       "      <td>2.429588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.151260</td>\n",
       "      <td>3.216333</td>\n",
       "      <td>0.784559</td>\n",
       "      <td>1.691281</td>\n",
       "      <td>0.430679</td>\n",
       "      <td>1.358677</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214011</td>\n",
       "      <td>1.853834</td>\n",
       "      <td>1.531043</td>\n",
       "      <td>1.683950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.088216</td>\n",
       "      <td>2.837656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.549347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2800</td>\n",
       "      <td>딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...</td>\n",
       "      <td>0.542204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.601285</td>\n",
       "      <td>1.840448</td>\n",
       "      <td>0.389547</td>\n",
       "      <td>2.070192</td>\n",
       "      <td>1.202173</td>\n",
       "      <td>2.518716</td>\n",
       "      <td>...</td>\n",
       "      <td>3.306703</td>\n",
       "      <td>3.799414</td>\n",
       "      <td>3.557182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.503757</td>\n",
       "      <td>3.547506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.004233</td>\n",
       "      <td>0.131174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>2801</td>\n",
       "      <td>본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...</td>\n",
       "      <td>3.664947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626962</td>\n",
       "      <td>0.581019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.856927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.518692</td>\n",
       "      <td>0.560103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.743693</td>\n",
       "      <td>2.647182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689267</td>\n",
       "      <td>2.292974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2802</td>\n",
       "      <td>인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...</td>\n",
       "      <td>1.139739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.887890</td>\n",
       "      <td>1.844434</td>\n",
       "      <td>0.978103</td>\n",
       "      <td>2.868803</td>\n",
       "      <td>0.405209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.259139</td>\n",
       "      <td>1.710425</td>\n",
       "      <td>1.534153</td>\n",
       "      <td>0.711135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.237338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.731840</td>\n",
       "      <td>0.737280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2803</td>\n",
       "      <td>인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...</td>\n",
       "      <td>1.893398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.758515</td>\n",
       "      <td>3.033492</td>\n",
       "      <td>0.736422</td>\n",
       "      <td>1.959595</td>\n",
       "      <td>0.711334</td>\n",
       "      <td>1.353843</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361314</td>\n",
       "      <td>1.530630</td>\n",
       "      <td>3.216768</td>\n",
       "      <td>1.008312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.007342</td>\n",
       "      <td>1.402147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.390691</td>\n",
       "      <td>1.366772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2804</td>\n",
       "      <td>현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...</td>\n",
       "      <td>3.141152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213001</td>\n",
       "      <td>0.129726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561627</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.534352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198416</td>\n",
       "      <td>0.635571</td>\n",
       "      <td>1.127186</td>\n",
       "      <td>1.118183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.681765</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970372</td>\n",
       "      <td>0.817302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...  1.859065   \n",
       "1              1  고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...  1.503368   \n",
       "2              2  마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...  2.819702   \n",
       "3              3  현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...  0.950928   \n",
       "4              4  최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...  2.429588   \n",
       "...          ...                                                ...       ...   \n",
       "2800        2800  딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...  0.542204   \n",
       "2801        2801  본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...  3.664947   \n",
       "2802        2802  인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...  1.139739   \n",
       "2803        2803  인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...  1.893398   \n",
       "2804        2804  현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...  3.141152   \n",
       "\n",
       "        1         2         3         4         5         6         7  ...  \\\n",
       "0     0.0  0.768482  4.208251  0.299953  1.829271  0.549787  0.875938  ...   \n",
       "1     0.0  1.671269  3.332441  0.379955  0.000000  0.420594  2.498717  ...   \n",
       "2     0.0  1.104125  4.511050  2.193634  2.065551  0.699897  3.954691  ...   \n",
       "3     0.0  2.743537  2.777191  1.854041  3.136917  1.585593  1.659128  ...   \n",
       "4     0.0  2.151260  3.216333  0.784559  1.691281  0.430679  1.358677  ...   \n",
       "...   ...       ...       ...       ...       ...       ...       ...  ...   \n",
       "2800  0.0  2.601285  1.840448  0.389547  2.070192  1.202173  2.518716  ...   \n",
       "2801  0.0  0.626962  0.581019  0.000000  2.856927  0.000000  0.145338  ...   \n",
       "2802  0.0  2.887890  1.844434  0.978103  2.868803  0.405209  0.000000  ...   \n",
       "2803  0.0  2.758515  3.033492  0.736422  1.959595  0.711334  1.353843  ...   \n",
       "2804  0.0  1.213001  0.129726  0.000000  0.561627  0.769634  0.534352  ...   \n",
       "\n",
       "            54        55        56        57   58        59        60   61  \\\n",
       "0     1.068475  0.988764  4.023951  0.933374  0.0  2.543880  0.000000  0.0   \n",
       "1     0.494116  3.401626  1.402863  0.709119  0.0  4.646207  3.521524  0.0   \n",
       "2     1.989702  0.368869  2.444483  0.601464  0.0  3.300735  5.817879  0.0   \n",
       "3     2.188068  1.046049  2.570028  0.000000  0.0  0.000000  1.579502  0.0   \n",
       "4     1.214011  1.853834  1.531043  1.683950  0.0  5.088216  2.837656  0.0   \n",
       "...        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "2800  3.306703  3.799414  3.557182  0.000000  0.0  1.503757  3.547506  0.0   \n",
       "2801  0.645899  0.000000  1.518692  0.560103  0.0  1.743693  2.647182  0.0   \n",
       "2802  2.259139  1.710425  1.534153  0.711135  0.0  0.000000  1.237338  0.0   \n",
       "2803  2.361314  1.530630  3.216768  1.008312  0.0  2.007342  1.402147  0.0   \n",
       "2804  1.198416  0.635571  1.127186  1.118183  0.0  3.681765  0.985598  0.0   \n",
       "\n",
       "            62        63  \n",
       "0     2.928553  1.043881  \n",
       "1     1.554926  0.882358  \n",
       "2     0.816709  4.201205  \n",
       "3     4.306474  0.238258  \n",
       "4     0.000000  1.549347  \n",
       "...        ...       ...  \n",
       "2800  5.004233  0.131174  \n",
       "2801  0.689267  2.292974  \n",
       "2802  2.731840  0.737280  \n",
       "2803  2.390691  1.366772  \n",
       "2804  0.970372  0.817302  \n",
       "\n",
       "[2805 rows x 66 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...</td>\n",
       "      <td>0.975564</td>\n",
       "      <td>0</td>\n",
       "      <td>1.698603</td>\n",
       "      <td>0.825450</td>\n",
       "      <td>0.679568</td>\n",
       "      <td>1.048623</td>\n",
       "      <td>0.548835</td>\n",
       "      <td>2.351269</td>\n",
       "      <td>...</td>\n",
       "      <td>2.731234</td>\n",
       "      <td>1.499718</td>\n",
       "      <td>1.009095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.342696</td>\n",
       "      <td>3.852439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.449900</td>\n",
       "      <td>1.319041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...</td>\n",
       "      <td>2.146861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.251596</td>\n",
       "      <td>1.369750</td>\n",
       "      <td>0.216136</td>\n",
       "      <td>0.251116</td>\n",
       "      <td>0.649305</td>\n",
       "      <td>1.678851</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310529</td>\n",
       "      <td>1.904618</td>\n",
       "      <td>0.407024</td>\n",
       "      <td>1.961398</td>\n",
       "      <td>0</td>\n",
       "      <td>3.935543</td>\n",
       "      <td>2.119132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...</td>\n",
       "      <td>0.334722</td>\n",
       "      <td>0</td>\n",
       "      <td>1.767782</td>\n",
       "      <td>5.394941</td>\n",
       "      <td>1.133812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333045</td>\n",
       "      <td>3.623545</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847691</td>\n",
       "      <td>2.218239</td>\n",
       "      <td>2.552304</td>\n",
       "      <td>0.413375</td>\n",
       "      <td>0</td>\n",
       "      <td>4.027470</td>\n",
       "      <td>2.335804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130540</td>\n",
       "      <td>1.486040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...</td>\n",
       "      <td>1.878717</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237748</td>\n",
       "      <td>4.948579</td>\n",
       "      <td>0.375578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.519852</td>\n",
       "      <td>3.323231</td>\n",
       "      <td>...</td>\n",
       "      <td>2.630978</td>\n",
       "      <td>2.885851</td>\n",
       "      <td>2.300232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.668746</td>\n",
       "      <td>1.966404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.454632</td>\n",
       "      <td>1.750944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...</td>\n",
       "      <td>4.101379</td>\n",
       "      <td>0</td>\n",
       "      <td>2.606388</td>\n",
       "      <td>0.981125</td>\n",
       "      <td>0.366505</td>\n",
       "      <td>1.759244</td>\n",
       "      <td>0.956917</td>\n",
       "      <td>2.015815</td>\n",
       "      <td>...</td>\n",
       "      <td>3.832008</td>\n",
       "      <td>1.800635</td>\n",
       "      <td>1.561169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.870930</td>\n",
       "      <td>2.288014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.869269</td>\n",
       "      <td>1.738205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...</td>\n",
       "      <td>1.802560</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587461</td>\n",
       "      <td>4.627356</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>1.724201</td>\n",
       "      <td>0.587015</td>\n",
       "      <td>2.908261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218225</td>\n",
       "      <td>2.083348</td>\n",
       "      <td>2.934301</td>\n",
       "      <td>0.435996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.133583</td>\n",
       "      <td>3.076900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.287173</td>\n",
       "      <td>1.056643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...</td>\n",
       "      <td>1.893398</td>\n",
       "      <td>0</td>\n",
       "      <td>2.758515</td>\n",
       "      <td>3.033492</td>\n",
       "      <td>0.736422</td>\n",
       "      <td>1.959596</td>\n",
       "      <td>0.711334</td>\n",
       "      <td>1.353843</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361314</td>\n",
       "      <td>1.530629</td>\n",
       "      <td>3.216768</td>\n",
       "      <td>1.008312</td>\n",
       "      <td>0</td>\n",
       "      <td>2.007342</td>\n",
       "      <td>1.402147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.390692</td>\n",
       "      <td>1.366772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...</td>\n",
       "      <td>2.929448</td>\n",
       "      <td>0</td>\n",
       "      <td>4.444677</td>\n",
       "      <td>1.866635</td>\n",
       "      <td>0.987381</td>\n",
       "      <td>2.167695</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>0.628170</td>\n",
       "      <td>...</td>\n",
       "      <td>2.969559</td>\n",
       "      <td>1.926105</td>\n",
       "      <td>2.365925</td>\n",
       "      <td>1.031104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.788936</td>\n",
       "      <td>1.801119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952480</td>\n",
       "      <td>1.872088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...</td>\n",
       "      <td>2.217202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.284184</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>2.797025</td>\n",
       "      <td>0.396394</td>\n",
       "      <td>0.244705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564461</td>\n",
       "      <td>2.156883</td>\n",
       "      <td>0.778674</td>\n",
       "      <td>0</td>\n",
       "      <td>3.706711</td>\n",
       "      <td>2.157487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976887</td>\n",
       "      <td>0.974419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...</td>\n",
       "      <td>0.950928</td>\n",
       "      <td>0</td>\n",
       "      <td>2.743537</td>\n",
       "      <td>2.777190</td>\n",
       "      <td>1.854041</td>\n",
       "      <td>3.136917</td>\n",
       "      <td>1.585593</td>\n",
       "      <td>1.659128</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188068</td>\n",
       "      <td>1.046049</td>\n",
       "      <td>2.570028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.579502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306475</td>\n",
       "      <td>0.238258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...  0.975564   \n",
       "1             1  최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...  2.146861   \n",
       "2             2  가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...  0.334722   \n",
       "3             3  문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...  1.878717   \n",
       "4             4  최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...  4.101379   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...  1.802560   \n",
       "931         931  제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...  1.893398   \n",
       "932         932  초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...  2.929448   \n",
       "933         933  사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...  2.217202   \n",
       "934         934  이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...  0.950928   \n",
       "\n",
       "     1         2         3         4         5         6         7  ...  \\\n",
       "0    0  1.698603  0.825450  0.679568  1.048623  0.548835  2.351269  ...   \n",
       "1    0  2.251596  1.369750  0.216136  0.251116  0.649305  1.678851  ...   \n",
       "2    0  1.767782  5.394941  1.133812  0.000000  1.333045  3.623545  ...   \n",
       "3    0  0.237748  4.948579  0.375578  0.000000  1.519852  3.323231  ...   \n",
       "4    0  2.606388  0.981125  0.366505  1.759244  0.956917  2.015815  ...   \n",
       "..  ..       ...       ...       ...       ...       ...       ...  ...   \n",
       "930  0  1.587461  4.627356  0.498222  1.724201  0.587015  2.908261  ...   \n",
       "931  0  2.758515  3.033492  0.736422  1.959596  0.711334  1.353843  ...   \n",
       "932  0  4.444677  1.866635  0.987381  2.167695  0.171970  0.628170  ...   \n",
       "933  0  0.000000  5.284184  0.014590  2.797025  0.396394  0.244705  ...   \n",
       "934  0  2.743537  2.777190  1.854041  3.136917  1.585593  1.659128  ...   \n",
       "\n",
       "           54        55        56        57  58        59        60   61  \\\n",
       "0    2.731234  1.499718  1.009095  0.000000   0  1.342696  3.852439  0.0   \n",
       "1    2.310529  1.904618  0.407024  1.961398   0  3.935543  2.119132  0.0   \n",
       "2    2.847691  2.218239  2.552304  0.413375   0  4.027470  2.335804  0.0   \n",
       "3    2.630978  2.885851  2.300232  0.000000   0  4.668746  1.966404  0.0   \n",
       "4    3.832008  1.800635  1.561169  0.000000   0  1.870930  2.288014  0.0   \n",
       "..        ...       ...       ...       ...  ..       ...       ...  ...   \n",
       "930  1.218225  2.083348  2.934301  0.435996   0  4.133583  3.076900  0.0   \n",
       "931  2.361314  1.530629  3.216768  1.008312   0  2.007342  1.402147  0.0   \n",
       "932  2.969559  1.926105  2.365925  1.031104   0  1.788936  1.801119  0.0   \n",
       "933  0.000000  0.564461  2.156883  0.778674   0  3.706711  2.157487  0.0   \n",
       "934  2.188068  1.046049  2.570028  0.000000   0  0.000000  1.579502  0.0   \n",
       "\n",
       "           62        63  \n",
       "0    2.449900  1.319041  \n",
       "1    0.000000  0.569264  \n",
       "2    1.130540  1.486040  \n",
       "3    1.454632  1.750944  \n",
       "4    3.869269  1.738205  \n",
       "..        ...       ...  \n",
       "930  2.287173  1.056643  \n",
       "931  2.390692  1.366772  \n",
       "932  0.952480  1.872088  \n",
       "933  0.976887  0.974419  \n",
       "934  4.306475  0.238258  \n",
       "\n",
       "[935 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...</td>\n",
       "      <td>2.897394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.430467</td>\n",
       "      <td>5.470337</td>\n",
       "      <td>1.023333</td>\n",
       "      <td>3.250161</td>\n",
       "      <td>1.808790</td>\n",
       "      <td>1.809577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724370</td>\n",
       "      <td>2.669310</td>\n",
       "      <td>2.628493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.861607</td>\n",
       "      <td>2.786877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.305915</td>\n",
       "      <td>0.866838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...</td>\n",
       "      <td>2.197051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.650359</td>\n",
       "      <td>1.051105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522087</td>\n",
       "      <td>1.221114</td>\n",
       "      <td>1.867954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.721751</td>\n",
       "      <td>1.911091</td>\n",
       "      <td>1.704715</td>\n",
       "      <td>0.580422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.561583</td>\n",
       "      <td>2.446083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.867273</td>\n",
       "      <td>1.058794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...</td>\n",
       "      <td>2.068614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.188759</td>\n",
       "      <td>2.989452</td>\n",
       "      <td>0.563915</td>\n",
       "      <td>3.100077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.644134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366693</td>\n",
       "      <td>2.067188</td>\n",
       "      <td>1.122288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.944655</td>\n",
       "      <td>4.497924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.419938</td>\n",
       "      <td>1.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...</td>\n",
       "      <td>1.802560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587461</td>\n",
       "      <td>4.627357</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>1.724200</td>\n",
       "      <td>0.587015</td>\n",
       "      <td>2.908260</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218225</td>\n",
       "      <td>2.083348</td>\n",
       "      <td>2.934301</td>\n",
       "      <td>0.435996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133583</td>\n",
       "      <td>3.076900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.287174</td>\n",
       "      <td>1.056643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...</td>\n",
       "      <td>1.144965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.148048</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.337940</td>\n",
       "      <td>2.922622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.727664</td>\n",
       "      <td>1.663665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.201086</td>\n",
       "      <td>2.123586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519155</td>\n",
       "      <td>1.757320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...</td>\n",
       "      <td>2.157738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.574679</td>\n",
       "      <td>1.679128</td>\n",
       "      <td>0.689120</td>\n",
       "      <td>2.701783</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>1.919042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090602</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>2.587833</td>\n",
       "      <td>0.893670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.719681</td>\n",
       "      <td>3.192332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.893287</td>\n",
       "      <td>0.471967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...</td>\n",
       "      <td>3.046409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.843873</td>\n",
       "      <td>3.155958</td>\n",
       "      <td>1.075289</td>\n",
       "      <td>3.249340</td>\n",
       "      <td>1.252380</td>\n",
       "      <td>2.462117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.913887</td>\n",
       "      <td>1.993651</td>\n",
       "      <td>2.355115</td>\n",
       "      <td>0.195466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.337923</td>\n",
       "      <td>3.795005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.479585</td>\n",
       "      <td>1.185263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...</td>\n",
       "      <td>3.494578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.811093</td>\n",
       "      <td>1.444410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.056445</td>\n",
       "      <td>0.300975</td>\n",
       "      <td>0.308933</td>\n",
       "      <td>...</td>\n",
       "      <td>2.187046</td>\n",
       "      <td>2.284416</td>\n",
       "      <td>2.117782</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803474</td>\n",
       "      <td>1.749591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847904</td>\n",
       "      <td>0.889190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...</td>\n",
       "      <td>0.790727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.343679</td>\n",
       "      <td>2.384608</td>\n",
       "      <td>1.575888</td>\n",
       "      <td>1.797486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.239733</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755615</td>\n",
       "      <td>2.938772</td>\n",
       "      <td>2.560087</td>\n",
       "      <td>0.252346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.433876</td>\n",
       "      <td>1.607416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.060641</td>\n",
       "      <td>1.535150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>(연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...</td>\n",
       "      <td>3.220416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>4.118911</td>\n",
       "      <td>0.742014</td>\n",
       "      <td>4.048771</td>\n",
       "      <td>0.323267</td>\n",
       "      <td>0.611445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193002</td>\n",
       "      <td>0.499372</td>\n",
       "      <td>2.133054</td>\n",
       "      <td>0.575985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.035159</td>\n",
       "      <td>3.420978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.373252</td>\n",
       "      <td>2.402286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...  2.897394   \n",
       "1             1  본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...  2.197051   \n",
       "2             2  오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...  2.068614   \n",
       "3             3  도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...  1.802560   \n",
       "4             4  컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...  1.144965   \n",
       "..          ...                                                ...       ...   \n",
       "930         930  포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...  2.157738   \n",
       "931         931  4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...  3.046409   \n",
       "932         932  본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...  3.494578   \n",
       "933         933  제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...  0.790727   \n",
       "934         934  (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...  3.220416   \n",
       "\n",
       "       1         2         3         4         5         6         7  ...  \\\n",
       "0    0.0  2.430467  5.470337  1.023333  3.250161  1.808790  1.809577  ...   \n",
       "1    0.0  1.650359  1.051105  0.000000  0.522087  1.221114  1.867954  ...   \n",
       "2    0.0  2.188759  2.989452  0.563915  3.100077  0.000000  1.644134  ...   \n",
       "3    0.0  1.587461  4.627357  0.498222  1.724200  0.587015  2.908260  ...   \n",
       "4    0.0  0.000000  4.148048  0.992492  0.689115  0.337940  2.922622  ...   \n",
       "..   ...       ...       ...       ...       ...       ...       ...  ...   \n",
       "930  0.0  2.574679  1.679128  0.689120  2.701783  0.533735  1.919042  ...   \n",
       "931  0.0  2.843873  3.155958  1.075289  3.249340  1.252380  2.462117  ...   \n",
       "932  0.0  2.811093  1.444410  0.000000  3.056445  0.300975  0.308933  ...   \n",
       "933  0.0  2.343679  2.384608  1.575888  1.797486  0.000000  1.239733  ...   \n",
       "934  0.0  0.067622  4.118911  0.742014  4.048771  0.323267  0.611445  ...   \n",
       "\n",
       "           54        55        56        57   58        59        60   61  \\\n",
       "0    1.724370  2.669310  2.628493  0.000000  0.0  2.861607  2.786877  0.0   \n",
       "1    1.721751  1.911091  1.704715  0.580422  0.0  3.561583  2.446083  0.0   \n",
       "2    0.000000  1.366693  2.067188  1.122288  0.0  1.944655  4.497924  0.0   \n",
       "3    1.218225  2.083348  2.934301  0.435996  0.0  4.133583  3.076900  0.0   \n",
       "4    0.000000  0.000000  2.727664  1.663665  0.0  4.201086  2.123586  0.0   \n",
       "..        ...       ...       ...       ...  ...       ...       ...  ...   \n",
       "930  1.090602  0.950331  2.587833  0.893670  0.0  1.719681  3.192332  0.0   \n",
       "931  1.913887  1.993651  2.355115  0.195466  0.0  2.337923  3.795005  0.0   \n",
       "932  2.187046  2.284416  2.117782  0.020285  0.0  0.803474  1.749591  0.0   \n",
       "933  1.755615  2.938772  2.560087  0.252346  0.0  2.433876  1.607416  0.0   \n",
       "934  0.193002  0.499372  2.133054  0.575985  0.0  2.035159  3.420978  0.0   \n",
       "\n",
       "           62        63  \n",
       "0    3.305915  0.866838  \n",
       "1    1.867273  1.058794  \n",
       "2    1.419938  1.330579  \n",
       "3    2.287174  1.056643  \n",
       "4    0.519155  1.757320  \n",
       "..        ...       ...  \n",
       "930  1.893287  0.471967  \n",
       "931  3.479585  1.185263  \n",
       "932  3.847904  0.889190  \n",
       "933  4.060641  1.535150  \n",
       "934  2.373252  2.402286  \n",
       "\n",
       "[935 rows x 66 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 ...\n",
       "1       고속철도의 출현과 함께 철도는 국내외에서 자주 사용하는 교통수단 중 하나이다. 또한...\n",
       "2       마찰력은 일상생활에서 뉴턴 역학을 이해하는데 매우 중요한 힘임에도불구하고 많은 학생...\n",
       "3       현재 진행형인 4차 산업혁명 사회는 기존 사회와는 여러 가지 면에서 구분되며, 그 ...\n",
       "4       최근, 급격한 산업화로 인한 급속한 기후변화가 생태 보전 및 생물 다양성에 부정적인...\n",
       "                              ...                        \n",
       "2800    딥러닝에 기반 한 인공지능과 다양한 센서기술의 발전이 빠르게 진행되면서 운전자 없이...\n",
       "2801    본 연구는 콜버그 도덕·윤리교육의 ``정의 공동체 접근법``을 공학윤리교육에 적용하...\n",
       "2802    인공지능 로봇이 사회적, 정서적 상호작용의 대상으로서 사람들의 일상적 공간 안으로 ...\n",
       "2803    인공지능 로봇과 연관된 기술의 발전 속도가 빨라짐에 따라 기존에 인간에 의해서만 이...\n",
       "2804    현재 전세계 배터리 시장은 이차전지 개발에 박차를 가하고 있는 실정이지만, 실제로 ...\n",
       "Name: abstract, Length: 2805, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.859065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768482</td>\n",
       "      <td>4.208251</td>\n",
       "      <td>0.299953</td>\n",
       "      <td>1.829271</td>\n",
       "      <td>0.549787</td>\n",
       "      <td>0.875938</td>\n",
       "      <td>4.559343</td>\n",
       "      <td>2.447888</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068475</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>4.023951</td>\n",
       "      <td>0.933374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.543880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.928553</td>\n",
       "      <td>1.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.503368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.671269</td>\n",
       "      <td>3.332441</td>\n",
       "      <td>0.379955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420594</td>\n",
       "      <td>2.498717</td>\n",
       "      <td>1.378190</td>\n",
       "      <td>4.072253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494116</td>\n",
       "      <td>3.401626</td>\n",
       "      <td>1.402863</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.646207</td>\n",
       "      <td>3.521524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.554926</td>\n",
       "      <td>0.882358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.819702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104125</td>\n",
       "      <td>4.511050</td>\n",
       "      <td>2.193634</td>\n",
       "      <td>2.065551</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>3.954691</td>\n",
       "      <td>0.258508</td>\n",
       "      <td>4.074126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989702</td>\n",
       "      <td>0.368869</td>\n",
       "      <td>2.444483</td>\n",
       "      <td>0.601464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.300735</td>\n",
       "      <td>5.817879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816709</td>\n",
       "      <td>4.201205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.743537</td>\n",
       "      <td>2.777191</td>\n",
       "      <td>1.854041</td>\n",
       "      <td>3.136917</td>\n",
       "      <td>1.585593</td>\n",
       "      <td>1.659128</td>\n",
       "      <td>0.739964</td>\n",
       "      <td>2.388241</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188068</td>\n",
       "      <td>1.046049</td>\n",
       "      <td>2.570028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.579502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306474</td>\n",
       "      <td>0.238258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.429588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.151260</td>\n",
       "      <td>3.216333</td>\n",
       "      <td>0.784559</td>\n",
       "      <td>1.691281</td>\n",
       "      <td>0.430679</td>\n",
       "      <td>1.358677</td>\n",
       "      <td>2.250579</td>\n",
       "      <td>1.687131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.214011</td>\n",
       "      <td>1.853834</td>\n",
       "      <td>1.531043</td>\n",
       "      <td>1.683950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.088216</td>\n",
       "      <td>2.837656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.549347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>0.542204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.601285</td>\n",
       "      <td>1.840448</td>\n",
       "      <td>0.389547</td>\n",
       "      <td>2.070192</td>\n",
       "      <td>1.202173</td>\n",
       "      <td>2.518716</td>\n",
       "      <td>1.124654</td>\n",
       "      <td>2.202389</td>\n",
       "      <td>...</td>\n",
       "      <td>3.306703</td>\n",
       "      <td>3.799414</td>\n",
       "      <td>3.557182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.503757</td>\n",
       "      <td>3.547506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.004233</td>\n",
       "      <td>0.131174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>3.664947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626962</td>\n",
       "      <td>0.581019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.856927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145338</td>\n",
       "      <td>1.086746</td>\n",
       "      <td>2.486792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.518692</td>\n",
       "      <td>0.560103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.743693</td>\n",
       "      <td>2.647182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689267</td>\n",
       "      <td>2.292974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>1.139739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.887890</td>\n",
       "      <td>1.844434</td>\n",
       "      <td>0.978103</td>\n",
       "      <td>2.868803</td>\n",
       "      <td>0.405209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.172990</td>\n",
       "      <td>0.990353</td>\n",
       "      <td>...</td>\n",
       "      <td>2.259139</td>\n",
       "      <td>1.710425</td>\n",
       "      <td>1.534153</td>\n",
       "      <td>0.711135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.237338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.731840</td>\n",
       "      <td>0.737280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>1.893398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.758515</td>\n",
       "      <td>3.033492</td>\n",
       "      <td>0.736422</td>\n",
       "      <td>1.959595</td>\n",
       "      <td>0.711334</td>\n",
       "      <td>1.353843</td>\n",
       "      <td>3.535809</td>\n",
       "      <td>2.639570</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361314</td>\n",
       "      <td>1.530630</td>\n",
       "      <td>3.216768</td>\n",
       "      <td>1.008312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.007342</td>\n",
       "      <td>1.402147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.390691</td>\n",
       "      <td>1.366772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>3.141152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213001</td>\n",
       "      <td>0.129726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561627</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.534352</td>\n",
       "      <td>1.449991</td>\n",
       "      <td>3.479450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198416</td>\n",
       "      <td>0.635571</td>\n",
       "      <td>1.127186</td>\n",
       "      <td>1.118183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.681765</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.970372</td>\n",
       "      <td>0.817302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1         2         3         4         5         6   \\\n",
       "0     1.859065  0.0  0.768482  4.208251  0.299953  1.829271  0.549787   \n",
       "1     1.503368  0.0  1.671269  3.332441  0.379955  0.000000  0.420594   \n",
       "2     2.819702  0.0  1.104125  4.511050  2.193634  2.065551  0.699897   \n",
       "3     0.950928  0.0  2.743537  2.777191  1.854041  3.136917  1.585593   \n",
       "4     2.429588  0.0  2.151260  3.216333  0.784559  1.691281  0.430679   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "2800  0.542204  0.0  2.601285  1.840448  0.389547  2.070192  1.202173   \n",
       "2801  3.664947  0.0  0.626962  0.581019  0.000000  2.856927  0.000000   \n",
       "2802  1.139739  0.0  2.887890  1.844434  0.978103  2.868803  0.405209   \n",
       "2803  1.893398  0.0  2.758515  3.033492  0.736422  1.959595  0.711334   \n",
       "2804  3.141152  0.0  1.213001  0.129726  0.000000  0.561627  0.769634   \n",
       "\n",
       "            7         8         9   ...        54        55        56  \\\n",
       "0     0.875938  4.559343  2.447888  ...  1.068475  0.988764  4.023951   \n",
       "1     2.498717  1.378190  4.072253  ...  0.494116  3.401626  1.402863   \n",
       "2     3.954691  0.258508  4.074126  ...  1.989702  0.368869  2.444483   \n",
       "3     1.659128  0.739964  2.388241  ...  2.188068  1.046049  2.570028   \n",
       "4     1.358677  2.250579  1.687131  ...  1.214011  1.853834  1.531043   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2800  2.518716  1.124654  2.202389  ...  3.306703  3.799414  3.557182   \n",
       "2801  0.145338  1.086746  2.486792  ...  0.645899  0.000000  1.518692   \n",
       "2802  0.000000  2.172990  0.990353  ...  2.259139  1.710425  1.534153   \n",
       "2803  1.353843  3.535809  2.639570  ...  2.361314  1.530630  3.216768   \n",
       "2804  0.534352  1.449991  3.479450  ...  1.198416  0.635571  1.127186   \n",
       "\n",
       "            57   58        59        60   61        62        63  \n",
       "0     0.933374  0.0  2.543880  0.000000  0.0  2.928553  1.043881  \n",
       "1     0.709119  0.0  4.646207  3.521524  0.0  1.554926  0.882358  \n",
       "2     0.601464  0.0  3.300735  5.817879  0.0  0.816709  4.201205  \n",
       "3     0.000000  0.0  0.000000  1.579502  0.0  4.306474  0.238258  \n",
       "4     1.683950  0.0  5.088216  2.837656  0.0  0.000000  1.549347  \n",
       "...        ...  ...       ...       ...  ...       ...       ...  \n",
       "2800  0.000000  0.0  1.503757  3.547506  0.0  5.004233  0.131174  \n",
       "2801  0.560103  0.0  1.743693  2.647182  0.0  0.689267  2.292974  \n",
       "2802  0.711135  0.0  0.000000  1.237338  0.0  2.731840  0.737280  \n",
       "2803  1.008312  0.0  2.007342  1.402147  0.0  2.390691  1.366772  \n",
       "2804  1.118183  0.0  3.681765  0.985598  0.0  0.970372  0.817302  \n",
       "\n",
       "[2805 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      로지스틱 회귀분석은 통계학 등의 분야에서 예측을 위한 기술 혹은 변수 간의 상관관계...\n",
       "1      최근에 이르러, 기계학습 및 데이터마이닝은 수많은 질병 예측 및 진단에 활용되고 있...\n",
       "2      가상발전소 시장에 전력을 안정적으로 공급하기 위해서는 발전량에 대한 정확한 예측이 ...\n",
       "3      문서 자동 요약은 주어진 문서로부터 주요 내용을 추출하거나 생성하는 방식으로 축약하...\n",
       "4      최근 소프트웨어와 인공지능 교육이 점차 중요하게 다루어지면서 2019년 12월 과학...\n",
       "                             ...                        \n",
       "930    인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므...\n",
       "931    제4차 산업혁명이 도래하면서 인공지능 로봇은 다양한 영화 및 드라마에서 다른 캐릭터...\n",
       "932    초등학교 소프트웨어 교육에서는 간단한 문제해결 과정을 통하여 프로그래밍 과정을 경험...\n",
       "933    사물인터넷(IoT) 제품 등의 보안이 허술해 각종 해킹 사고가 발생하고 있다. 보안...\n",
       "934    이 글은 북한의 4차 산업혁명에 대한 대응전략과 추진방식, 그리고 일부 성과들을  ...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975564</td>\n",
       "      <td>0</td>\n",
       "      <td>1.698603</td>\n",
       "      <td>0.825450</td>\n",
       "      <td>0.679568</td>\n",
       "      <td>1.048623</td>\n",
       "      <td>0.548835</td>\n",
       "      <td>2.351269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.581206</td>\n",
       "      <td>...</td>\n",
       "      <td>2.731234</td>\n",
       "      <td>1.499718</td>\n",
       "      <td>1.009095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.342696</td>\n",
       "      <td>3.852439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.449900</td>\n",
       "      <td>1.319041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.146861</td>\n",
       "      <td>0</td>\n",
       "      <td>2.251596</td>\n",
       "      <td>1.369750</td>\n",
       "      <td>0.216136</td>\n",
       "      <td>0.251116</td>\n",
       "      <td>0.649305</td>\n",
       "      <td>1.678851</td>\n",
       "      <td>0.468371</td>\n",
       "      <td>2.144354</td>\n",
       "      <td>...</td>\n",
       "      <td>2.310529</td>\n",
       "      <td>1.904618</td>\n",
       "      <td>0.407024</td>\n",
       "      <td>1.961398</td>\n",
       "      <td>0</td>\n",
       "      <td>3.935543</td>\n",
       "      <td>2.119132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334722</td>\n",
       "      <td>0</td>\n",
       "      <td>1.767782</td>\n",
       "      <td>5.394941</td>\n",
       "      <td>1.133812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333045</td>\n",
       "      <td>3.623545</td>\n",
       "      <td>1.650426</td>\n",
       "      <td>4.047481</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847691</td>\n",
       "      <td>2.218239</td>\n",
       "      <td>2.552304</td>\n",
       "      <td>0.413375</td>\n",
       "      <td>0</td>\n",
       "      <td>4.027470</td>\n",
       "      <td>2.335804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130540</td>\n",
       "      <td>1.486040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.878717</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237748</td>\n",
       "      <td>4.948579</td>\n",
       "      <td>0.375578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.519852</td>\n",
       "      <td>3.323231</td>\n",
       "      <td>3.201345</td>\n",
       "      <td>2.186207</td>\n",
       "      <td>...</td>\n",
       "      <td>2.630978</td>\n",
       "      <td>2.885851</td>\n",
       "      <td>2.300232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.668746</td>\n",
       "      <td>1.966404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.454632</td>\n",
       "      <td>1.750944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.101379</td>\n",
       "      <td>0</td>\n",
       "      <td>2.606388</td>\n",
       "      <td>0.981125</td>\n",
       "      <td>0.366505</td>\n",
       "      <td>1.759244</td>\n",
       "      <td>0.956917</td>\n",
       "      <td>2.015815</td>\n",
       "      <td>0.384175</td>\n",
       "      <td>5.998785</td>\n",
       "      <td>...</td>\n",
       "      <td>3.832008</td>\n",
       "      <td>1.800635</td>\n",
       "      <td>1.561169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.870930</td>\n",
       "      <td>2.288014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.869269</td>\n",
       "      <td>1.738205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.802560</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587461</td>\n",
       "      <td>4.627356</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>1.724201</td>\n",
       "      <td>0.587015</td>\n",
       "      <td>2.908261</td>\n",
       "      <td>1.970190</td>\n",
       "      <td>3.502609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218225</td>\n",
       "      <td>2.083348</td>\n",
       "      <td>2.934301</td>\n",
       "      <td>0.435996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.133583</td>\n",
       "      <td>3.076900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.287173</td>\n",
       "      <td>1.056643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1.893398</td>\n",
       "      <td>0</td>\n",
       "      <td>2.758515</td>\n",
       "      <td>3.033492</td>\n",
       "      <td>0.736422</td>\n",
       "      <td>1.959596</td>\n",
       "      <td>0.711334</td>\n",
       "      <td>1.353843</td>\n",
       "      <td>3.535809</td>\n",
       "      <td>2.639570</td>\n",
       "      <td>...</td>\n",
       "      <td>2.361314</td>\n",
       "      <td>1.530629</td>\n",
       "      <td>3.216768</td>\n",
       "      <td>1.008312</td>\n",
       "      <td>0</td>\n",
       "      <td>2.007342</td>\n",
       "      <td>1.402147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.390692</td>\n",
       "      <td>1.366772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2.929448</td>\n",
       "      <td>0</td>\n",
       "      <td>4.444677</td>\n",
       "      <td>1.866635</td>\n",
       "      <td>0.987381</td>\n",
       "      <td>2.167695</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>0.628170</td>\n",
       "      <td>3.027721</td>\n",
       "      <td>1.042448</td>\n",
       "      <td>...</td>\n",
       "      <td>2.969559</td>\n",
       "      <td>1.926105</td>\n",
       "      <td>2.365925</td>\n",
       "      <td>1.031104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.788936</td>\n",
       "      <td>1.801119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952480</td>\n",
       "      <td>1.872088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2.217202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.284184</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>2.797025</td>\n",
       "      <td>0.396394</td>\n",
       "      <td>0.244705</td>\n",
       "      <td>3.688993</td>\n",
       "      <td>1.166239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.564461</td>\n",
       "      <td>2.156883</td>\n",
       "      <td>0.778674</td>\n",
       "      <td>0</td>\n",
       "      <td>3.706711</td>\n",
       "      <td>2.157487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976887</td>\n",
       "      <td>0.974419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.950928</td>\n",
       "      <td>0</td>\n",
       "      <td>2.743537</td>\n",
       "      <td>2.777190</td>\n",
       "      <td>1.854041</td>\n",
       "      <td>3.136917</td>\n",
       "      <td>1.585593</td>\n",
       "      <td>1.659128</td>\n",
       "      <td>0.739964</td>\n",
       "      <td>2.388241</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188068</td>\n",
       "      <td>1.046049</td>\n",
       "      <td>2.570028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.579502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306475</td>\n",
       "      <td>0.238258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1         2         3         4         5         6         7   \\\n",
       "0    0.975564   0  1.698603  0.825450  0.679568  1.048623  0.548835  2.351269   \n",
       "1    2.146861   0  2.251596  1.369750  0.216136  0.251116  0.649305  1.678851   \n",
       "2    0.334722   0  1.767782  5.394941  1.133812  0.000000  1.333045  3.623545   \n",
       "3    1.878717   0  0.237748  4.948579  0.375578  0.000000  1.519852  3.323231   \n",
       "4    4.101379   0  2.606388  0.981125  0.366505  1.759244  0.956917  2.015815   \n",
       "..        ...  ..       ...       ...       ...       ...       ...       ...   \n",
       "930  1.802560   0  1.587461  4.627356  0.498222  1.724201  0.587015  2.908261   \n",
       "931  1.893398   0  2.758515  3.033492  0.736422  1.959596  0.711334  1.353843   \n",
       "932  2.929448   0  4.444677  1.866635  0.987381  2.167695  0.171970  0.628170   \n",
       "933  2.217202   0  0.000000  5.284184  0.014590  2.797025  0.396394  0.244705   \n",
       "934  0.950928   0  2.743537  2.777190  1.854041  3.136917  1.585593  1.659128   \n",
       "\n",
       "           8         9   ...        54        55        56        57  58  \\\n",
       "0    0.000000  3.581206  ...  2.731234  1.499718  1.009095  0.000000   0   \n",
       "1    0.468371  2.144354  ...  2.310529  1.904618  0.407024  1.961398   0   \n",
       "2    1.650426  4.047481  ...  2.847691  2.218239  2.552304  0.413375   0   \n",
       "3    3.201345  2.186207  ...  2.630978  2.885851  2.300232  0.000000   0   \n",
       "4    0.384175  5.998785  ...  3.832008  1.800635  1.561169  0.000000   0   \n",
       "..        ...       ...  ...       ...       ...       ...       ...  ..   \n",
       "930  1.970190  3.502609  ...  1.218225  2.083348  2.934301  0.435996   0   \n",
       "931  3.535809  2.639570  ...  2.361314  1.530629  3.216768  1.008312   0   \n",
       "932  3.027721  1.042448  ...  2.969559  1.926105  2.365925  1.031104   0   \n",
       "933  3.688993  1.166239  ...  0.000000  0.564461  2.156883  0.778674   0   \n",
       "934  0.739964  2.388241  ...  2.188068  1.046049  2.570028  0.000000   0   \n",
       "\n",
       "           59        60   61        62        63  \n",
       "0    1.342696  3.852439  0.0  2.449900  1.319041  \n",
       "1    3.935543  2.119132  0.0  0.000000  0.569264  \n",
       "2    4.027470  2.335804  0.0  1.130540  1.486040  \n",
       "3    4.668746  1.966404  0.0  1.454632  1.750944  \n",
       "4    1.870930  2.288014  0.0  3.869269  1.738205  \n",
       "..        ...       ...  ...       ...       ...  \n",
       "930  4.133583  3.076900  0.0  2.287173  1.056643  \n",
       "931  2.007342  1.402147  0.0  2.390692  1.366772  \n",
       "932  1.788936  1.801119  0.0  0.952480  1.872088  \n",
       "933  3.706711  2.157487  0.0  0.976887  0.974419  \n",
       "934  0.000000  1.579502  0.0  4.306475  0.238258  \n",
       "\n",
       "[935 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      인류는 1800년대 1차 산업혁명을 거치면서 급격하게 변화하고 성장하였다. 약 20...\n",
       "1      본 연구는 Deep Neural Network(DNN)을 이용하여 광주-기아 챔피언...\n",
       "2      오늘날 기업이 급변하는 글로벌 경영 환경에 민첩하게 대응하기 위해서는 기업 구성원 ...\n",
       "3      도시에서 홍수 피해를 방지하기 위한 침수를 예측하기 위해 본 논문에서는 딥러닝(De...\n",
       "4      컴퓨터가 실생활에서 많이 사용됨에 따라, 악성코드(malware)를 만들어 악의적인...\n",
       "                             ...                        \n",
       "930    포스트 휴머니즘의 한 갈래로서 트랜스 휴머니즘은 ‘의지적 진화’에 의한 인간의 개선...\n",
       "931    4차 산업혁명 진전되는 인공지능 시대 노동법제 논의가 필요한 과제는 다음과 같다.첫...\n",
       "932    본 연구는 현대 패션쇼에 나타난 포스트휴먼의 내적 특성에 관한 연구이다. 연구의 목...\n",
       "933    제4차 산업혁명이라는 유행어가 잘 보여주는 것처럼 현대 과학기술은 사회구조 및 사고...\n",
       "934    (연구배경 및 목적) 생활 방식 변화로 1인 가구의 증가율은 전 연령대에서 지속해서...\n",
       "Name: abstract, Length: 935, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.897394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.430467</td>\n",
       "      <td>5.470337</td>\n",
       "      <td>1.023333</td>\n",
       "      <td>3.250161</td>\n",
       "      <td>1.808790</td>\n",
       "      <td>1.809577</td>\n",
       "      <td>3.241730</td>\n",
       "      <td>2.979927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724370</td>\n",
       "      <td>2.669310</td>\n",
       "      <td>2.628493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.861607</td>\n",
       "      <td>2.786877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.305915</td>\n",
       "      <td>0.866838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.197051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.650359</td>\n",
       "      <td>1.051105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522087</td>\n",
       "      <td>1.221114</td>\n",
       "      <td>1.867954</td>\n",
       "      <td>1.385166</td>\n",
       "      <td>3.236677</td>\n",
       "      <td>...</td>\n",
       "      <td>1.721751</td>\n",
       "      <td>1.911091</td>\n",
       "      <td>1.704715</td>\n",
       "      <td>0.580422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.561583</td>\n",
       "      <td>2.446083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.867273</td>\n",
       "      <td>1.058794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.068614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.188759</td>\n",
       "      <td>2.989452</td>\n",
       "      <td>0.563915</td>\n",
       "      <td>3.100077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.644134</td>\n",
       "      <td>2.181427</td>\n",
       "      <td>1.303193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366693</td>\n",
       "      <td>2.067188</td>\n",
       "      <td>1.122288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.944655</td>\n",
       "      <td>4.497924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.419938</td>\n",
       "      <td>1.330579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.802560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587461</td>\n",
       "      <td>4.627357</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>1.724200</td>\n",
       "      <td>0.587015</td>\n",
       "      <td>2.908260</td>\n",
       "      <td>1.970191</td>\n",
       "      <td>3.502609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218225</td>\n",
       "      <td>2.083348</td>\n",
       "      <td>2.934301</td>\n",
       "      <td>0.435996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133583</td>\n",
       "      <td>3.076900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.287174</td>\n",
       "      <td>1.056643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.144965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.148048</td>\n",
       "      <td>0.992492</td>\n",
       "      <td>0.689115</td>\n",
       "      <td>0.337940</td>\n",
       "      <td>2.922622</td>\n",
       "      <td>0.785970</td>\n",
       "      <td>3.838092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.727664</td>\n",
       "      <td>1.663665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.201086</td>\n",
       "      <td>2.123586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519155</td>\n",
       "      <td>1.757320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2.157738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.574679</td>\n",
       "      <td>1.679128</td>\n",
       "      <td>0.689120</td>\n",
       "      <td>2.701783</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>1.919042</td>\n",
       "      <td>1.049675</td>\n",
       "      <td>1.595294</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090602</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>2.587833</td>\n",
       "      <td>0.893670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.719681</td>\n",
       "      <td>3.192332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.893287</td>\n",
       "      <td>0.471967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>3.046409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.843873</td>\n",
       "      <td>3.155958</td>\n",
       "      <td>1.075289</td>\n",
       "      <td>3.249340</td>\n",
       "      <td>1.252380</td>\n",
       "      <td>2.462117</td>\n",
       "      <td>1.450358</td>\n",
       "      <td>2.889375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.913887</td>\n",
       "      <td>1.993651</td>\n",
       "      <td>2.355115</td>\n",
       "      <td>0.195466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.337923</td>\n",
       "      <td>3.795005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.479585</td>\n",
       "      <td>1.185263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>3.494578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.811093</td>\n",
       "      <td>1.444410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.056445</td>\n",
       "      <td>0.300975</td>\n",
       "      <td>0.308933</td>\n",
       "      <td>1.844930</td>\n",
       "      <td>4.824278</td>\n",
       "      <td>...</td>\n",
       "      <td>2.187046</td>\n",
       "      <td>2.284416</td>\n",
       "      <td>2.117782</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803474</td>\n",
       "      <td>1.749591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.847904</td>\n",
       "      <td>0.889190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.790727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.343679</td>\n",
       "      <td>2.384608</td>\n",
       "      <td>1.575888</td>\n",
       "      <td>1.797486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.239733</td>\n",
       "      <td>2.212777</td>\n",
       "      <td>3.939019</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755615</td>\n",
       "      <td>2.938772</td>\n",
       "      <td>2.560087</td>\n",
       "      <td>0.252346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.433876</td>\n",
       "      <td>1.607416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.060641</td>\n",
       "      <td>1.535150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>3.220416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>4.118911</td>\n",
       "      <td>0.742014</td>\n",
       "      <td>4.048771</td>\n",
       "      <td>0.323267</td>\n",
       "      <td>0.611445</td>\n",
       "      <td>2.363508</td>\n",
       "      <td>2.835138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193002</td>\n",
       "      <td>0.499372</td>\n",
       "      <td>2.133054</td>\n",
       "      <td>0.575985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.035159</td>\n",
       "      <td>3.420978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.373252</td>\n",
       "      <td>2.402286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1         2         3         4         5         6   \\\n",
       "0    2.897394  0.0  2.430467  5.470337  1.023333  3.250161  1.808790   \n",
       "1    2.197051  0.0  1.650359  1.051105  0.000000  0.522087  1.221114   \n",
       "2    2.068614  0.0  2.188759  2.989452  0.563915  3.100077  0.000000   \n",
       "3    1.802560  0.0  1.587461  4.627357  0.498222  1.724200  0.587015   \n",
       "4    1.144965  0.0  0.000000  4.148048  0.992492  0.689115  0.337940   \n",
       "..        ...  ...       ...       ...       ...       ...       ...   \n",
       "930  2.157738  0.0  2.574679  1.679128  0.689120  2.701783  0.533735   \n",
       "931  3.046409  0.0  2.843873  3.155958  1.075289  3.249340  1.252380   \n",
       "932  3.494578  0.0  2.811093  1.444410  0.000000  3.056445  0.300975   \n",
       "933  0.790727  0.0  2.343679  2.384608  1.575888  1.797486  0.000000   \n",
       "934  3.220416  0.0  0.067622  4.118911  0.742014  4.048771  0.323267   \n",
       "\n",
       "           7         8         9   ...        54        55        56  \\\n",
       "0    1.809577  3.241730  2.979927  ...  1.724370  2.669310  2.628493   \n",
       "1    1.867954  1.385166  3.236677  ...  1.721751  1.911091  1.704715   \n",
       "2    1.644134  2.181427  1.303193  ...  0.000000  1.366693  2.067188   \n",
       "3    2.908260  1.970191  3.502609  ...  1.218225  2.083348  2.934301   \n",
       "4    2.922622  0.785970  3.838092  ...  0.000000  0.000000  2.727664   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "930  1.919042  1.049675  1.595294  ...  1.090602  0.950331  2.587833   \n",
       "931  2.462117  1.450358  2.889375  ...  1.913887  1.993651  2.355115   \n",
       "932  0.308933  1.844930  4.824278  ...  2.187046  2.284416  2.117782   \n",
       "933  1.239733  2.212777  3.939019  ...  1.755615  2.938772  2.560087   \n",
       "934  0.611445  2.363508  2.835138  ...  0.193002  0.499372  2.133054   \n",
       "\n",
       "           57   58        59        60   61        62        63  \n",
       "0    0.000000  0.0  2.861607  2.786877  0.0  3.305915  0.866838  \n",
       "1    0.580422  0.0  3.561583  2.446083  0.0  1.867273  1.058794  \n",
       "2    1.122288  0.0  1.944655  4.497924  0.0  1.419938  1.330579  \n",
       "3    0.435996  0.0  4.133583  3.076900  0.0  2.287174  1.056643  \n",
       "4    1.663665  0.0  4.201086  2.123586  0.0  0.519155  1.757320  \n",
       "..        ...  ...       ...       ...  ...       ...       ...  \n",
       "930  0.893670  0.0  1.719681  3.192332  0.0  1.893287  0.471967  \n",
       "931  0.195466  0.0  2.337923  3.795005  0.0  3.479585  1.185263  \n",
       "932  0.020285  0.0  0.803474  1.749591  0.0  3.847904  0.889190  \n",
       "933  0.252346  0.0  2.433876  1.607416  0.0  4.060641  1.535150  \n",
       "934  0.575985  0.0  2.035159  3.420978  0.0  2.373252  2.402286  \n",
       "\n",
       "[935 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2805/2805 [01:15<00:00, 37.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:26<00:00, 35.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 935/935 [00:26<00:00, 35.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['로지',\n",
       "  '스틱',\n",
       "  '회귀분석은',\n",
       "  '통계학',\n",
       "  '등의',\n",
       "  '분야에서',\n",
       "  '예측을',\n",
       "  '위한',\n",
       "  '기술',\n",
       "  '혹은',\n",
       "  '변수',\n",
       "  '간의',\n",
       "  '상관관계',\n",
       "  '를',\n",
       "  '설명',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '오랫동안',\n",
       "  '사용',\n",
       "  '되어',\n",
       "  '왔다',\n",
       "  '이러한',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법에서',\n",
       "  '현재',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '들',\n",
       "  '은',\n",
       "  '목적',\n",
       "  '값에',\n",
       "  '대하여',\n",
       "  '동일한',\n",
       "  '중요도를',\n",
       "  '가지고',\n",
       "  '있다',\n",
       "  '본',\n",
       "  '연구에서는',\n",
       "  '이러한',\n",
       "  '가중치',\n",
       "  '계산',\n",
       "  '을',\n",
       "  '좀더',\n",
       "  '세분화',\n",
       "  '하여',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '의',\n",
       "  '값이',\n",
       "  '서로',\n",
       "  '다른',\n",
       "  '중요도를',\n",
       "  '가지는',\n",
       "  '새로운',\n",
       "  '학습',\n",
       "  '방법을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '알고리즘의',\n",
       "  '성능을',\n",
       "  '최대',\n",
       "  '화하는',\n",
       "  '각',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '가중치',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '계산',\n",
       "  '하기',\n",
       "  '위하여',\n",
       "  '점진적',\n",
       "  '하강법을',\n",
       "  '이용하여',\n",
       "  '개발',\n",
       "  '하였다',\n",
       "  '본',\n",
       "  '연구에서',\n",
       "  '제안된',\n",
       "  '방법은',\n",
       "  '다양한',\n",
       "  '데이터를',\n",
       "  '이용하여',\n",
       "  '실험',\n",
       "  '하였고',\n",
       "  '속성',\n",
       "  '값',\n",
       "  '기반',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '방법은',\n",
       "  '기존의',\n",
       "  '로지',\n",
       "  '스틱',\n",
       "  '회귀분석',\n",
       "  '보다',\n",
       "  '우수한',\n",
       "  '학습',\n",
       "  '능력을',\n",
       "  '보임을',\n",
       "  '알',\n",
       "  '수',\n",
       "  '있었다'],\n",
       " ['최근에',\n",
       "  '이르러',\n",
       "  '기계학습',\n",
       "  '및',\n",
       "  '데이터마이닝',\n",
       "  '은',\n",
       "  '수많은',\n",
       "  '질병',\n",
       "  '예측',\n",
       "  '및',\n",
       "  '진단에',\n",
       "  '활용되고',\n",
       "  '있다',\n",
       "  '만성질환',\n",
       "  '은',\n",
       "  '전체',\n",
       "  '사망률',\n",
       "  '의',\n",
       "  '약',\n",
       "  '80',\n",
       "  '를',\n",
       "  '차지하는',\n",
       "  '질병',\n",
       "  '으로',\n",
       "  '점점',\n",
       "  '증가',\n",
       "  '하는',\n",
       "  '추세',\n",
       "  '이다',\n",
       "  '만성질환',\n",
       "  '관련',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '연구',\n",
       "  '한',\n",
       "  '기존',\n",
       "  '연구들은',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '구성하는',\n",
       "  '데이터로',\n",
       "  '혈당',\n",
       "  '혈압',\n",
       "  '인슐린',\n",
       "  '수치',\n",
       "  '등의',\n",
       "  '건강검진',\n",
       "  '수준의',\n",
       "  '데이터를',\n",
       "  '이용',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '논문은',\n",
       "  '만성질환',\n",
       "  '의',\n",
       "  '위험',\n",
       "  '요인인',\n",
       "  '이상',\n",
       "  '지질혈증과',\n",
       "  '안면',\n",
       "  '정보의',\n",
       "  '연관성을',\n",
       "  '검증',\n",
       "  '하고',\n",
       "  '기계학습',\n",
       "  '기반',\n",
       "  '안면',\n",
       "  '정보를',\n",
       "  '이용한',\n",
       "  '이상',\n",
       "  '지질혈증',\n",
       "  '예측',\n",
       "  '모델을',\n",
       "  '세계',\n",
       "  '최초로',\n",
       "  '개발',\n",
       "  '한다',\n",
       "  '본',\n",
       "  '연구는',\n",
       "  '5390',\n",
       "  '명의',\n",
       "  '임상',\n",
       "  '데이터',\n",
       "  '중',\n",
       "  '안면',\n",
       "  '정보와',\n",
       "  '중성지방혈증',\n",
       "  '정보를',\n",
       "  '바탕으로',\n",
       "  '수행',\n",
       "  '하였다',\n",
       "  '중성지방혈증은',\n",
       "  '이상',\n",
       "  '지질혈증을',\n",
       "  '판단하는',\n",
       "  '척도',\n",
       "  '이다',\n",
       "  '연구의',\n",
       "  '결과로',\n",
       "  '얼굴',\n",
       "  '의',\n",
       "  '하악',\n",
       "  '간의',\n",
       "  '거리를',\n",
       "  '나타내는',\n",
       "  '4314300001',\n",
       "  '0652',\n",
       "  '와',\n",
       "  '고중성지방혈증이',\n",
       "  '매우',\n",
       "  '높은',\n",
       "  '연관성을',\n",
       "  '가진',\n",
       "  '것을',\n",
       "  '밝혀냈고',\n",
       "  '이를',\n",
       "  '기반으로',\n",
       "  '구축',\n",
       "  '한',\n",
       "  '모델은',\n",
       "  '0662',\n",
       "  '의',\n",
       "  '값을',\n",
       "  '획득',\n",
       "  '하였다',\n",
       "  '이러한',\n",
       "  '연구결과는',\n",
       "  '향후',\n",
       "  '질병',\n",
       "  '역학',\n",
       "  '및',\n",
       "  '대중',\n",
       "  '보건',\n",
       "  '영역의',\n",
       "  '스크',\n",
       "  '리닝',\n",
       "  '단계에서',\n",
       "  '안면정보만으로',\n",
       "  '다양할',\n",
       "  '질병',\n",
       "  '을',\n",
       "  '예측할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '기반을',\n",
       "  '제',\n",
       "  '공할',\n",
       "  '수',\n",
       "  '있을',\n",
       "  '것이',\n",
       "  '다'],\n",
       " ['가상',\n",
       "  '발전소',\n",
       "  '시장에',\n",
       "  '전력을',\n",
       "  '안정적으로',\n",
       "  '공급',\n",
       "  '하기',\n",
       "  '위해서는',\n",
       "  '발전',\n",
       "  '량에',\n",
       "  '대한',\n",
       "  '정확한',\n",
       "  '예측이',\n",
       "  '필요하다',\n",
       "  '하지만',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량은',\n",
       "  '기상',\n",
       "  '환경에',\n",
       "  '영향을',\n",
       "  '받아',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '편차가',\n",
       "  '심하기',\n",
       "  '때문에',\n",
       "  '안정적',\n",
       "  '인',\n",
       "  '예측이',\n",
       "  '어렵다',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '기반',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델을',\n",
       "  '제안',\n",
       "  '한다',\n",
       "  '우리는',\n",
       "  '기상',\n",
       "  '데이터와',\n",
       "  '기상',\n",
       "  '예보',\n",
       "  '데이터를',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측모델에',\n",
       "  '입력',\n",
       "  '하여',\n",
       "  '성능을',\n",
       "  '향상',\n",
       "  '시킨다',\n",
       "  '또한',\n",
       "  '상관계수',\n",
       "  '를',\n",
       "  '기준으로',\n",
       "  '우선순위',\n",
       "  '를',\n",
       "  '설정하',\n",
       "  '여',\n",
       "  '변수를',\n",
       "  '선택',\n",
       "  '한다',\n",
       "  '태양광',\n",
       "  '발전',\n",
       "  '량의',\n",
       "  '상관관계',\n",
       "  '와',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측',\n",
       "  '결과를',\n",
       "  '비교하여',\n",
       "  '태양광',\n",
       "  '에너지',\n",
       "  '발전',\n",
       "  '량',\n",
       "  '예측에',\n",
       "  '활용',\n",
       "  '되는',\n",
       "  '최적의',\n",
       "  '기상',\n",
       "  '요인을',\n",
       "  '검토',\n",
       "  '한다'],\n",
       " ['문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '주어진',\n",
       "  '문서로부터',\n",
       "  '주요',\n",
       "  '내용을',\n",
       "  '추출',\n",
       "  '하거나',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '축약',\n",
       "  '하는',\n",
       "  '작업을',\n",
       "  '말',\n",
       "  '한다',\n",
       "  '최근',\n",
       "  '연구에서는',\n",
       "  '대량의',\n",
       "  '문서를',\n",
       "  '딥러닝',\n",
       "  '기법을',\n",
       "  '적용하여',\n",
       "  '요약',\n",
       "  '문',\n",
       "  '자체',\n",
       "  '를',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방식으로',\n",
       "  '발전',\n",
       "  '하고',\n",
       "  '있다',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '은',\n",
       "  '미리',\n",
       "  '생성',\n",
       "  '된',\n",
       "  '위드',\n",
       "  '임베딩',\n",
       "  '정보를',\n",
       "  '사용하는데',\n",
       "  '전문',\n",
       "  '용어와',\n",
       "  '같이',\n",
       "  '저빈도',\n",
       "  '핵심',\n",
       "  '어휘',\n",
       "  '는',\n",
       "  '입베딩',\n",
       "  '된',\n",
       "  '사전',\n",
       "  '에',\n",
       "  '없는',\n",
       "  '문제가',\n",
       "  '발생',\n",
       "  '한다',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '신경망',\n",
       "  '모델의',\n",
       "  '문서',\n",
       "  '자동',\n",
       "  '요약',\n",
       "  '에서',\n",
       "  '미등록',\n",
       "  '어휘',\n",
       "  '의',\n",
       "  '출현',\n",
       "  '은',\n",
       "  '요약',\n",
       "  '성능',\n",
       "  '저하',\n",
       "  '의',\n",
       "  '요인',\n",
       "  '이다',\n",
       "  '이를',\n",
       "  '해결',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '본',\n",
       "  '논문에서는',\n",
       "  '요약',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '에서',\n",
       "  '새로',\n",
       "  '출현',\n",
       "  '한',\n",
       "  '단어',\n",
       "  '를',\n",
       "  '복사',\n",
       "  '하여',\n",
       "  '요약',\n",
       "  '문을',\n",
       "  '생성',\n",
       "  '하는',\n",
       "  '방법을',\n",
       "  '사용',\n",
       "  '한다',\n",
       "  '기존의',\n",
       "  '연구',\n",
       "  '와는',\n",
       "  '달리',\n",
       "  '정확한',\n",
       "  '포인',\n",
       "  '팅',\n",
       "  '정보와',\n",
       "  '선택',\n",
       "  '적',\n",
       "  '복사',\n",
       "  '지시',\n",
       "  '정보를',\n",
       "  '명시적',\n",
       "  '으로',\n",
       "  '제공하는',\n",
       "  '방법으로',\n",
       "  '제안',\n",
       "  '하였다',\n",
       "  '학습',\n",
       "  '데이터는',\n",
       "  '논문의',\n",
       "  '초록과',\n",
       "  '제목을',\n",
       "  '대상',\n",
       "  '문서',\n",
       "  '와',\n",
       "  '정답',\n",
       "  '요약',\n",
       "  '으로',\n",
       "  '사용',\n",
       "  '하였다',\n",
       "  '제안한',\n",
       "  '인코딩',\n",
       "  '디코딩',\n",
       "  '기반',\n",
       "  '모델을',\n",
       "  '통해서',\n",
       "  '자동',\n",
       "  '생성',\n",
       "  '요약',\n",
       "  '을',\n",
       "  '수행',\n",
       "  '한',\n",
       "  '결과',\n",
       "  '단어',\n",
       "  '제현',\n",
       "  '기반의',\n",
       "  '1',\n",
       "  '이',\n",
       "  '4701',\n",
       "  '로',\n",
       "  '나타났으며',\n",
       "  '또한',\n",
       "  '어순',\n",
       "  '기반의',\n",
       "  '이',\n",
       "  '2955',\n",
       "  '로',\n",
       "  '향상',\n",
       "  '되었다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3740/3740 [00:01<00:00, 2901.28it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그러므로',\n",
       " '선박,',\n",
       " '빌딩,',\n",
       " '기차,',\n",
       " '비행기',\n",
       " '등',\n",
       " 'Modbus를',\n",
       " '이용하는',\n",
       " '모든',\n",
       " '장비들과',\n",
       " '연결이',\n",
       " '가능하여',\n",
       " '환경변수의',\n",
       " '측정',\n",
       " '및',\n",
       " '원격제어가',\n",
       " '가능하게',\n",
       " '된다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3740/3740 [00:00<00:00, 312515.13it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modbus는 각종 자동화 장비 감시 및 제어에 전 세계적으로 널리 사용되고 있는 자발적 산업표준 통신 프로토콜이다',\n",
       " '그러므로 선박, 빌딩, 기차, 비행기 등 Modbus를 이용하는 모든 장비들과 연결이 가능하여 환경변수의 측정 및 원격제어가 가능하게 된다',\n",
       " '본 논문에서 는 퍼지제어 시스템을 이용하여 외부환경요인을 각각 조합한 불확실한 내용을 정량적인 값으로 변환하여 LED 조명으로 표현하기 위해 알고 리즘을 설계하고, 설계한 알고리즘에 Modbus 통신 프로토콜을 추가하여 선박의 통합관리 시스템에서 외부환경요인 확인 및 원격제어가 가능 한 감성조명용 LED 제어기 회로를 설계 및 구현 하였다',\n",
       " '외부환경요소인 온도, 습도, 조도 값을 센서를 통해 제어기로 받아들이고 이 값들을 퍼지제어 알고리즘을 통해 LED로 표현된다',\n",
       " 'Modbus는 Serial 통신으로 RS485를 이용하여 다른 기기와 연결 되어 온도, 습도, 조도 상태 및 LED 출력 값 확인이 가능하고 또한 사용자가 원격으로 RGB 값을 변경 할 수 있기 때문에 원하는 색으로 변경이 가능하게 된다',\n",
       " '제작한 제 어기로 온도, 습도, 조도에 따라 LED 조명색상이 변화 되는 것을 확인 하였다.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  34\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.831550802139038\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  391\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 19.31136906794128\n",
      "문장 내의 단어 개수 중앙값 : 18.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2805, 20, 200)\n",
      "train_Y_data.shape: (2805, 64)\n",
      "val_X_data.shape: (935, 20, 200)\n",
      "val_Y_data.shape: (935, 64)\n",
      "test_X_data.shape: (935, 20, 200)\n",
      "test_Y_data.shape: (935, 64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '을': 2,\n",
       " '에': 3,\n",
       " '이': 4,\n",
       " '수': 5,\n",
       " '있다': 6,\n",
       " '하였다': 7,\n",
       " '를': 8,\n",
       " '한다': 9,\n",
       " '하고': 10,\n",
       " '할': 11,\n",
       " '본': 12,\n",
       " '대한': 13,\n",
       " '과': 14,\n",
       " '적': 15,\n",
       " '및': 16,\n",
       " '는': 17,\n",
       " '하는': 18,\n",
       " '있는': 19,\n",
       " '한': 20,\n",
       " '은': 21,\n",
       " '가': 22,\n",
       " '으로': 23,\n",
       " '것이': 24,\n",
       " '와': 25,\n",
       " '위해': 26,\n",
       " '통해': 27,\n",
       " '된': 28,\n",
       " '인': 29,\n",
       " '위한': 30,\n",
       " '로': 31,\n",
       " '인공지능': 32,\n",
       " '분석': 33,\n",
       " '하기': 34,\n",
       " '다': 35,\n",
       " '학습': 36,\n",
       " '들': 37,\n",
       " '이다': 38,\n",
       " '연구': 39,\n",
       " '에서': 40,\n",
       " '그': 41,\n",
       " '활용': 42,\n",
       " '이러한': 43,\n",
       " '다양한': 44,\n",
       " '이를': 45,\n",
       " '4': 46,\n",
       " '하여': 47,\n",
       " '것으로': 48,\n",
       " '교육': 49,\n",
       " '연구는': 50,\n",
       " '기술': 51,\n",
       " '고': 52,\n",
       " '제안': 53,\n",
       " '될': 54,\n",
       " '차': 55,\n",
       " '적용': 56,\n",
       " '또한': 57,\n",
       " '데이터': 58,\n",
       " '개발': 59,\n",
       " '사용': 60,\n",
       " '결과': 61,\n",
       " '된다': 62,\n",
       " '새로운': 63,\n",
       " '산업혁명': 64,\n",
       " '따라': 65,\n",
       " '예측': 66,\n",
       " '되고': 67,\n",
       " '경우': 68,\n",
       " '관련': 69,\n",
       " '도': 70,\n",
       " '되는': 71,\n",
       " '스마트': 72,\n",
       " '연구에서는': 73,\n",
       " '그리고': 74,\n",
       " '정보': 75,\n",
       " '되었다': 76,\n",
       " '기반': 77,\n",
       " '대해': 78,\n",
       " '인간': 79,\n",
       " '제': 80,\n",
       " '등': 81,\n",
       " '논문에서는': 82,\n",
       " '데이터를': 83,\n",
       " '영향을': 84,\n",
       " '제시': 85,\n",
       " '같은': 86,\n",
       " '최근': 87,\n",
       " '이에': 88,\n",
       " '3': 89,\n",
       " '분류': 90,\n",
       " '따라서': 91,\n",
       " '해': 92,\n",
       " '가장': 93,\n",
       " '이용하여': 94,\n",
       " '서': 95,\n",
       " '수행': 96,\n",
       " '확인': 97,\n",
       " '평가': 98,\n",
       " '인간의': 99,\n",
       " '되어': 100,\n",
       " '보다': 101,\n",
       " '사물인터넷': 102,\n",
       " '중': 103,\n",
       " '가지': 104,\n",
       " '연구의': 105,\n",
       " '특히': 106,\n",
       " '지': 107,\n",
       " '성': 108,\n",
       " '위하여': 109,\n",
       " '서비스': 110,\n",
       " '문제': 111,\n",
       " '기존': 112,\n",
       " '2': 113,\n",
       " '정보를': 114,\n",
       " '있었다': 115,\n",
       " '융합': 116,\n",
       " '인식': 117,\n",
       " '미래': 118,\n",
       " '제공': 119,\n",
       " '있으며': 120,\n",
       " '수업': 121,\n",
       " '나타났다': 122,\n",
       " '결과를': 123,\n",
       " '하고자': 124,\n",
       " '발생': 125,\n",
       " '설계': 126,\n",
       " '모델을': 127,\n",
       " '높은': 128,\n",
       " '것을': 129,\n",
       " '더': 130,\n",
       " '핵심': 131,\n",
       " '그러나': 132,\n",
       " '따른': 133,\n",
       " '비교': 134,\n",
       " '많은': 135,\n",
       " '아니라': 136,\n",
       " '방법을': 137,\n",
       " '대상으로': 138,\n",
       " '사회': 139,\n",
       " '관한': 140,\n",
       " '기존의': 141,\n",
       " '여': 142,\n",
       " '디자인': 143,\n",
       " '증가': 144,\n",
       " '진행': 145,\n",
       " '생성': 146,\n",
       " '해결': 147,\n",
       " '등의': 148,\n",
       " '산업': 149,\n",
       " '해야': 150,\n",
       " '기술의': 151,\n",
       " '각': 152,\n",
       " '인공지능의': 153,\n",
       " '기반으로': 154,\n",
       " '실험': 155,\n",
       " '변화': 156,\n",
       " '현재': 157,\n",
       " '구성': 158,\n",
       " '있을': 159,\n",
       " '하였으며': 160,\n",
       " '성능을': 161,\n",
       " '다른': 162,\n",
       " '에서는': 163,\n",
       " '발전': 164,\n",
       " '빅데이터': 165,\n",
       " '통한': 166,\n",
       " '기반의': 167,\n",
       " '1': 168,\n",
       " '바탕으로': 169,\n",
       " '딥러닝': 170,\n",
       " '활용하여': 171,\n",
       " '실제': 172,\n",
       " '연구가': 173,\n",
       " '미치는': 174,\n",
       " '문제를': 175,\n",
       " '기술을': 176,\n",
       " '등을': 177,\n",
       " '통하여': 178,\n",
       " '때': 179,\n",
       " '활용한': 180,\n",
       " '위해서는': 181,\n",
       " '개선': 182,\n",
       " '분석을': 183,\n",
       " '둘째': 184,\n",
       " '첫째': 185,\n",
       " '논문은': 186,\n",
       " '때문에': 187,\n",
       " '디지털': 188,\n",
       " '중요한': 189,\n",
       " '검토': 190,\n",
       " '수집': 191,\n",
       " '이용한': 192,\n",
       " '공학': 193,\n",
       " '의미': 194,\n",
       " '향후': 195,\n",
       " '필요': 196,\n",
       " '음악': 197,\n",
       " '논의': 198,\n",
       " '중심으로': 199,\n",
       " '도출': 200,\n",
       " '며': 201,\n",
       " '향상': 202,\n",
       " '이용': 203,\n",
       " '사회적': 204,\n",
       " '접근': 205,\n",
       " '후': 206,\n",
       " '시스템을': 207,\n",
       " '개의': 208,\n",
       " '연구를': 209,\n",
       " '간': 210,\n",
       " '했다': 211,\n",
       " '화': 212,\n",
       " '하지만': 213,\n",
       " '에는': 214,\n",
       " '필요하다': 215,\n",
       " '검증': 216,\n",
       " '에게': 217,\n",
       " '구축': 218,\n",
       " '주요': 219,\n",
       " '자': 220,\n",
       " '개': 221,\n",
       " '네트워크': 222,\n",
       " '사용자': 223,\n",
       " '필요한': 224,\n",
       " '있어': 225,\n",
       " '두': 226,\n",
       " '관리': 227,\n",
       " '기계학습': 228,\n",
       " '있도록': 229,\n",
       " '기초': 230,\n",
       " '이는': 231,\n",
       " '국내': 232,\n",
       " '시스템': 233,\n",
       " '하는데': 234,\n",
       " '이나': 235,\n",
       " '여러': 236,\n",
       " '인공지능이': 237,\n",
       " '다음': 238,\n",
       " '기법을': 239,\n",
       " '사물': 240,\n",
       " '것은': 241,\n",
       " '함께': 242,\n",
       " '존재': 243,\n",
       " '함으로써': 244,\n",
       " '교육의': 245,\n",
       " '한국': 246,\n",
       " '교수': 247,\n",
       " '하였고': 248,\n",
       " '과학': 249,\n",
       " '개인': 250,\n",
       " '측정': 251,\n",
       " '방안을': 252,\n",
       " '고려': 253,\n",
       " '나': 254,\n",
       " '판단': 255,\n",
       " '성능': 256,\n",
       " '법적': 257,\n",
       " '매우': 258,\n",
       " '관련된': 259,\n",
       " '알고리즘': 260,\n",
       " '어떻게': 261,\n",
       " '대하여': 262,\n",
       " '로봇': 263,\n",
       " '구현': 264,\n",
       " '하며': 265,\n",
       " '셋째': 266,\n",
       " '큰': 267,\n",
       " '모든': 268,\n",
       " '지식': 269,\n",
       " '있다는': 270,\n",
       " '도입': 271,\n",
       " '이미지': 272,\n",
       " '또는': 273,\n",
       " '인해': 274,\n",
       " '보안': 275,\n",
       " '운영': 276,\n",
       " '처리': 277,\n",
       " '되어야': 278,\n",
       " '개인정보': 279,\n",
       " '변화를': 280,\n",
       " '조사': 281,\n",
       " '지원': 282,\n",
       " '형': 283,\n",
       " '대학': 284,\n",
       " '요구': 285,\n",
       " '기계': 286,\n",
       " '특성을': 287,\n",
       " '데이터의': 288,\n",
       " '사용하여': 289,\n",
       " '탐색': 290,\n",
       " '알고리즘을': 291,\n",
       " '생각': 292,\n",
       " '실시': 293,\n",
       " '지능': 294,\n",
       " '연결': 295,\n",
       " '있어서': 296,\n",
       " '하면서': 297,\n",
       " '방법': 298,\n",
       " '개념': 299,\n",
       " '해당': 300,\n",
       " '센서': 301,\n",
       " '가능한': 302,\n",
       " '5': 303,\n",
       " '적용하여': 304,\n",
       " '특징': 305,\n",
       " '가능성을': 306,\n",
       " '환경': 307,\n",
       " '있음을': 308,\n",
       " '대': 309,\n",
       " '사전': 310,\n",
       " '영상': 311,\n",
       " '선택': 312,\n",
       " '게': 313,\n",
       " '확장': 314,\n",
       " '간의': 315,\n",
       " '국가': 316,\n",
       " '있고': 317,\n",
       " '인공지능에': 318,\n",
       " '없는': 319,\n",
       " '인터넷': 320,\n",
       " '통합': 321,\n",
       " '대응': 322,\n",
       " '과정에서': 323,\n",
       " '이고': 324,\n",
       " '현실': 325,\n",
       " '보였다': 326,\n",
       " '모두': 327,\n",
       " '이해': 328,\n",
       " '하지': 329,\n",
       " '결과는': 330,\n",
       " '역할을': 331,\n",
       " '관점에서': 332,\n",
       " '기술이': 333,\n",
       " '소프트웨어': 334,\n",
       " '모델': 335,\n",
       " '즉': 336,\n",
       " '비해': 337,\n",
       " '감성': 338,\n",
       " '참여': 339,\n",
       " '표현': 340,\n",
       " '시': 341,\n",
       " '포함': 342,\n",
       " '규제': 343,\n",
       " '에서의': 344,\n",
       " '학교': 345,\n",
       " '보호': 346,\n",
       " '인공지능을': 347,\n",
       " '인지': 348,\n",
       " '서비스를': 349,\n",
       " '의한': 350,\n",
       " '프로그램': 351,\n",
       " '내용': 352,\n",
       " '텍스트': 353,\n",
       " '일반': 354,\n",
       " '정의': 355,\n",
       " '등장': 356,\n",
       " '모형을': 357,\n",
       " '문제점': 358,\n",
       " '생산': 359,\n",
       " '경험': 360,\n",
       " '제안하는': 361,\n",
       " '체계': 362,\n",
       " '만': 363,\n",
       " '분야에서': 364,\n",
       " '데': 365,\n",
       " '부터': 366,\n",
       " '라는': 367,\n",
       " '자료를': 368,\n",
       " '전공': 369,\n",
       " '기능': 370,\n",
       " '이와': 371,\n",
       " '추출': 372,\n",
       " '과정을': 373,\n",
       " '심층': 374,\n",
       " '전체': 375,\n",
       " '연구에서': 376,\n",
       " '시스템의': 377,\n",
       " '까지': 378,\n",
       " '의해': 379,\n",
       " '정책': 380,\n",
       " '목적은': 381,\n",
       " '활동': 382,\n",
       " '컴퓨터': 383,\n",
       " '확보': 384,\n",
       " '결정': 385,\n",
       " '설명': 386,\n",
       " '크게': 387,\n",
       " '볼': 388,\n",
       " '모델의': 389,\n",
       " '상호작용': 390,\n",
       " '이며': 391,\n",
       " '때문': 392,\n",
       " '어떤': 393,\n",
       " '환경에서': 394,\n",
       " '자기': 395,\n",
       " '가지고': 396,\n",
       " '세': 397,\n",
       " '역량': 398,\n",
       " '전': 399,\n",
       " '중심': 400,\n",
       " '더욱': 401,\n",
       " '뿐': 402,\n",
       " '사용자의': 403,\n",
       " '상황': 404,\n",
       " '한계': 405,\n",
       " '창의적': 406,\n",
       " '제품': 407,\n",
       " '우리': 408,\n",
       " '먼저': 409,\n",
       " '분야': 410,\n",
       " '의료': 411,\n",
       " '학년': 412,\n",
       " '온라인': 413,\n",
       " '확대': 414,\n",
       " '세계': 415,\n",
       " '측면에서': 416,\n",
       " '예술': 417,\n",
       " '교육을': 418,\n",
       " '이라는': 419,\n",
       " '전문가': 420,\n",
       " '인간과': 421,\n",
       " '특성': 422,\n",
       " '콘텐츠': 423,\n",
       " '시대에': 424,\n",
       " '행동': 425,\n",
       " '효과를': 426,\n",
       " '정확도를': 427,\n",
       " '관계': 428,\n",
       " '사고': 429,\n",
       " '머신러닝': 430,\n",
       " '점에서': 431,\n",
       " '분야의': 432,\n",
       " '디바이스': 433,\n",
       " '한다는': 434,\n",
       " '시도': 435,\n",
       " '모바일': 436,\n",
       " '교과': 437,\n",
       " '총': 438,\n",
       " '내용을': 439,\n",
       " '제작': 440,\n",
       " '탐지': 441,\n",
       " '분석하여': 442,\n",
       " '야': 443,\n",
       " '문화': 444,\n",
       " '공간': 445,\n",
       " '관계를': 446,\n",
       " '평균': 447,\n",
       " '마련': 448,\n",
       " '자료': 449,\n",
       " '인공지능과': 450,\n",
       " '같다': 451,\n",
       " '입력': 452,\n",
       " '구': 453,\n",
       " '문제가': 454,\n",
       " '자동': 455,\n",
       " '학생들의': 456,\n",
       " '직접': 457,\n",
       " '토대로': 458,\n",
       " '영향': 459,\n",
       " '학생': 460,\n",
       " '등이': 461,\n",
       " '제공하는': 462,\n",
       " '기술적': 463,\n",
       " '시대의': 464,\n",
       " '않은': 465,\n",
       " '차이가': 466,\n",
       " '제안한': 467,\n",
       " '파악': 468,\n",
       " '이상': 469,\n",
       " '이후': 470,\n",
       " '우리나라': 471,\n",
       " '하게': 472,\n",
       " '시작': 473,\n",
       " '제안된': 474,\n",
       " '현': 475,\n",
       " '유의': 476,\n",
       " '학습을': 477,\n",
       " '방향을': 478,\n",
       " '감정': 479,\n",
       " '형성': 480,\n",
       " '신경망': 481,\n",
       " '별': 482,\n",
       " '많이': 483,\n",
       " '같이': 484,\n",
       " '사이버': 485,\n",
       " '위치': 486,\n",
       " '동시에': 487,\n",
       " '인한': 488,\n",
       " '되지': 489,\n",
       " '화된': 490,\n",
       " '기업': 491,\n",
       " '프로그램을': 492,\n",
       " '측면': 493,\n",
       " '에도': 494,\n",
       " '혁신': 495,\n",
       " '방법은': 496,\n",
       " '유형': 497,\n",
       " '적합한': 498,\n",
       " '실험을': 499,\n",
       " '변화에': 500,\n",
       " '교사': 501,\n",
       " '시스템은': 502,\n",
       " '법률': 503,\n",
       " '플랫폼': 504,\n",
       " '연계': 505,\n",
       " '영역': 506,\n",
       " '기대': 507,\n",
       " '사례를': 508,\n",
       " '마지막으로': 509,\n",
       " '의사결정': 510,\n",
       " '이루어지': 511,\n",
       " '어떠한': 512,\n",
       " '상호': 513,\n",
       " '상': 514,\n",
       " '선정': 515,\n",
       " '설정': 516,\n",
       " '제어': 517,\n",
       " '면': 518,\n",
       " '개별': 519,\n",
       " '가치': 520,\n",
       " '등에': 521,\n",
       " '고찰': 522,\n",
       " '알': 523,\n",
       " '통신': 524,\n",
       " '단어': 525,\n",
       " '기능을': 526,\n",
       " '관련하여': 527,\n",
       " '컴퓨팅': 528,\n",
       " '스마트폰': 529,\n",
       " '언어': 530,\n",
       " '전문': 531,\n",
       " '특정': 532,\n",
       " '시킬': 533,\n",
       " '계산': 534,\n",
       " '인공지능은': 535,\n",
       " '결합': 536,\n",
       " '우선': 537,\n",
       " '교수학습': 538,\n",
       " '과제': 539,\n",
       " '수학': 540,\n",
       " '었다': 541,\n",
       " '학습자': 542,\n",
       " '더불어': 543,\n",
       " '로봇의': 544,\n",
       " '발달': 545,\n",
       " '능력': 546,\n",
       " '점을': 547,\n",
       " '있지만': 548,\n",
       " '내': 549,\n",
       " '감소': 550,\n",
       " '모형': 551,\n",
       " '시간': 552,\n",
       " '인공': 553,\n",
       " '창의성': 554,\n",
       " '문장': 555,\n",
       " '모색': 556,\n",
       " '중국': 557,\n",
       " '방식을': 558,\n",
       " '책임': 559,\n",
       " '라고': 560,\n",
       " '금융': 561,\n",
       " '않고': 562,\n",
       " '분야에': 563,\n",
       " '글쓰기': 564,\n",
       " '보인다': 565,\n",
       " '발생하는': 566,\n",
       " '효과적인': 567,\n",
       " '전자': 568,\n",
       " '구조': 569,\n",
       " '특징을': 570,\n",
       " '없이': 571,\n",
       " '차원': 572,\n",
       " '나아가': 573,\n",
       " '지능형': 574,\n",
       " '협력': 575,\n",
       " '가치를': 576,\n",
       " '응용': 577,\n",
       " '효과적으로': 578,\n",
       " '공유': 579,\n",
       " '부분': 580,\n",
       " '검색': 581,\n",
       " '확인할': 582,\n",
       " '아닌': 583,\n",
       " '기술은': 584,\n",
       " '없다': 585,\n",
       " '소비자': 586,\n",
       " '에서도': 587,\n",
       " '권리': 588,\n",
       " '시대': 589,\n",
       " '주로': 590,\n",
       " '교육과정': 591,\n",
       " '자동차': 592,\n",
       " '클라우드': 593,\n",
       " '기본': 594,\n",
       " '위험': 595,\n",
       " '검출': 596,\n",
       " '사례': 597,\n",
       " '단계': 598,\n",
       " '약': 599,\n",
       " '살펴보았다': 600,\n",
       " '러닝': 601,\n",
       " '하도록': 602,\n",
       " '능력을': 603,\n",
       " '하거나': 604,\n",
       " '잘': 605,\n",
       " '목적으로': 606,\n",
       " '성과': 607,\n",
       " '우리는': 608,\n",
       " '가상': 609,\n",
       " '중심의': 610,\n",
       " '윤리적': 611,\n",
       " '확산': 612,\n",
       " '정보의': 613,\n",
       " '윤리': 614,\n",
       " '과의': 615,\n",
       " '함에': 616,\n",
       " '있게': 617,\n",
       " '기술과': 618,\n",
       " '목적을': 619,\n",
       " '탐구': 620,\n",
       " '학생들이': 621,\n",
       " '진행되고': 622,\n",
       " '효과': 623,\n",
       " '혹은': 624,\n",
       " '미국': 625,\n",
       " '모델은': 626,\n",
       " '인간이': 627,\n",
       " '않는': 628,\n",
       " '고려하여': 629,\n",
       " '력': 630,\n",
       " '강조': 631,\n",
       " '과학기술': 632,\n",
       " '수용': 633,\n",
       " '시사점을': 634,\n",
       " '산업의': 635,\n",
       " '방법으로': 636,\n",
       " '목적': 637,\n",
       " '영화': 638,\n",
       " '인정': 639,\n",
       " '개인의': 640,\n",
       " '역할': 641,\n",
       " '객체': 642,\n",
       " '반영': 643,\n",
       " '추정': 644,\n",
       " '블록체인': 645,\n",
       " '스스로': 646,\n",
       " '6': 647,\n",
       " '현대': 648,\n",
       " '통해서': 649,\n",
       " '차량': 650,\n",
       " '창작': 651,\n",
       " '좋은': 652,\n",
       " '주장': 653,\n",
       " '활성화': 654,\n",
       " '중에서': 655,\n",
       " '기법': 656,\n",
       " '사용하는': 657,\n",
       " '연구결과': 658,\n",
       " '서로': 659,\n",
       " '요소를': 660,\n",
       " '실시간': 661,\n",
       " '진단': 662,\n",
       " '하면': 663,\n",
       " '강화': 664,\n",
       " '실행': 665,\n",
       " '문제해결': 666,\n",
       " '양성': 667,\n",
       " '과정': 668,\n",
       " '분석한': 669,\n",
       " '이런': 670,\n",
       " '방법이': 671,\n",
       " '모니터링': 672,\n",
       " '요소': 673,\n",
       " '사': 674,\n",
       " '속에서': 675,\n",
       " '상태': 676,\n",
       " '주목': 677,\n",
       " '향상을': 678,\n",
       " '역량을': 679,\n",
       " '이들': 680,\n",
       " '있다고': 681,\n",
       " '이론적': 682,\n",
       " '식': 683,\n",
       " '집중': 684,\n",
       " '이미': 685,\n",
       " '아직': 686,\n",
       " '추가': 687,\n",
       " '안전': 688,\n",
       " '개념을': 689,\n",
       " '한국어': 690,\n",
       " '평가를': 691,\n",
       " '줄': 692,\n",
       " '한편': 693,\n",
       " '유의미한': 694,\n",
       " '기업의': 695,\n",
       " '대상': 696,\n",
       " '가능성이': 697,\n",
       " '개발된': 698,\n",
       " '학습자의': 699,\n",
       " '하나의': 700,\n",
       " '있기': 701,\n",
       " '종합': 702,\n",
       " '웹': 703,\n",
       " '활용하는': 704,\n",
       " '접목': 705,\n",
       " '경제': 706,\n",
       " '시각': 707,\n",
       " '첨단': 708,\n",
       " '빅': 709,\n",
       " '현장': 710,\n",
       " '보조공학': 711,\n",
       " '가진': 712,\n",
       " '초기': 713,\n",
       " '되기': 714,\n",
       " '드론': 715,\n",
       " '모형의': 716,\n",
       " '교육에': 717,\n",
       " '개정': 718,\n",
       " '프로젝트': 719,\n",
       " '추천': 720,\n",
       " '창의': 721,\n",
       " '시장': 722,\n",
       " '각각': 723,\n",
       " '지역': 724,\n",
       " '것인지': 725,\n",
       " '자신의': 726,\n",
       " '변화가': 727,\n",
       " '주제': 728,\n",
       " '진로': 729,\n",
       " '구분': 730,\n",
       " '법': 731,\n",
       " '데이터에': 732,\n",
       " '기대한다': 733,\n",
       " '체험': 734,\n",
       " '우수한': 735,\n",
       " '배경': 736,\n",
       " '창출': 737,\n",
       " '어려운': 738,\n",
       " '방식으로': 739,\n",
       " '효율적인': 740,\n",
       " '실현': 741,\n",
       " '논문에서': 742,\n",
       " '되었으며': 743,\n",
       " '장애': 744,\n",
       " '대학의': 745,\n",
       " '낮은': 746,\n",
       " '불구하고': 747,\n",
       " '갖는': 748,\n",
       " '살펴보고': 749,\n",
       " '에너지': 750,\n",
       " '적절한': 751,\n",
       " '대비': 752,\n",
       " '한계를': 753,\n",
       " '데이터가': 754,\n",
       " '의미를': 755,\n",
       " '물론': 756,\n",
       " '통계적': 757,\n",
       " '보완': 758,\n",
       " '높게': 759,\n",
       " '예상': 760,\n",
       " '유사한': 761,\n",
       " '관점': 762,\n",
       " '국제': 763,\n",
       " '수정': 764,\n",
       " '교육이': 765,\n",
       " '자동화': 766,\n",
       " '달성': 767,\n",
       " '집단': 768,\n",
       " '도덕': 769,\n",
       " '왔다': 770,\n",
       " '기술에': 771,\n",
       " '전송': 772,\n",
       " '공공': 773,\n",
       " '앞으로': 774,\n",
       " '쟁점': 775,\n",
       " '수업을': 776,\n",
       " '해석': 777,\n",
       " '사회의': 778,\n",
       " '상황에서': 779,\n",
       " '수집된': 780,\n",
       " '아니': 781,\n",
       " '시뮬레이션': 782,\n",
       " '효율적으로': 783,\n",
       " '사람': 784,\n",
       " '대체': 785,\n",
       " '미디어': 786,\n",
       " '발견': 787,\n",
       " '명의': 788,\n",
       " '교육적': 789,\n",
       " '형태의': 790,\n",
       " '전통적인': 791,\n",
       " '부여': 792,\n",
       " '다중': 793,\n",
       " '서비스의': 794,\n",
       " '환경을': 795,\n",
       " '영역에서': 796,\n",
       " '추론': 797,\n",
       " '달리': 798,\n",
       " '필요성': 799,\n",
       " '형태로': 800,\n",
       " '하여야': 801,\n",
       " '최적화': 802,\n",
       " '되면서': 803,\n",
       " '차이를': 804,\n",
       " '유지': 805,\n",
       " '뿐만': 806,\n",
       " '패턴': 807,\n",
       " '관심이': 808,\n",
       " '설치': 809,\n",
       " '역시': 810,\n",
       " '구체적으로': 811,\n",
       " '방법에': 812,\n",
       " '피드백': 813,\n",
       " '지만': 814,\n",
       " '지식을': 815,\n",
       " '최종': 816,\n",
       " '그에': 817,\n",
       " '소통': 818,\n",
       " '포스트휴먼': 819,\n",
       " '기기': 820,\n",
       " '전망': 821,\n",
       " '신체': 822,\n",
       " '요인': 823,\n",
       " '노력': 824,\n",
       " '사이의': 825,\n",
       " '영역을': 826,\n",
       " '수준': 827,\n",
       " '등으로': 828,\n",
       " '10': 829,\n",
       " '이상의': 830,\n",
       " '도움이': 831,\n",
       " '으로는': 832,\n",
       " '생활': 833,\n",
       " '구체적인': 834,\n",
       " '상황을': 835,\n",
       " '발전에': 836,\n",
       " '넷째': 837,\n",
       " '있으나': 838,\n",
       " '소개': 839,\n",
       " '개발을': 840,\n",
       " '작성': 841,\n",
       " '긍정적인': 842,\n",
       " '침해': 843,\n",
       " '본질': 844,\n",
       " '전략을': 845,\n",
       " '무선': 846,\n",
       " '수준의': 847,\n",
       " '하나인': 848,\n",
       " '명을': 849,\n",
       " '식별': 850,\n",
       " '속': 851,\n",
       " '문제에': 852,\n",
       " '검사': 853,\n",
       " '논의가': 854,\n",
       " '만을': 855,\n",
       " '새롭게': 856,\n",
       " '계': 857,\n",
       " '게임': 858,\n",
       " '인하여': 859,\n",
       " '문서': 860,\n",
       " '현행': 861,\n",
       " '방식': 862,\n",
       " '우리의': 863,\n",
       " '연구에': 864,\n",
       " '것에': 865,\n",
       " '실천': 866,\n",
       " '빠르게': 867,\n",
       " '이용해': 868,\n",
       " '챗봇': 869,\n",
       " '속성': 870,\n",
       " '국내외': 871,\n",
       " '전략': 872,\n",
       " '활용되고': 873,\n",
       " '인식을': 874,\n",
       " '의의': 875,\n",
       " '대표적인': 876,\n",
       " '번째': 877,\n",
       " '추진': 878,\n",
       " '경제적': 879,\n",
       " '사용자가': 880,\n",
       " '점이': 881,\n",
       " '응답': 882,\n",
       " '시켜': 883,\n",
       " '지속적으로': 884,\n",
       " '대해서는': 885,\n",
       " '하나': 886,\n",
       " '군집': 887,\n",
       " '현재의': 888,\n",
       " '도시': 889,\n",
       " '관심을': 890,\n",
       " '근거': 891,\n",
       " '보았다': 892,\n",
       " '직업': 893,\n",
       " '선행': 894,\n",
       " '논의를': 895,\n",
       " '기': 896,\n",
       " '변수': 897,\n",
       " '특허': 898,\n",
       " '되며': 899,\n",
       " '의사소통': 900,\n",
       " '않다': 901,\n",
       " '제한': 902,\n",
       " '파악하고': 903,\n",
       " '데이터는': 904,\n",
       " '알고리즘의': 905,\n",
       " '작동': 906,\n",
       " '도로': 907,\n",
       " '방법의': 908,\n",
       " '실정': 909,\n",
       " '표준': 910,\n",
       " '구조를': 911,\n",
       " '긍정적': 912,\n",
       " '과거': 913,\n",
       " '주는': 914,\n",
       " '대부분': 915,\n",
       " '함을': 916,\n",
       " '진화': 917,\n",
       " '문제는': 918,\n",
       " '하려는': 919,\n",
       " '도덕적': 920,\n",
       " '반면': 921,\n",
       " '중요하다': 922,\n",
       " '경험을': 923,\n",
       " '상대적으로': 924,\n",
       " '딥': 925,\n",
       " '작업': 926,\n",
       " '전력': 927,\n",
       " '저장': 928,\n",
       " '동작': 929,\n",
       " '인공신경망': 930,\n",
       " '필요성이': 931,\n",
       " '테스트': 932,\n",
       " '생명': 933,\n",
       " '도출하': 934,\n",
       " '환경에': 935,\n",
       " '목적이': 936,\n",
       " '시키기': 937,\n",
       " '성능이': 938,\n",
       " '지적': 939,\n",
       " '활발히': 940,\n",
       " '오늘날': 941,\n",
       " '마음': 942,\n",
       " '자연': 943,\n",
       " '테크놀로지': 944,\n",
       " '규정': 945,\n",
       " '오류': 946,\n",
       " '정확한': 947,\n",
       " '것': 948,\n",
       " '훈련': 949,\n",
       " '목표': 950,\n",
       " '증대': 951,\n",
       " '이미지를': 952,\n",
       " '값을': 953,\n",
       " '어느': 954,\n",
       " '보장': 955,\n",
       " '논문': 956,\n",
       " '일부': 957,\n",
       " '으로서': 958,\n",
       " '실시간으로': 959,\n",
       " '프라이버시': 960,\n",
       " '받고': 961,\n",
       " '학습에': 962,\n",
       " '보다는': 963,\n",
       " '시대를': 964,\n",
       " '포함한': 965,\n",
       " '인성': 966,\n",
       " '교육공학': 967,\n",
       " '공할': 968,\n",
       " '20': 969,\n",
       " '기반한': 970,\n",
       " '웨어러블': 971,\n",
       " '시키는': 972,\n",
       " '서버': 973,\n",
       " '준비': 974,\n",
       " '기준': 975,\n",
       " '되었고': 976,\n",
       " '촉진': 977,\n",
       " '시키고': 978,\n",
       " '인간을': 979,\n",
       " '번역': 980,\n",
       " '프로그래밍': 981,\n",
       " '분석하는': 982,\n",
       " '문헌': 983,\n",
       " '수도': 984,\n",
       " '영역에': 985,\n",
       " '자율': 986,\n",
       " '점': 987,\n",
       " '제조': 988,\n",
       " '고려한': 989,\n",
       " '현장에서': 990,\n",
       " '파악하': 991,\n",
       " '입법': 992,\n",
       " '증강현실': 993,\n",
       " '야기': 994,\n",
       " '도움을': 995,\n",
       " '계획': 996,\n",
       " '책임을': 997,\n",
       " '갖고': 998,\n",
       " '투자': 999,\n",
       " '비교하여': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41225 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x2337507c608>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2805 samples, validate on 935 samples\n",
      "Epoch 1/30\n",
      "2805/2805 [==============================] - 78s 28ms/step - loss: 2.0530 - val_loss: 2.2762\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_ls64_v1_01_2.27624.h5\n",
      "Epoch 2/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 1.1211 - val_loss: 1.2422\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_ls64_v1_02_1.24218.h5\n",
      "Epoch 3/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 1.0356 - val_loss: 0.8940\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_ls64_v1_03_0.89404.h5\n",
      "Epoch 4/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 0.9709 - val_loss: 0.8394\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_ls64_v1_04_0.83944.h5\n",
      "Epoch 5/30\n",
      "2805/2805 [==============================] - 79s 28ms/step - loss: 0.9199 - val_loss: 0.8260\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_ls64_v1_05_0.82600.h5\n",
      "Epoch 6/30\n",
      "2805/2805 [==============================] - 79s 28ms/step - loss: 0.9062 - val_loss: 0.7907\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_ls64_v1_06_0.79066.h5\n",
      "Epoch 7/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 0.8679 - val_loss: 0.7869\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_ls64_v1_07_0.78685.h5\n",
      "Epoch 8/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 0.8501 - val_loss: 0.8489\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_ls64_v1_08_0.84892.h5\n",
      "Epoch 9/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 0.8173 - val_loss: 0.7863\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_ls64_v1_09_0.78634.h5\n",
      "Epoch 10/30\n",
      "2805/2805 [==============================] - 77s 27ms/step - loss: 0.8023 - val_loss: 0.8209\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_ls64_v1_10_0.82087.h5\n",
      "Epoch 11/30\n",
      "2805/2805 [==============================] - 78s 28ms/step - loss: 0.7745 - val_loss: 0.7847\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_ls64_v1_11_0.78472.h5\n",
      "Epoch 12/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.7440 - val_loss: 0.8001\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_rae_ls64_v1_12_0.80013.h5\n",
      "Epoch 13/30\n",
      "2805/2805 [==============================] - 75s 27ms/step - loss: 0.7218 - val_loss: 0.7868\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_rae_ls64_v1_13_0.78676.h5\n",
      "Epoch 14/30\n",
      "2805/2805 [==============================] - 74s 26ms/step - loss: 0.6911 - val_loss: 0.7776\n",
      "\n",
      "Epoch 00014: saving model to ./save_models/han_rae_ls64_v1_14_0.77761.h5\n",
      "Epoch 15/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.6628 - val_loss: 0.8115\n",
      "\n",
      "Epoch 00015: saving model to ./save_models/han_rae_ls64_v1_15_0.81145.h5\n",
      "Epoch 16/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.6355 - val_loss: 0.7989\n",
      "\n",
      "Epoch 00016: saving model to ./save_models/han_rae_ls64_v1_16_0.79885.h5\n",
      "Epoch 17/30\n",
      "2805/2805 [==============================] - 77s 28ms/step - loss: 0.6109 - val_loss: 0.8271\n",
      "\n",
      "Epoch 00017: saving model to ./save_models/han_rae_ls64_v1_17_0.82710.h5\n",
      "Epoch 18/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.5864 - val_loss: 0.7996\n",
      "\n",
      "Epoch 00018: saving model to ./save_models/han_rae_ls64_v1_18_0.79956.h5\n",
      "Epoch 19/30\n",
      "2805/2805 [==============================] - 76s 27ms/step - loss: 0.5546 - val_loss: 0.8276\n",
      "\n",
      "Epoch 00019: saving model to ./save_models/han_rae_ls64_v1_19_0.82760.h5\n",
      "time : 1464.7524852752686\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(64)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_ls64_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4364000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                3264      \n",
      "=================================================================\n",
      "Total params: 4,714,614\n",
      "Trainable params: 591,614\n",
      "Non-trainable params: 4,123,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_ls64_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_ls64_v1_14_0.77761.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8113311564858584"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.178043  , -0.00762871,  2.245517  , ...,  0.06828783,\n",
       "         3.366321  ,  1.0371809 ],\n",
       "       [ 2.0095937 , -0.0453414 ,  1.3402305 , ...,  0.06533381,\n",
       "         1.0147538 ,  1.3568722 ],\n",
       "       [ 2.0112689 ,  0.01373455,  1.3771763 , ..., -0.13745493,\n",
       "         2.4960663 ,  2.0548496 ],\n",
       "       ...,\n",
       "       [ 2.0771034 , -0.04939099,  1.9464941 , ...,  0.05078008,\n",
       "         2.6431077 ,  1.402715  ],\n",
       "       [ 1.9231591 , -0.05450096,  2.6332383 , ...,  0.0441407 ,\n",
       "         1.98716   ,  1.2387931 ],\n",
       "       [ 2.6334128 , -0.02687363,  0.96413904, ...,  0.1374223 ,\n",
       "         2.2064526 ,  2.3903685 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_ls64_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8637237e-08, 5.3007091e-12, 6.8331894e-04, ..., 5.9572874e-10,\n",
       "        1.1229651e-07, 4.1043636e-06],\n",
       "       [1.4716943e-21, 7.5720232e-14, 6.1136350e-20, ..., 1.5548214e-11,\n",
       "        2.6374017e-17, 2.5899014e-08],\n",
       "       [1.5198361e-14, 3.6817220e-12, 1.7104508e-18, ..., 5.8300795e-12,\n",
       "        2.1767535e-10, 3.0322602e-11],\n",
       "       ...,\n",
       "       [5.3847532e-10, 1.2071948e-11, 4.7696767e-06, ..., 1.0521330e-11,\n",
       "        4.7347051e-09, 1.3031920e-06],\n",
       "       [6.1980396e-13, 6.0262674e-14, 2.3045475e-08, ..., 1.0548535e-15,\n",
       "        7.3065912e-08, 1.2710889e-05],\n",
       "       [1.6340153e-13, 3.4489572e-14, 1.2089555e-18, ..., 5.3586627e-12,\n",
       "        3.4280623e-14, 1.0933709e-12]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3D프린팅</th>\n",
       "      <th>4차산업</th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>STEAM교육</th>\n",
       "      <th>가상현실</th>\n",
       "      <th>감성</th>\n",
       "      <th>감성분석</th>\n",
       "      <th>감정</th>\n",
       "      <th>강한인공지능</th>\n",
       "      <th>강화학습</th>\n",
       "      <th>...</th>\n",
       "      <th>핀테크</th>\n",
       "      <th>학습</th>\n",
       "      <th>학습동기</th>\n",
       "      <th>학습성과</th>\n",
       "      <th>학업성취도</th>\n",
       "      <th>합성곱신경망</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>헬스케어</th>\n",
       "      <th>혁신</th>\n",
       "      <th>협업</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3D프린팅  4차산업  4차산업혁명  STEAM교육  가상현실  감성  감성분석  감정  강한인공지능  강화학습  ...  핀테크  \\\n",
       "0        0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "1        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "2        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "3        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "4        0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "..     ...   ...     ...      ...   ...  ..   ...  ..     ...   ...  ...  ...   \n",
       "930      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "931      0     0       1        0     0   0     0   0       0     0  ...    0   \n",
       "932      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "933      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "934      0     0       0        0     0   0     0   0       0     0  ...    0   \n",
       "\n",
       "     학습  학습동기  학습성과  학업성취도  합성곱신경망  핵심역량  헬스케어  혁신  협업  \n",
       "0     0     0     0      0       0     0     0   0   0  \n",
       "1     0     0     0      0       0     0     0   0   0  \n",
       "2     0     0     0      0       0     0     0   0   0  \n",
       "3     0     0     0      0       0     0     0   0   0  \n",
       "4     0     0     0      0       0     0     0   0   0  \n",
       "..   ..   ...   ...    ...     ...   ...   ...  ..  ..  \n",
       "930   0     0     0      0       0     0     0   0   0  \n",
       "931   0     0     0      0       0     0     0   0   0  \n",
       "932   0     0     0      0       0     0     0   0   0  \n",
       "933   0     0     0      0       0     0     0   0   0  \n",
       "934   0     0     0      0       0     0     0   0   0  \n",
       "\n",
       "[935 rows x 262 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/paper_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(935, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.0877005347593583\n",
      "precision :  0.5414937759336099\n",
      "recall :  0.15713425647200482\n",
      "f1 :  0.2435837610825945\n",
      "------------------------\n",
      "hamming_loss :  0.0066171367922602765\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.0877005347593583\n",
      "precision :  0.26684491978609626\n",
      "recall :  0.16793226381461676\n",
      "f1 :  0.194331550802139\n",
      "------------------------\n",
      "hamming_loss :  0.0066171367922602765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ccf08da81ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wrong example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m attention_extractor = Model(inputs=[document_input],\n\u001b[0m\u001b[0;32m      3\u001b[0m                             outputs=[word_attention, sentence_attention])\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_input' is not defined"
     ]
    }
   ],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
