{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6523338651177492088\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 397390497491477547\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4869287936\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1900817314732815840\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2860275469765542880\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_extra_all_v4_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_extra_all_v4_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_extra_all_v4_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...</td>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...</td>\n",
       "      <td>2.523835</td>\n",
       "      <td>3.260611</td>\n",
       "      <td>1.669686</td>\n",
       "      <td>3.370940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...</td>\n",
       "      <td>0.930321</td>\n",
       "      <td>0.542420</td>\n",
       "      <td>1.852430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...</td>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...</td>\n",
       "      <td>4.333861</td>\n",
       "      <td>3.978497</td>\n",
       "      <td>3.662714</td>\n",
       "      <td>3.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...</td>\n",
       "      <td>4.946594</td>\n",
       "      <td>8.686300</td>\n",
       "      <td>1.476334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...</td>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...</td>\n",
       "      <td>1.834378</td>\n",
       "      <td>1.115448</td>\n",
       "      <td>4.501013</td>\n",
       "      <td>3.099241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...</td>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2797</td>\n",
       "      <td>본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...</td>\n",
       "      <td>1.561563</td>\n",
       "      <td>1.182006</td>\n",
       "      <td>2.323821</td>\n",
       "      <td>1.482143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...  5.194959   \n",
       "1              1  최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...  2.523835   \n",
       "2              2  글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...  0.930321   \n",
       "3              3  본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...  5.194959   \n",
       "4              4  본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...  4.333861   \n",
       "...          ...                                                ...       ...   \n",
       "2793        2793  본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...  4.946594   \n",
       "2794        2794  본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...  7.886700   \n",
       "2795        2795  경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...  1.834378   \n",
       "2796        2796  본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...  7.886700   \n",
       "2797        2797  본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...  1.561563   \n",
       "\n",
       "             1         2         3  \n",
       "0     0.463620  3.099519  1.837639  \n",
       "1     3.260611  1.669686  3.370940  \n",
       "2     0.542420  1.852430  0.000000  \n",
       "3     0.463620  3.099519  1.837639  \n",
       "4     3.978497  3.662714  3.577977  \n",
       "...        ...       ...       ...  \n",
       "2793  8.686300  1.476334  0.000000  \n",
       "2794  2.730818  1.936125  2.332378  \n",
       "2795  1.115448  4.501013  3.099241  \n",
       "2796  2.730818  1.936125  2.332378  \n",
       "2797  1.182006  2.323821  1.482143  \n",
       "\n",
       "[2798 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...</td>\n",
       "      <td>4.252167</td>\n",
       "      <td>2.948070</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>2.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...</td>\n",
       "      <td>4.448070</td>\n",
       "      <td>5.104998</td>\n",
       "      <td>1.674422</td>\n",
       "      <td>0.211541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...</td>\n",
       "      <td>4.941952</td>\n",
       "      <td>1.189352</td>\n",
       "      <td>0.948080</td>\n",
       "      <td>5.824813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...</td>\n",
       "      <td>7.061509</td>\n",
       "      <td>4.723454</td>\n",
       "      <td>1.920044</td>\n",
       "      <td>4.697660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...</td>\n",
       "      <td>2.117849</td>\n",
       "      <td>2.717265</td>\n",
       "      <td>1.860312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...</td>\n",
       "      <td>4.311187</td>\n",
       "      <td>1.612342</td>\n",
       "      <td>2.545564</td>\n",
       "      <td>1.304350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174629</td>\n",
       "      <td>5.023723</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...</td>\n",
       "      <td>3.285078</td>\n",
       "      <td>3.259609</td>\n",
       "      <td>2.390505</td>\n",
       "      <td>1.122444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...</td>\n",
       "      <td>2.872831</td>\n",
       "      <td>2.474819</td>\n",
       "      <td>1.055902</td>\n",
       "      <td>2.022084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...  4.252167   \n",
       "1             1  기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...  4.448070   \n",
       "2             2  본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...  4.941952   \n",
       "3             3  본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...  7.061509   \n",
       "4             4  오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...  2.356642   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...  2.117849   \n",
       "928         928  본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...  4.311187   \n",
       "929         929  한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...  2.356642   \n",
       "930         930  본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...  3.285078   \n",
       "931         931  본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...  2.872831   \n",
       "\n",
       "            1         2         3  \n",
       "0    2.948070  0.193734  2.841667  \n",
       "1    5.104998  1.674422  0.211541  \n",
       "2    1.189352  0.948080  5.824813  \n",
       "3    4.723454  1.920044  4.697660  \n",
       "4    6.174630  5.023724  1.891224  \n",
       "..        ...       ...       ...  \n",
       "927  2.717265  1.860312  0.000000  \n",
       "928  1.612342  2.545564  1.304350  \n",
       "929  6.174629  5.023723  1.891224  \n",
       "930  3.259609  2.390505  1.122444  \n",
       "931  2.474819  1.055902  2.022084  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...</td>\n",
       "      <td>1.728056</td>\n",
       "      <td>2.490819</td>\n",
       "      <td>1.481277</td>\n",
       "      <td>0.309363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...</td>\n",
       "      <td>0.569367</td>\n",
       "      <td>2.411349</td>\n",
       "      <td>0.669784</td>\n",
       "      <td>2.912357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>3.581591</td>\n",
       "      <td>5.395686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...</td>\n",
       "      <td>5.353525</td>\n",
       "      <td>2.865519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.773600</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>4.443259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.431511</td>\n",
       "      <td>3.441139</td>\n",
       "      <td>2.680054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...</td>\n",
       "      <td>3.078681</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>1.338593</td>\n",
       "      <td>0.836499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...</td>\n",
       "      <td>7.714356</td>\n",
       "      <td>5.515837</td>\n",
       "      <td>1.598979</td>\n",
       "      <td>2.919135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...</td>\n",
       "      <td>1.897139</td>\n",
       "      <td>2.673828</td>\n",
       "      <td>1.905965</td>\n",
       "      <td>2.324860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...  2.356642   \n",
       "1             1  본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...  1.728056   \n",
       "2             2  중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...  0.569367   \n",
       "3             3  본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...  1.272908   \n",
       "4             4  본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...  5.353525   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...  0.000000   \n",
       "928         928  최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...  0.000000   \n",
       "929         929  본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...  3.078681   \n",
       "930         930  본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...  7.714356   \n",
       "931         931  2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...  1.897139   \n",
       "\n",
       "            1         2         3  \n",
       "0    6.174630  5.023724  1.891224  \n",
       "1    2.490819  1.481277  0.309363  \n",
       "2    2.411349  0.669784  2.912357  \n",
       "3    0.038271  3.581591  5.395686  \n",
       "4    2.865519  0.000000  1.439444  \n",
       "..        ...       ...       ...  \n",
       "927  1.773600  0.121333  4.443259  \n",
       "928  3.431511  3.441139  2.680054  \n",
       "929  0.956077  1.338593  0.836499  \n",
       "930  5.515837  1.598979  2.919135  \n",
       "931  2.673828  1.905965  2.324860  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...\n",
       "1       최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...\n",
       "2       글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...\n",
       "3       본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...\n",
       "4       본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...\n",
       "                              ...                        \n",
       "2793    본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...\n",
       "2794    본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...\n",
       "2795    경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...\n",
       "2796    본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...\n",
       "2797    본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...\n",
       "Name: abstract, Length: 2798, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.523835</td>\n",
       "      <td>3.260611</td>\n",
       "      <td>1.669686</td>\n",
       "      <td>3.370940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930321</td>\n",
       "      <td>0.542420</td>\n",
       "      <td>1.852430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.333861</td>\n",
       "      <td>3.978497</td>\n",
       "      <td>3.662714</td>\n",
       "      <td>3.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>4.946594</td>\n",
       "      <td>8.686300</td>\n",
       "      <td>1.476334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>1.834378</td>\n",
       "      <td>1.115448</td>\n",
       "      <td>4.501013</td>\n",
       "      <td>3.099241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>1.561563</td>\n",
       "      <td>1.182006</td>\n",
       "      <td>2.323821</td>\n",
       "      <td>1.482143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     5.194959  0.463620  3.099519  1.837639\n",
       "1     2.523835  3.260611  1.669686  3.370940\n",
       "2     0.930321  0.542420  1.852430  0.000000\n",
       "3     5.194959  0.463620  3.099519  1.837639\n",
       "4     4.333861  3.978497  3.662714  3.577977\n",
       "...        ...       ...       ...       ...\n",
       "2793  4.946594  8.686300  1.476334  0.000000\n",
       "2794  7.886700  2.730818  1.936125  2.332378\n",
       "2795  1.834378  1.115448  4.501013  3.099241\n",
       "2796  7.886700  2.730818  1.936125  2.332378\n",
       "2797  1.561563  1.182006  2.323821  1.482143\n",
       "\n",
       "[2798 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...\n",
       "1      기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...\n",
       "2      본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...\n",
       "3      본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...\n",
       "4      오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...\n",
       "                             ...                        \n",
       "927    본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...\n",
       "928    본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...\n",
       "929    한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...\n",
       "930    본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...\n",
       "931    본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.252167</td>\n",
       "      <td>2.948070</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>2.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.448070</td>\n",
       "      <td>5.104998</td>\n",
       "      <td>1.674422</td>\n",
       "      <td>0.211541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.941952</td>\n",
       "      <td>1.189352</td>\n",
       "      <td>0.948080</td>\n",
       "      <td>5.824813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.061509</td>\n",
       "      <td>4.723454</td>\n",
       "      <td>1.920044</td>\n",
       "      <td>4.697660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>2.117849</td>\n",
       "      <td>2.717265</td>\n",
       "      <td>1.860312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>4.311187</td>\n",
       "      <td>1.612342</td>\n",
       "      <td>2.545564</td>\n",
       "      <td>1.304350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174629</td>\n",
       "      <td>5.023723</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>3.285078</td>\n",
       "      <td>3.259609</td>\n",
       "      <td>2.390505</td>\n",
       "      <td>1.122444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2.872831</td>\n",
       "      <td>2.474819</td>\n",
       "      <td>1.055902</td>\n",
       "      <td>2.022084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    4.252167  2.948070  0.193734  2.841667\n",
       "1    4.448070  5.104998  1.674422  0.211541\n",
       "2    4.941952  1.189352  0.948080  5.824813\n",
       "3    7.061509  4.723454  1.920044  4.697660\n",
       "4    2.356642  6.174630  5.023724  1.891224\n",
       "..        ...       ...       ...       ...\n",
       "927  2.117849  2.717265  1.860312  0.000000\n",
       "928  4.311187  1.612342  2.545564  1.304350\n",
       "929  2.356642  6.174629  5.023723  1.891224\n",
       "930  3.285078  3.259609  2.390505  1.122444\n",
       "931  2.872831  2.474819  1.055902  2.022084\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...\n",
       "1      본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...\n",
       "2      중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...\n",
       "3      본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...\n",
       "4      본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...\n",
       "                             ...                        \n",
       "927    본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...\n",
       "928    최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...\n",
       "929    본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...\n",
       "930    본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...\n",
       "931    2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.728056</td>\n",
       "      <td>2.490819</td>\n",
       "      <td>1.481277</td>\n",
       "      <td>0.309363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569367</td>\n",
       "      <td>2.411349</td>\n",
       "      <td>0.669784</td>\n",
       "      <td>2.912357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.272908</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>3.581591</td>\n",
       "      <td>5.395686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.353525</td>\n",
       "      <td>2.865519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.773600</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>4.443259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.431511</td>\n",
       "      <td>3.441139</td>\n",
       "      <td>2.680054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3.078681</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>1.338593</td>\n",
       "      <td>0.836499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>7.714356</td>\n",
       "      <td>5.515837</td>\n",
       "      <td>1.598979</td>\n",
       "      <td>2.919135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1.897139</td>\n",
       "      <td>2.673828</td>\n",
       "      <td>1.905965</td>\n",
       "      <td>2.324860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    2.356642  6.174630  5.023724  1.891224\n",
       "1    1.728056  2.490819  1.481277  0.309363\n",
       "2    0.569367  2.411349  0.669784  2.912357\n",
       "3    1.272908  0.038271  3.581591  5.395686\n",
       "4    5.353525  2.865519  0.000000  1.439444\n",
       "..        ...       ...       ...       ...\n",
       "927  0.000000  1.773600  0.121333  4.443259\n",
       "928  0.000000  3.431511  3.441139  2.680054\n",
       "929  3.078681  0.956077  1.338593  0.836499\n",
       "930  7.714356  5.515837  1.598979  2.919135\n",
       "931  1.897139  2.673828  1.905965  2.324860\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2798/2798 [01:55<00:00, 24.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:42<00:00, 21.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:41<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['본',\n",
       "  '연구는',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련이',\n",
       "  '인지',\n",
       "  '손상',\n",
       "  '이',\n",
       "  '있는',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '및',\n",
       "  '만족감에',\n",
       "  '미치는',\n",
       "  '영향을',\n",
       "  '알고자',\n",
       "  '하였다',\n",
       "  '인천',\n",
       "  '에',\n",
       "  '소재한',\n",
       "  '병원에',\n",
       "  '입원',\n",
       "  '중인',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자',\n",
       "  '들',\n",
       "  '이',\n",
       "  '본',\n",
       "  '연구에',\n",
       "  '참여',\n",
       "  '하였다',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '대상자들은',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '으로',\n",
       "  '7',\n",
       "  '명씩',\n",
       "  '무작위',\n",
       "  '배정',\n",
       "  '되었다',\n",
       "  '두',\n",
       "  '그룹의',\n",
       "  '대상자들은',\n",
       "  '모두',\n",
       "  '전통적인',\n",
       "  '인지',\n",
       "  '치료를',\n",
       "  '4',\n",
       "  '주간',\n",
       "  '주',\n",
       "  '5회',\n",
       "  '1일',\n",
       "  '30분',\n",
       "  '의',\n",
       "  '중재를',\n",
       "  '받았으며',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련을',\n",
       "  '30분',\n",
       "  '씩',\n",
       "  '추가적으로',\n",
       "  '실시',\n",
       "  '하였다',\n",
       "  '평가는',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후에',\n",
       "  '한국판',\n",
       "  '간이',\n",
       "  '정신',\n",
       "  '상태',\n",
       "  '검사',\n",
       "  '한국판',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '시각',\n",
       "  '상사',\n",
       "  '척도를',\n",
       "  '사용하여',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '만족감을',\n",
       "  '측정',\n",
       "  '하였다',\n",
       "  '연구',\n",
       "  '결과',\n",
       "  '두',\n",
       "  '그룹은',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후로',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가와',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '변화',\n",
       "  '량',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '대조군',\n",
       "  '보다',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '만족감',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '은',\n",
       "  '유의한',\n",
       "  '차이가',\n",
       "  '없었다',\n",
       "  '05',\n",
       "  '본',\n",
       "  '연구의',\n",
       "  '결과를',\n",
       "  '통하여',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련은',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '향상에',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '효과를',\n",
       "  '기대할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '중재법',\n",
       "  '으로',\n",
       "  '사료',\n",
       "  '된다'],\n",
       " ['기독교',\n",
       "  '대학은',\n",
       "  '대학생의',\n",
       "  '스트레스',\n",
       "  '상황에서',\n",
       "  '영향을',\n",
       "  '조절',\n",
       "  '하여',\n",
       "  '완충시켜주거나',\n",
       "  '적응을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '잘',\n",
       "  '분석하여',\n",
       "  '그',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '프로그램을',\n",
       "  '개발',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있다',\n",
       "  '그러므로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '자아탄력성',\n",
       "  '과',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '소그룹',\n",
       "  '활동',\n",
       "  '간의',\n",
       "  '관계성',\n",
       "  '을',\n",
       "  '탐구',\n",
       "  '하여',\n",
       "  '대학생의',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '증진을',\n",
       "  '위한',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '역할을',\n",
       "  '모색하',\n",
       "  '는',\n",
       "  '것을',\n",
       "  '목적으로',\n",
       "  '삼는다',\n",
       "  '구체적으로',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '대표적',\n",
       "  '구성요소',\n",
       "  '인',\n",
       "  '낙관성',\n",
       "  '활력성',\n",
       "  '감정',\n",
       "  '통제력',\n",
       "  '그리고',\n",
       "  '대인관계',\n",
       "  '능력을',\n",
       "  '강화',\n",
       "  '시킴에',\n",
       "  '있어서',\n",
       "  '소그룹',\n",
       "  '활동의',\n",
       "  '특성들',\n",
       "  '과',\n",
       "  '어떠한',\n",
       "  '관련',\n",
       "  '이',\n",
       "  '있는지를',\n",
       "  '분석하는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '그리고',\n",
       "  '이러한',\n",
       "  '분석에',\n",
       "  '기초하여',\n",
       "  '기독교',\n",
       "  '대학에서',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '통한',\n",
       "  '영적',\n",
       "  '돌봄',\n",
       "  '이',\n",
       "  '효과',\n",
       "  '적',\n",
       "  '으로',\n",
       "  '이루어질',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '몇',\n",
       "  '가지',\n",
       "  '사례',\n",
       "  '들',\n",
       "  '을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '결론적으로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '소그룹',\n",
       "  '활동이',\n",
       "  '스트레스로',\n",
       "  '부터의',\n",
       "  '회복을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '네',\n",
       "  '기본',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시켜',\n",
       "  '주기',\n",
       "  '때문에',\n",
       "  '기독교',\n",
       "  '대학이',\n",
       "  '보다',\n",
       "  '적극적으로',\n",
       "  '종교',\n",
       "  '교육적',\n",
       "  '인',\n",
       "  '목적의',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '개발',\n",
       "  '시킬',\n",
       "  '것을',\n",
       "  '제안',\n",
       "  '한다'],\n",
       " ['본',\n",
       "  '연구는',\n",
       "  '초등학생의',\n",
       "  '방과후',\n",
       "  '운동',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '정신건강',\n",
       "  '과의',\n",
       "  '관계를',\n",
       "  '탐색',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '수행',\n",
       "  '되었다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '서울시',\n",
       "  '소재의',\n",
       "  '초등학생',\n",
       "  '217',\n",
       "  '명이',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '척도',\n",
       "  '한국',\n",
       "  '정보화',\n",
       "  '진흥원',\n",
       "  '2011',\n",
       "  '와',\n",
       "  '정신건강',\n",
       "  '측정',\n",
       "  '척도',\n",
       "  '김동일',\n",
       "  '안현',\n",
       "  '의',\n",
       "  '2006',\n",
       "  '에',\n",
       "  '응답',\n",
       "  '하였다',\n",
       "  '수집된',\n",
       "  '자료는',\n",
       "  '먼저',\n",
       "  '운동',\n",
       "  '시간이',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '35시간',\n",
       "  '매일운동으로',\n",
       "  '집단을',\n",
       "  '분류하여',\n",
       "  '스마트폰',\n",
       "  '중독과',\n",
       "  '정신건강',\n",
       "  '의',\n",
       "  '차이를',\n",
       "  '분석',\n",
       "  '하였다',\n",
       "  '그',\n",
       "  '결과',\n",
       "  '매일운동',\n",
       "  '집단은',\n",
       "  '주당',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '운동',\n",
       "  '집단에',\n",
       "  '비해',\n",
       "  '일상생활',\n",
       "  '장애',\n",
       "  '금단',\n",
       "  '내성',\n",
       "  '가상세계',\n",
       "  '의',\n",
       "  '점수가',\n",
       "  '모두',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났고',\n",
       "  '정신건강',\n",
       "  '에서',\n",
       "  '우울',\n",
       "  '충동',\n",
       "  '공격성',\n",
       "  '이',\n",
       "  '유의하게',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '경로분석',\n",
       "  '에서',\n",
       "  '운동',\n",
       "  '시간은',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '직접',\n",
       "  '적',\n",
       "  '인',\n",
       "  '효과가',\n",
       "  '있었으며',\n",
       "  '정신건강',\n",
       "  '을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '효과에서',\n",
       "  '는',\n",
       "  '직접효과',\n",
       "  '는',\n",
       "  '없고',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '통한',\n",
       "  '간접효과',\n",
       "  '만이',\n",
       "  '나타났다'],\n",
       " ['본',\n",
       "  '연구의',\n",
       "  '목적은',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여',\n",
       "  '의의',\n",
       "  '를',\n",
       "  '살펴보고',\n",
       "  '학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '간의',\n",
       "  '연계',\n",
       "  '활동을',\n",
       "  '보다',\n",
       "  '활성화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '방안을',\n",
       "  '제시하',\n",
       "  '는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '관련',\n",
       "  '연구',\n",
       "  '문헌을',\n",
       "  '검토',\n",
       "  '하고',\n",
       "  '관계자를',\n",
       "  '인터뷰',\n",
       "  '하고',\n",
       "  '마을교육',\n",
       "  '과',\n",
       "  '방과후학교',\n",
       "  '의',\n",
       "  '강점',\n",
       "  '약점',\n",
       "  '기회',\n",
       "  '위기',\n",
       "  '요인들을',\n",
       "  '분석',\n",
       "  '하고',\n",
       "  '연계',\n",
       "  '활성화를',\n",
       "  '위한',\n",
       "  '방안을',\n",
       "  '제시',\n",
       "  '하였다',\n",
       "  '연구결과',\n",
       "  '방과후학교',\n",
       "  '는',\n",
       "  '학부모',\n",
       "  '의',\n",
       "  '높은',\n",
       "  '만족도',\n",
       "  '사교육비',\n",
       "  '경감',\n",
       "  '등에',\n",
       "  '효과가',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '인식',\n",
       "  '되는',\n",
       "  '등',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '기능을',\n",
       "  '수행하고',\n",
       "  '있으며',\n",
       "  '지역사회',\n",
       "  '와의',\n",
       "  '연계',\n",
       "  '활동',\n",
       "  '강화를',\n",
       "  '중요하게',\n",
       "  '생각',\n",
       "  '하고',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '최근에는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '이',\n",
       "  '서로',\n",
       "  '연계',\n",
       "  '하는',\n",
       "  '사례가',\n",
       "  '나타나고',\n",
       "  '있다',\n",
       "  '이는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '연계',\n",
       "  '를',\n",
       "  '통해',\n",
       "  '학생들이',\n",
       "  '지역사회',\n",
       "  '공동체',\n",
       "  '의식을',\n",
       "  '함양',\n",
       "  '하고',\n",
       "  '지역사회',\n",
       "  '의',\n",
       "  '공동체',\n",
       "  '성',\n",
       "  '을',\n",
       "  '회복하는',\n",
       "  '밑거름',\n",
       "  '이',\n",
       "  '된다는',\n",
       "  '측면에서',\n",
       "  '매우',\n",
       "  '중요한',\n",
       "  '의미를',\n",
       "  '지니고',\n",
       "  '있다',\n",
       "  '이러한',\n",
       "  '연구',\n",
       "  '결과를',\n",
       "  '토대로',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여가',\n",
       "  '보다',\n",
       "  '활성화를',\n",
       "  '위',\n",
       "  '해서는',\n",
       "  '단위',\n",
       "  '학교에서는',\n",
       "  '마을교육',\n",
       "  '만이',\n",
       "  '가지',\n",
       "  '고',\n",
       "  '있는',\n",
       "  '고유의',\n",
       "  '특징을',\n",
       "  '충분히',\n",
       "  '이해',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있으며',\n",
       "  '마을교육',\n",
       "  '단체들은',\n",
       "  '방과후학교',\n",
       "  '활동을',\n",
       "  '위한',\n",
       "  '전문성',\n",
       "  '을',\n",
       "  '제고',\n",
       "  '해야',\n",
       "  '함을',\n",
       "  '대안으로',\n",
       "  '제시',\n",
       "  '하였다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3730/3730 [00:01<00:00, 2921.86it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이를',\n",
       " '위해',\n",
       " '한국청소년정책연구원에서',\n",
       " '구축한',\n",
       " '한국아동⋅',\n",
       " '청소년패널조사(Korean',\n",
       " 'Children',\n",
       " '&',\n",
       " 'Youth',\n",
       " 'Panel',\n",
       " 'Survey)의',\n",
       " '2013년~2016년(4차,',\n",
       " '5차,',\n",
       " '6차,',\n",
       " '7차)',\n",
       " '의',\n",
       " '데이터를',\n",
       " '사용하였다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3730/3730 [00:00<00:00, 340073.77it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하고, 청소년의 사회 자본이 주관적 삶의 만족도에 미치는 영향과 종단적 변화 양상을 잠재성장모델(Latent Growth Model)을 활용하여 분석하였다',\n",
       " '이를 위해 한국청소년정책연구원에서 구축한 한국아동⋅ 청소년패널조사(Korean Children & Youth Panel Survey)의 2013년~2016년(4차, 5차, 6차, 7차) 의 데이터를 사용하였다',\n",
       " '연구결과를 살펴보면 첫째, 청소년의 사회자본과 주관적 삶의 만족도의초기 값과의 관계는 학교 또래 관계(+), 부모와의 관계(+), 지역사회 인식(+), 교사와의 관계(+), 공동체 의식(+)이 정적인 관계가 있는 것으로 나타났다',\n",
       " '또한 청소년의 주관적 삶의 만족도에대한 시간에 따른 변화율은 성별(-), 학교 또래 관계(-), 학교 교사와의 관계(-), 공동체의식(-)이영향을 미침을 알 수 있다',\n",
       " '이에 청소년의 주관적 삶의 만족도에 가정 내 부모관계가 여전히 중요하지만 학교 사회자본과 지역사회 사회자본의 중요성 또한 주목하여 이를 강화시킬 수 있는 실천적대안을 제시하였다',\n",
       " '또한 고등학교로 진학하고 시간이 흐름에 따라 학교 또래 관계, 교사와의 관계, 공동체 의식 변수가 스트레스에 대한 보호적 역할을 지속할 수 있도록 학교 현장에 맞는 정책적대안이 필요함을 제언하는 바이다',\n",
       " '본 연구는 청소년의 주관적 삶의 만족도와 사회자본과의 관계와종단적 영향을 보여줌으로서 청소년의 주관적 삶의 만족도 향상을 위한 학문적 기초를 제공함에그 의의가 있을 것이다']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  35\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.892493297587132\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  509\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 18.38516933319746\n",
      "문장 내의 단어 개수 중앙값 : 17.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2798, 20, 200)\n",
      "train_Y_data.shape: (2798, 4)\n",
      "val_X_data.shape: (932, 20, 200)\n",
      "val_Y_data.shape: (932, 4)\n",
      "test_X_data.shape: (932, 20, 200)\n",
      "test_Y_data.shape: (932, 4)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '하였다': 2,\n",
       " '에': 3,\n",
       " '을': 4,\n",
       " '이': 5,\n",
       " '과': 6,\n",
       " '본': 7,\n",
       " '영향을': 8,\n",
       " '대한': 9,\n",
       " '것으로': 10,\n",
       " '적': 11,\n",
       " '및': 12,\n",
       " '수': 13,\n",
       " '를': 14,\n",
       " '미치는': 15,\n",
       " '는': 16,\n",
       " '나타났다': 17,\n",
       " '은': 18,\n",
       " '한': 19,\n",
       " '있는': 20,\n",
       " '하고': 21,\n",
       " '있다': 22,\n",
       " '하는': 23,\n",
       " '인': 24,\n",
       " '연구는': 25,\n",
       " '분석': 26,\n",
       " '연구': 27,\n",
       " '가': 28,\n",
       " '와': 29,\n",
       " '할': 30,\n",
       " '위해': 31,\n",
       " '으로': 32,\n",
       " '통해': 33,\n",
       " '결과': 34,\n",
       " '되었다': 35,\n",
       " '로': 36,\n",
       " '것이': 37,\n",
       " '대상으로': 38,\n",
       " '위한': 39,\n",
       " '연구의': 40,\n",
       " '한다': 41,\n",
       " '고': 42,\n",
       " '다': 43,\n",
       " '이를': 44,\n",
       " '직무': 45,\n",
       " '에서': 46,\n",
       " '우울': 47,\n",
       " '된': 48,\n",
       " '한국': 49,\n",
       " '실시': 50,\n",
       " '들': 51,\n",
       " '하기': 52,\n",
       " '진로': 53,\n",
       " '이러한': 54,\n",
       " '유의한': 55,\n",
       " '그': 56,\n",
       " '확인': 57,\n",
       " '자기': 58,\n",
       " '사회적': 59,\n",
       " '또한': 60,\n",
       " '검증': 61,\n",
       " '둘째': 62,\n",
       " '첫째': 63,\n",
       " '사회': 64,\n",
       " '하여': 65,\n",
       " '중': 66,\n",
       " '그리고': 67,\n",
       " '교육': 68,\n",
       " '관련': 69,\n",
       " '중국': 70,\n",
       " '있었다': 71,\n",
       " '사용': 72,\n",
       " '따라': 73,\n",
       " '지': 74,\n",
       " '이다': 75,\n",
       " '학교': 76,\n",
       " '긍정적': 77,\n",
       " '성': 78,\n",
       " '활용': 79,\n",
       " '삶의': 80,\n",
       " '서비스': 81,\n",
       " '조직': 82,\n",
       " '하였으며': 83,\n",
       " '다음': 84,\n",
       " '제시': 85,\n",
       " '셋째': 86,\n",
       " '명을': 87,\n",
       " '높은': 88,\n",
       " '영향': 89,\n",
       " '학습': 90,\n",
       " '도': 91,\n",
       " '청소년의': 92,\n",
       " '대해': 93,\n",
       " '청소년': 94,\n",
       " '관계를': 95,\n",
       " '경우': 96,\n",
       " '경험': 97,\n",
       " '결과는': 98,\n",
       " '3': 99,\n",
       " '부모': 100,\n",
       " '따른': 101,\n",
       " '4': 102,\n",
       " '결과를': 103,\n",
       " '간': 104,\n",
       " '가장': 105,\n",
       " '2': 106,\n",
       " '이용': 107,\n",
       " '다양한': 108,\n",
       " '가지': 109,\n",
       " '바탕으로': 110,\n",
       " '심리적': 111,\n",
       " '더': 112,\n",
       " '개발': 113,\n",
       " '될': 114,\n",
       " '보다': 115,\n",
       " '요인': 116,\n",
       " '간의': 117,\n",
       " '1': 118,\n",
       " '자료를': 119,\n",
       " '차이가': 120,\n",
       " '연구에서는': 121,\n",
       " '된다': 122,\n",
       " '같다': 123,\n",
       " '서': 124,\n",
       " '모두': 125,\n",
       " '것을': 126,\n",
       " '참여': 127,\n",
       " '위하여': 128,\n",
       " '목적은': 129,\n",
       " '인식': 130,\n",
       " '총': 131,\n",
       " '따라서': 132,\n",
       " '관계': 133,\n",
       " '매개': 134,\n",
       " '증가': 135,\n",
       " '유의미한': 136,\n",
       " '관계에서': 137,\n",
       " '분석을': 138,\n",
       " '문화': 139,\n",
       " '의미': 140,\n",
       " '대학': 141,\n",
       " '후': 142,\n",
       " '수행': 143,\n",
       " '되는': 144,\n",
       " '같은': 145,\n",
       " '개': 146,\n",
       " '해': 147,\n",
       " '논의': 148,\n",
       " '연구를': 149,\n",
       " '하고자': 150,\n",
       " '되고': 151,\n",
       " '개인': 152,\n",
       " '문제': 153,\n",
       " '제공': 154,\n",
       " '특히': 155,\n",
       " '여': 156,\n",
       " '다문화': 157,\n",
       " '등': 158,\n",
       " '구성': 159,\n",
       " '이에': 160,\n",
       " '학년': 161,\n",
       " '프로그램': 162,\n",
       " '제': 163,\n",
       " '평가': 164,\n",
       " '개의': 165,\n",
       " '측정': 166,\n",
       " '일반': 167,\n",
       " '집단': 168,\n",
       " '가족': 169,\n",
       " '정보': 170,\n",
       " '연구결과': 171,\n",
       " '진행': 172,\n",
       " '학업': 173,\n",
       " '지역': 174,\n",
       " '명': 175,\n",
       " '향상': 176,\n",
       " '비교': 177,\n",
       " '효과를': 178,\n",
       " '도출': 179,\n",
       " '명의': 180,\n",
       " '프로그램을': 181,\n",
       " '변화': 182,\n",
       " '만족도': 183,\n",
       " '부터': 184,\n",
       " '적용': 185,\n",
       " '하였고': 186,\n",
       " '중요한': 187,\n",
       " '에서는': 188,\n",
       " '5': 189,\n",
       " '주요': 190,\n",
       " '건강': 191,\n",
       " '정적': 192,\n",
       " '부정적': 193,\n",
       " '조사': 194,\n",
       " '국내': 195,\n",
       " '기술': 196,\n",
       " '했다': 197,\n",
       " '있으며': 198,\n",
       " '하는데': 199,\n",
       " '차이를': 200,\n",
       " '자아존중감': 201,\n",
       " '만족': 202,\n",
       " '통한': 203,\n",
       " '정의': 204,\n",
       " '교사': 205,\n",
       " '자': 206,\n",
       " '까지': 207,\n",
       " '질적': 208,\n",
       " '세': 209,\n",
       " '대': 210,\n",
       " '대학생': 211,\n",
       " '이는': 212,\n",
       " '정서': 213,\n",
       " '때': 214,\n",
       " '차': 215,\n",
       " '스트레스': 216,\n",
       " '나타났으며': 217,\n",
       " '보였다': 218,\n",
       " '통계적으로': 219,\n",
       " '만족도에': 220,\n",
       " '고객': 221,\n",
       " '아니라': 222,\n",
       " '이용하여': 223,\n",
       " '며': 224,\n",
       " '지원': 225,\n",
       " '이었다': 226,\n",
       " '새로운': 227,\n",
       " '생활': 228,\n",
       " '여성': 229,\n",
       " '자료': 230,\n",
       " '각': 231,\n",
       " '에는': 232,\n",
       " '두': 233,\n",
       " '향후': 234,\n",
       " '있음을': 235,\n",
       " '비해': 236,\n",
       " '관한': 237,\n",
       " '척도': 238,\n",
       " '중심으로': 239,\n",
       " '설문조사': 240,\n",
       " '미치': 241,\n",
       " '위': 242,\n",
       " '하위': 243,\n",
       " '인터넷': 244,\n",
       " '감소': 245,\n",
       " '직접': 246,\n",
       " '등의': 247,\n",
       " '수집': 248,\n",
       " '역할을': 249,\n",
       " '대학생의': 250,\n",
       " '함께': 251,\n",
       " '되어': 252,\n",
       " '있어': 253,\n",
       " '상호작용': 254,\n",
       " '연구가': 255,\n",
       " '큰': 256,\n",
       " '탐색': 257,\n",
       " '불안': 258,\n",
       " '학생': 259,\n",
       " '에게': 260,\n",
       " '어떠한': 261,\n",
       " '직업': 262,\n",
       " '매개효과를': 263,\n",
       " '이후': 264,\n",
       " '인지': 265,\n",
       " '대인관계': 266,\n",
       " '통하여': 267,\n",
       " '연구결과를': 268,\n",
       " '형': 269,\n",
       " '토대로': 270,\n",
       " '행동': 271,\n",
       " '해야': 272,\n",
       " '부적': 273,\n",
       " '제안': 274,\n",
       " '고객만족': 275,\n",
       " '분석한': 276,\n",
       " '유의': 277,\n",
       " '노인': 278,\n",
       " '많은': 279,\n",
       " '즉': 280,\n",
       " '요인을': 281,\n",
       " '방안을': 282,\n",
       " '효과': 283,\n",
       " '데': 284,\n",
       " '주관적': 285,\n",
       " '화': 286,\n",
       " '국가': 287,\n",
       " '해서는': 288,\n",
       " '주는': 289,\n",
       " '정책': 290,\n",
       " '다른': 291,\n",
       " '6': 292,\n",
       " '알': 293,\n",
       " '내': 294,\n",
       " '교수': 295,\n",
       " '활용하여': 296,\n",
       " '최근': 297,\n",
       " '시사점을': 298,\n",
       " '마지막으로': 299,\n",
       " '그러나': 300,\n",
       " '수업': 301,\n",
       " '자기효능감': 302,\n",
       " '높을수록': 303,\n",
       " '활동': 304,\n",
       " '온라인': 305,\n",
       " '있어서': 306,\n",
       " '높게': 307,\n",
       " '반면': 308,\n",
       " '환경': 309,\n",
       " '빅데이터': 310,\n",
       " '함으로써': 311,\n",
       " '있을': 312,\n",
       " '낮은': 313,\n",
       " '지지': 314,\n",
       " '정신건강': 315,\n",
       " '분석결과': 316,\n",
       " '전체': 317,\n",
       " '넷째': 318,\n",
       " '안녕감': 319,\n",
       " '의사소통': 320,\n",
       " '필요하다': 321,\n",
       " '현재': 322,\n",
       " '특성': 323,\n",
       " '매우': 324,\n",
       " '과의': 325,\n",
       " '관리': 326,\n",
       " '만족에': 327,\n",
       " '목적이': 328,\n",
       " '가정': 329,\n",
       " '등을': 330,\n",
       " '형성': 331,\n",
       " '조절': 332,\n",
       " '기업': 333,\n",
       " '관련된': 334,\n",
       " '하지': 335,\n",
       " '부모의': 336,\n",
       " '있도록': 337,\n",
       " '파악': 338,\n",
       " '필요가': 339,\n",
       " '않았다': 340,\n",
       " '접근': 341,\n",
       " '핵심': 342,\n",
       " '나': 343,\n",
       " '데이터': 344,\n",
       " '신뢰': 345,\n",
       " '많이': 346,\n",
       " '유형': 347,\n",
       " '연구결과는': 348,\n",
       " '특성을': 349,\n",
       " '효과가': 350,\n",
       " '이나': 351,\n",
       " '평균': 352,\n",
       " '성별': 353,\n",
       " '정서적': 354,\n",
       " '어떻게': 355,\n",
       " '있다는': 356,\n",
       " '자녀': 357,\n",
       " '간호': 358,\n",
       " '지각된': 359,\n",
       " '사용하여': 360,\n",
       " '과정에서': 361,\n",
       " '노인의': 362,\n",
       " '이상': 363,\n",
       " '볼': 364,\n",
       " '001': 365,\n",
       " '요인은': 366,\n",
       " '하며': 367,\n",
       " '운영': 368,\n",
       " '취업': 369,\n",
       " '프로그램의': 370,\n",
       " '스마트폰': 371,\n",
       " '개선': 372,\n",
       " '이해': 373,\n",
       " '수준': 374,\n",
       " '이고': 375,\n",
       " '성과': 376,\n",
       " '품질': 377,\n",
       " '발전': 378,\n",
       " '것은': 379,\n",
       " '수준이': 380,\n",
       " '만': 381,\n",
       " '중국의': 382,\n",
       " '고려': 383,\n",
       " '예측': 384,\n",
       " '자료는': 385,\n",
       " '수집된': 386,\n",
       " '설명': 387,\n",
       " '점': 388,\n",
       " '과정을': 389,\n",
       " '자살': 390,\n",
       " '모바일': 391,\n",
       " '경제적': 392,\n",
       " '기초': 393,\n",
       " '각각': 394,\n",
       " '가치': 395,\n",
       " '통합': 396,\n",
       " '생각': 397,\n",
       " '요인으로': 398,\n",
       " '태도': 399,\n",
       " '변화를': 400,\n",
       " '시사': 401,\n",
       " '규명': 402,\n",
       " '능력': 403,\n",
       " '유의하게': 404,\n",
       " '초기': 405,\n",
       " '와의': 406,\n",
       " '살펴보았다': 407,\n",
       " '자살생각': 408,\n",
       " '장애': 409,\n",
       " '만족도가': 410,\n",
       " '만족도를': 411,\n",
       " '전략': 412,\n",
       " '대상': 413,\n",
       " '없는': 414,\n",
       " '증진': 415,\n",
       " '존재': 416,\n",
       " '브랜드': 417,\n",
       " '연구에서': 418,\n",
       " '통계': 419,\n",
       " '성인': 420,\n",
       " '모형을': 421,\n",
       " '이와': 422,\n",
       " '미래': 423,\n",
       " '감정': 424,\n",
       " '이론적': 425,\n",
       " '않은': 426,\n",
       " '대하여': 427,\n",
       " '관광': 428,\n",
       " '중재': 429,\n",
       " '자신의': 430,\n",
       " '모든': 431,\n",
       " '시': 432,\n",
       " '통제': 433,\n",
       " '근거': 434,\n",
       " '경제': 435,\n",
       " '미치고': 436,\n",
       " '수용': 437,\n",
       " '사용자': 438,\n",
       " '실제': 439,\n",
       " '이들': 440,\n",
       " '선행연구': 441,\n",
       " '목적': 442,\n",
       " '포함': 443,\n",
       " '목적으로': 444,\n",
       " '독립': 445,\n",
       " '적응': 446,\n",
       " '소비자': 447,\n",
       " '학생들의': 448,\n",
       " '점에서': 449,\n",
       " '인간': 450,\n",
       " '사': 451,\n",
       " '중심': 452,\n",
       " '자아탄력성': 453,\n",
       " '아동': 454,\n",
       " '시키는': 455,\n",
       " '영향력을': 456,\n",
       " '되었으며': 457,\n",
       " '경험이': 458,\n",
       " '요인이': 459,\n",
       " '우리나라': 460,\n",
       " '이상의': 461,\n",
       " '이며': 462,\n",
       " '라는': 463,\n",
       " '되어야': 464,\n",
       " '않는': 465,\n",
       " '만족과': 466,\n",
       " '시킬': 467,\n",
       " '상담': 468,\n",
       " '현실': 469,\n",
       " '표현': 470,\n",
       " '전': 471,\n",
       " '확대': 472,\n",
       " '우리': 473,\n",
       " '시도': 474,\n",
       " '서울': 475,\n",
       " '미쳤다': 476,\n",
       " '주': 477,\n",
       " '최종': 478,\n",
       " '일': 479,\n",
       " '판단': 480,\n",
       " '운동': 481,\n",
       " '어떤': 482,\n",
       " '중학생': 483,\n",
       " '방법을': 484,\n",
       " '하면서': 485,\n",
       " '관계가': 486,\n",
       " '설문': 487,\n",
       " '검토': 488,\n",
       " '기반': 489,\n",
       " '일본': 490,\n",
       " '목적을': 491,\n",
       " '체험': 492,\n",
       " '발생': 493,\n",
       " '또래': 494,\n",
       " '활용한': 495,\n",
       " '개입': 496,\n",
       " '표본': 497,\n",
       " '신뢰도': 498,\n",
       " '이라는': 499,\n",
       " '실천': 500,\n",
       " '내용': 501,\n",
       " '남녀': 502,\n",
       " '역량': 503,\n",
       " '국제': 504,\n",
       " '발견': 505,\n",
       " '때문에': 506,\n",
       " '선정': 507,\n",
       " '크게': 508,\n",
       " '방향을': 509,\n",
       " '척도를': 510,\n",
       " '소재': 511,\n",
       " '의의': 512,\n",
       " '북한': 513,\n",
       " '사전': 514,\n",
       " '의의가': 515,\n",
       " '교육의': 516,\n",
       " '하지만': 517,\n",
       " '마련': 518,\n",
       " '나타난': 519,\n",
       " '미국': 520,\n",
       " '예방': 521,\n",
       " '등이': 522,\n",
       " '인공지능': 523,\n",
       " '전공': 524,\n",
       " '만족도와': 525,\n",
       " '순으로': 526,\n",
       " '여가': 527,\n",
       " '성격': 528,\n",
       " '변인': 529,\n",
       " '지역사회': 530,\n",
       " '높았다': 531,\n",
       " '경험을': 532,\n",
       " '전문': 533,\n",
       " '요구': 534,\n",
       " '세계': 535,\n",
       " '20': 536,\n",
       " '필요한': 537,\n",
       " '에서의': 538,\n",
       " '요': 539,\n",
       " '측면에서': 540,\n",
       " '디자인': 541,\n",
       " '결정': 542,\n",
       " '설문지를': 543,\n",
       " '사례': 544,\n",
       " '문화적': 545,\n",
       " '문제를': 546,\n",
       " '상관관계를': 547,\n",
       " '연령': 548,\n",
       " '파악하고': 549,\n",
       " '게': 550,\n",
       " '의해': 551,\n",
       " '만족도는': 552,\n",
       " '력': 553,\n",
       " '19': 554,\n",
       " '연구대상은': 555,\n",
       " '중인': 556,\n",
       " '업무': 557,\n",
       " '학교폭력': 558,\n",
       " '나타났고': 559,\n",
       " '효과적인': 560,\n",
       " '선택': 561,\n",
       " '중독': 562,\n",
       " '애착': 563,\n",
       " '조절효과를': 564,\n",
       " '부분': 565,\n",
       " '제한점': 566,\n",
       " '또는': 567,\n",
       " '중학교': 568,\n",
       " '검사': 569,\n",
       " '남학생': 570,\n",
       " '군': 571,\n",
       " '잠재': 572,\n",
       " '기업의': 573,\n",
       " '상호': 574,\n",
       " '동시에': 575,\n",
       " '분류': 576,\n",
       " '뿐': 577,\n",
       " '모색': 578,\n",
       " '간호대학생의': 579,\n",
       " '산업': 580,\n",
       " '연구에': 581,\n",
       " '인지적': 582,\n",
       " '기존': 583,\n",
       " '시작': 584,\n",
       " '장애인': 585,\n",
       " '나타나': 586,\n",
       " '에도': 587,\n",
       " '응답': 588,\n",
       " '상': 589,\n",
       " '단계': 590,\n",
       " '역할': 591,\n",
       " '실험집단': 592,\n",
       " '10': 593,\n",
       " '구조방정식': 594,\n",
       " '내적': 595,\n",
       " '강화': 596,\n",
       " '부의': 597,\n",
       " '여러': 598,\n",
       " '정책적': 599,\n",
       " '회귀분석을': 600,\n",
       " '자아': 601,\n",
       " '자기효능감과': 602,\n",
       " '분석에': 603,\n",
       " '기존의': 604,\n",
       " '시행': 605,\n",
       " '문항': 606,\n",
       " '향상을': 607,\n",
       " '먼저': 608,\n",
       " '확인할': 609,\n",
       " '하위요인': 610,\n",
       " '게임': 611,\n",
       " '고등학교': 612,\n",
       " '지만': 613,\n",
       " '구조': 614,\n",
       " '한다는': 615,\n",
       " '사후': 616,\n",
       " '융합': 617,\n",
       " '관점에서': 618,\n",
       " '초등학교': 619,\n",
       " '인해': 620,\n",
       " '광고': 621,\n",
       " '시키기': 622,\n",
       " '특성에': 623,\n",
       " '데이터를': 624,\n",
       " '하게': 625,\n",
       " '관계에': 626,\n",
       " '유지': 627,\n",
       " '점을': 628,\n",
       " '창업': 629,\n",
       " '구매': 630,\n",
       " '설정': 631,\n",
       " '공감': 632,\n",
       " '필요성': 633,\n",
       " '공격성': 634,\n",
       " '재학': 635,\n",
       " '모형': 636,\n",
       " '영향이': 637,\n",
       " '시사점': 638,\n",
       " '동안': 639,\n",
       " '빈도': 640,\n",
       " '알아보기': 641,\n",
       " '7': 642,\n",
       " '부를': 643,\n",
       " '내용을': 644,\n",
       " '글쓰기': 645,\n",
       " '네트워크': 646,\n",
       " '분석하여': 647,\n",
       " '기반으로': 648,\n",
       " '편의': 649,\n",
       " '의미를': 650,\n",
       " '수준을': 651,\n",
       " '신체': 652,\n",
       " '지식': 653,\n",
       " '있고': 654,\n",
       " '콘텐츠': 655,\n",
       " '방법': 656,\n",
       " '매개효과': 657,\n",
       " '실시하여': 658,\n",
       " '검증을': 659,\n",
       " '피해': 660,\n",
       " '우울의': 661,\n",
       " '있었으며': 662,\n",
       " '공공': 663,\n",
       " '8': 664,\n",
       " '해결': 665,\n",
       " '비행': 666,\n",
       " '산업혁명': 667,\n",
       " '기': 668,\n",
       " '구축': 669,\n",
       " '실천적': 670,\n",
       " '몰입': 671,\n",
       " '영향력': 672,\n",
       " '상관관계': 673,\n",
       " '더욱': 674,\n",
       " '화된': 675,\n",
       " '알아보고자': 676,\n",
       " '속에서': 677,\n",
       " '예비': 678,\n",
       " '대처': 679,\n",
       " '행복감': 680,\n",
       " '추후': 681,\n",
       " '조절효과': 682,\n",
       " '마케팅': 683,\n",
       " '상황': 684,\n",
       " '교사의': 685,\n",
       " '인한': 686,\n",
       " '한편': 687,\n",
       " '강조': 688,\n",
       " '청소년들의': 689,\n",
       " '동기': 690,\n",
       " '별': 691,\n",
       " '과정': 692,\n",
       " '노력': 693,\n",
       " '이직의도에': 694,\n",
       " '보호': 695,\n",
       " '못하': 696,\n",
       " '거주': 697,\n",
       " '정보를': 698,\n",
       " '질': 699,\n",
       " '발달': 700,\n",
       " '외상': 701,\n",
       " '통제집단': 702,\n",
       " '아동의': 703,\n",
       " '개념': 704,\n",
       " '여학생': 705,\n",
       " '더불어': 706,\n",
       " '개인적': 707,\n",
       " '논문은': 708,\n",
       " '측면': 709,\n",
       " '임파워먼트': 710,\n",
       " '작용': 711,\n",
       " '있었': 712,\n",
       " '프로그램이': 713,\n",
       " '반응': 714,\n",
       " '12': 715,\n",
       " '심리': 716,\n",
       " '가능성이': 717,\n",
       " '개별': 718,\n",
       " '구조적': 719,\n",
       " '유의미하게': 720,\n",
       " '학습자': 721,\n",
       " '전략을': 722,\n",
       " '매개효과가': 723,\n",
       " '기대': 724,\n",
       " '상관': 725,\n",
       " '어머니': 726,\n",
       " '살펴보고': 727,\n",
       " '다중회귀분석': 728,\n",
       " '상관관계가': 729,\n",
       " '정치': 730,\n",
       " '성과에': 731,\n",
       " '차이': 732,\n",
       " '회복탄력성': 733,\n",
       " '제언': 734,\n",
       " '영역': 735,\n",
       " '시간': 736,\n",
       " '되었고': 737,\n",
       " '개인의': 738,\n",
       " '언어': 739,\n",
       " '차년도': 740,\n",
       " '명이': 741,\n",
       " '때문': 742,\n",
       " '스포츠': 743,\n",
       " '제언을': 744,\n",
       " '치료': 745,\n",
       " '위험': 746,\n",
       " '고찰': 747,\n",
       " '특징': 748,\n",
       " '도움이': 749,\n",
       " '간에': 750,\n",
       " '상태': 751,\n",
       " '창의성': 752,\n",
       " '연구방법': 753,\n",
       " '대응': 754,\n",
       " '상대적으로': 755,\n",
       " '제외한': 756,\n",
       " '지속': 757,\n",
       " '인분석': 758,\n",
       " '지도': 759,\n",
       " '높이기': 760,\n",
       " '종교': 761,\n",
       " '근무': 762,\n",
       " '다문화가정': 763,\n",
       " '구분': 764,\n",
       " '대학의': 765,\n",
       " '보다는': 766,\n",
       " '였다': 767,\n",
       " '친구': 768,\n",
       " '어머니의': 769,\n",
       " '추구': 770,\n",
       " '전환': 771,\n",
       " '방문': 772,\n",
       " '이직의도': 773,\n",
       " '호텔': 774,\n",
       " '가진': 775,\n",
       " '행복': 776,\n",
       " '어려움': 777,\n",
       " '목표': 778,\n",
       " '나아가': 779,\n",
       " '대상자의': 780,\n",
       " '전국': 781,\n",
       " '중에서': 782,\n",
       " '대학생들의': 783,\n",
       " '프로그램은': 784,\n",
       " '이미지': 785,\n",
       " '시스템': 786,\n",
       " '속': 787,\n",
       " '잘': 788,\n",
       " '도시': 789,\n",
       " '가능성을': 790,\n",
       " '양적': 791,\n",
       " '가설': 792,\n",
       " '실시하였': 793,\n",
       " '적응에': 794,\n",
       " '맥락': 795,\n",
       " '같이': 796,\n",
       " '스트레스와': 797,\n",
       " '주의': 798,\n",
       " '활성화': 799,\n",
       " '자기효능감이': 800,\n",
       " '사고': 801,\n",
       " '주목': 802,\n",
       " '것': 803,\n",
       " '등에': 804,\n",
       " '디지털': 805,\n",
       " '상관이': 806,\n",
       " '살펴보고자': 807,\n",
       " '달성': 808,\n",
       " '소통': 809,\n",
       " '차별': 810,\n",
       " '해당': 811,\n",
       " '의한': 812,\n",
       " '연계': 813,\n",
       " '종합': 814,\n",
       " '학업적': 815,\n",
       " '기능': 816,\n",
       " '역사': 817,\n",
       " '프로그램에': 818,\n",
       " '탐색적': 819,\n",
       " '사이버': 820,\n",
       " '기본': 821,\n",
       " '군집': 822,\n",
       " '이들의': 823,\n",
       " '추출': 824,\n",
       " '감정노동': 825,\n",
       " '협력': 826,\n",
       " '자존감': 827,\n",
       " '주로': 828,\n",
       " '소재한': 829,\n",
       " '신체적': 830,\n",
       " '지속적인': 831,\n",
       " '계획': 832,\n",
       " '리더십': 833,\n",
       " '면': 834,\n",
       " '욕구': 835,\n",
       " '제공하는': 836,\n",
       " '가치를': 837,\n",
       " '기초자료': 838,\n",
       " '있다고': 839,\n",
       " '변화에': 840,\n",
       " '어': 841,\n",
       " '고등학생': 842,\n",
       " '전통': 843,\n",
       " '교육과정': 844,\n",
       " '코로나': 845,\n",
       " '효능감': 846,\n",
       " '만족을': 847,\n",
       " '참여한': 848,\n",
       " '학업성취도': 849,\n",
       " '제시하': 850,\n",
       " '요소': 851,\n",
       " '주제': 852,\n",
       " '복지': 853,\n",
       " '되지': 854,\n",
       " '상관을': 855,\n",
       " '창의적': 856,\n",
       " '성장': 857,\n",
       " '교육을': 858,\n",
       " '도입': 859,\n",
       " '보고': 860,\n",
       " '활동을': 861,\n",
       " '세기': 862,\n",
       " '시설': 863,\n",
       " '완화': 864,\n",
       " '함의를': 865,\n",
       " '조사를': 866,\n",
       " '남자': 867,\n",
       " '여자': 868,\n",
       " '경로': 869,\n",
       " '지속적으로': 870,\n",
       " '극복': 871,\n",
       " '성취': 872,\n",
       " '생산': 873,\n",
       " '구체적으로': 874,\n",
       " '집단에': 875,\n",
       " '집중': 876,\n",
       " '가운데': 877,\n",
       " '우울증': 878,\n",
       " '사람': 879,\n",
       " '분석과': 880,\n",
       " '시기': 881,\n",
       " '공간': 882,\n",
       " '배경': 883,\n",
       " '설문을': 884,\n",
       " '개인정보': 885,\n",
       " '청소년이': 886,\n",
       " '예술': 887,\n",
       " '커뮤니케이션': 888,\n",
       " '분석하는': 889,\n",
       " '희망': 890,\n",
       " '한류': 891,\n",
       " '뿐만': 892,\n",
       " '살펴본': 893,\n",
       " '갖는': 894,\n",
       " '정도': 895,\n",
       " '중심의': 896,\n",
       " '불구하고': 897,\n",
       " '갈등': 898,\n",
       " '학습자의': 899,\n",
       " '위계적': 900,\n",
       " '지역의': 901,\n",
       " '실행': 902,\n",
       " '실험': 903,\n",
       " '대학생활적응': 904,\n",
       " '있는지를': 905,\n",
       " '회피': 906,\n",
       " '적합한': 907,\n",
       " '상관분석': 908,\n",
       " '외국인': 909,\n",
       " '분석은': 910,\n",
       " '역시': 911,\n",
       " '검정': 912,\n",
       " '인식을': 913,\n",
       " '가능한': 914,\n",
       " '전문가': 915,\n",
       " '서비스를': 916,\n",
       " '자기효능감은': 917,\n",
       " '수준에': 918,\n",
       " '결론': 919,\n",
       " '남성': 920,\n",
       " '경기': 921,\n",
       " '2016년': 922,\n",
       " '죽음': 923,\n",
       " '연구들': 924,\n",
       " '과제': 925,\n",
       " '적용하여': 926,\n",
       " '가지는': 927,\n",
       " '영향력이': 928,\n",
       " '상황에서': 929,\n",
       " '요인에': 930,\n",
       " '관심': 931,\n",
       " '스트레스가': 932,\n",
       " '마음챙김': 933,\n",
       " '분야': 934,\n",
       " '관계는': 935,\n",
       " '결과에': 936,\n",
       " '인식과': 937,\n",
       " '보이': 938,\n",
       " '부적응': 939,\n",
       " '그들의': 940,\n",
       " '동아시아': 941,\n",
       " '범주': 942,\n",
       " '여성의': 943,\n",
       " '정서조절': 944,\n",
       " '타인': 945,\n",
       " '학생의': 946,\n",
       " '몰입에': 947,\n",
       " '선행': 948,\n",
       " '이용자': 949,\n",
       " '설계': 950,\n",
       " '공유': 951,\n",
       " '유아': 952,\n",
       " '지지와': 953,\n",
       " '구': 954,\n",
       " '제품': 955,\n",
       " '체육': 956,\n",
       " '실무적': 957,\n",
       " '제시하고자': 958,\n",
       " '연구자': 959,\n",
       " '처리': 960,\n",
       " '의도에': 961,\n",
       " '미칠': 962,\n",
       " '보인다': 963,\n",
       " '긍정': 964,\n",
       " '교육적': 965,\n",
       " '이야기': 966,\n",
       " '살펴보면': 967,\n",
       " '경험과': 968,\n",
       " '텍스트': 969,\n",
       " '정도가': 970,\n",
       " '으로는': 971,\n",
       " '요인과': 972,\n",
       " '유형에': 973,\n",
       " '자료로': 974,\n",
       " '변수': 975,\n",
       " '스마트': 976,\n",
       " '감성': 977,\n",
       " '스스로': 978,\n",
       " '집단이': 979,\n",
       " '정부': 980,\n",
       " '확장': 981,\n",
       " '인성': 982,\n",
       " '명으로': 983,\n",
       " '9': 984,\n",
       " '함을': 985,\n",
       " '추진': 986,\n",
       " '으로서': 987,\n",
       " '성별에': 988,\n",
       " '아닌': 989,\n",
       " '해외': 990,\n",
       " '과학': 991,\n",
       " '관련하여': 992,\n",
       " '자기효능감에': 993,\n",
       " '전문성': 994,\n",
       " '회복': 995,\n",
       " '특성과': 996,\n",
       " '차원에서': 997,\n",
       " '대학생을': 998,\n",
       " '확보': 999,\n",
       " '만족이': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 43358 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt_all_random_262.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1ac9e668fc8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2798 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "2798/2798 [==============================] - 80s 29ms/step - loss: 4.9673 - val_loss: 5.3480\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_extra_all_v1_01_5.34797.h5\n",
      "Epoch 2/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 3.4298 - val_loss: 4.6042\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_extra_all_v1_02_4.60421.h5\n",
      "Epoch 3/30\n",
      "2798/2798 [==============================] - 78s 28ms/step - loss: 3.0920 - val_loss: 3.9109\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_extra_all_v1_03_3.91093.h5\n",
      "Epoch 4/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 2.9110 - val_loss: 3.2438\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_extra_all_v1_04_3.24383.h5\n",
      "Epoch 5/30\n",
      "2798/2798 [==============================] - 78s 28ms/step - loss: 2.5630 - val_loss: 3.0563\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_extra_all_v1_05_3.05628.h5\n",
      "Epoch 6/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 2.3769 - val_loss: 3.4214\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_extra_all_v1_06_3.42141.h5\n",
      "Epoch 7/30\n",
      "2798/2798 [==============================] - 78s 28ms/step - loss: 2.1406 - val_loss: 3.4708\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_extra_all_v1_07_3.47083.h5\n",
      "Epoch 8/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 1.9913 - val_loss: 3.2871\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_extra_all_v1_08_3.28706.h5\n",
      "Epoch 9/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 1.7297 - val_loss: 2.9797\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_extra_all_v1_09_2.97973.h5\n",
      "Epoch 10/30\n",
      "2798/2798 [==============================] - 80s 29ms/step - loss: 1.6057 - val_loss: 3.5778\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_extra_all_v1_10_3.57778.h5\n",
      "Epoch 11/30\n",
      "2798/2798 [==============================] - 80s 28ms/step - loss: 1.4510 - val_loss: 3.1091\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_extra_all_v1_11_3.10913.h5\n",
      "Epoch 12/30\n",
      "2798/2798 [==============================] - 82s 29ms/step - loss: 1.3822 - val_loss: 3.1743\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_rae_extra_all_v1_12_3.17425.h5\n",
      "Epoch 13/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 1.2483 - val_loss: 3.1311\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_rae_extra_all_v1_13_3.13110.h5\n",
      "Epoch 14/30\n",
      "2798/2798 [==============================] - 79s 28ms/step - loss: 1.1837 - val_loss: 3.4490\n",
      "\n",
      "Epoch 00014: saving model to ./save_models/han_rae_extra_all_v1_14_3.44903.h5\n",
      "time : 1114.0699155330658\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(4)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_extra_all_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4577300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 4,924,854\n",
      "Trainable params: 588,554\n",
      "Non-trainable params: 4,336,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_extra_all_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_extra_all_v1_05_3.05628.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.258111416526107"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7816027, 2.5492995, 1.5522138, 2.6010995],\n",
       "       [3.0968177, 2.1838427, 0.7466641, 1.3214926],\n",
       "       [1.1799656, 2.9124303, 0.6083981, 4.650003 ],\n",
       "       ...,\n",
       "       [2.253261 , 2.011768 , 0.9982283, 2.7100635],\n",
       "       [6.65671  , 3.041023 , 1.0515697, 2.0739481],\n",
       "       [1.7747947, 1.1410756, 1.5019931, 2.6474884]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_extra_all_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.51071605e-05, 8.91991484e-04, 1.10260182e-04, ...,\n",
       "        6.01605780e-06, 6.08901064e-05, 3.22918058e-05],\n",
       "       [3.36943355e-11, 2.77524872e-04, 2.15635650e-04, ...,\n",
       "        5.68612677e-08, 4.98048787e-04, 1.25992738e-04],\n",
       "       [4.39740215e-12, 2.07408375e-05, 4.22686851e-03, ...,\n",
       "        4.36060219e-08, 6.78132679e-08, 2.54913088e-04],\n",
       "       ...,\n",
       "       [1.24244925e-08, 1.18170900e-03, 2.89910249e-02, ...,\n",
       "        5.67765710e-06, 1.05130137e-03, 6.15958264e-03],\n",
       "       [1.96158564e-20, 1.31077177e-05, 9.78866865e-07, ...,\n",
       "        3.13731788e-14, 1.25928636e-05, 4.64348477e-06],\n",
       "       [2.14344453e-09, 6.65471365e-04, 4.18450101e-04, ...,\n",
       "        5.94127050e-04, 1.43436645e-03, 4.09681769e-03]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>가족건강성</th>\n",
       "      <th>간호</th>\n",
       "      <th>간호대학생</th>\n",
       "      <th>간호사</th>\n",
       "      <th>감정</th>\n",
       "      <th>감정노동</th>\n",
       "      <th>개인정보</th>\n",
       "      <th>개인정보보호</th>\n",
       "      <th>개인정보보호법</th>\n",
       "      <th>...</th>\n",
       "      <th>한류</th>\n",
       "      <th>한반도</th>\n",
       "      <th>한중</th>\n",
       "      <th>해외직접투자</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>행복감</th>\n",
       "      <th>현상학</th>\n",
       "      <th>확인적요인분석</th>\n",
       "      <th>회복탄력성</th>\n",
       "      <th>희망</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4차산업혁명  가족건강성  간호  간호대학생  간호사  감정  감정노동  개인정보  개인정보보호  개인정보보호법  ...  한류  \\\n",
       "0         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "1         0      0   0      0    1   0     0     0       0        0  ...   0   \n",
       "2         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "3         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "4         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "..      ...    ...  ..    ...  ...  ..   ...   ...     ...      ...  ...  ..   \n",
       "927       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "928       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "929       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "930       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "931       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "\n",
       "     한반도  한중  해외직접투자  핵심역량  행복감  현상학  확인적요인분석  회복탄력성  희망  \n",
       "0      0   0       0     0    0    0        0      0   0  \n",
       "1      0   0       0     0    0    0        0      0   0  \n",
       "2      0   0       0     0    0    0        0      0   0  \n",
       "3      0   0       0     0    0    0        0      0   0  \n",
       "4      0   0       0     0    0    0        0      0   0  \n",
       "..   ...  ..     ...   ...  ...  ...      ...    ...  ..  \n",
       "927    0   0       0     0    0    0        0      0   0  \n",
       "928    0   0       0     0    0    0        0      0   0  \n",
       "929    0   0       0     0    0    0        0      0   0  \n",
       "930    0   0       0     0    0    0        0      0   0  \n",
       "931    0   0       0     0    0    0        0      0   0  \n",
       "\n",
       "[932 rows x 262 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/all_10_random_12000_262_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(932, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.019313304721030045\n",
      "precision :  0.41317365269461076\n",
      "recall :  0.05211480362537765\n",
      "f1 :  0.09255533199195172\n",
      "------------------------\n",
      "hamming_loss :  0.005540903580906202\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.019313304721030045\n",
      "precision :  0.0609799713876967\n",
      "recall :  0.04729971387696709\n",
      "f1 :  0.049535050071530765\n",
      "------------------------\n",
      "hamming_loss :  0.005540903580906202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ccf08da81ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wrong example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m attention_extractor = Model(inputs=[document_input],\n\u001b[0m\u001b[0;32m      3\u001b[0m                             outputs=[word_attention, sentence_attention])\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_input' is not defined"
     ]
    }
   ],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
