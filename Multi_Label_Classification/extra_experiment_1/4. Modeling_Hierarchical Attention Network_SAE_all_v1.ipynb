{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1174682535234831002\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7914521896755693566\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10915451165455599950\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3688995745168609103\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/sae_extra_all_v1_train.xlsx')\n",
    "val = pd.read_excel('./data/sae_extra_all_v1_val.xlsx')\n",
    "test = pd.read_excel('./data/sae_extra_all_v1_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...</td>\n",
       "      <td>1.011023</td>\n",
       "      <td>7.160912</td>\n",
       "      <td>6.622326</td>\n",
       "      <td>9.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...</td>\n",
       "      <td>0.398849</td>\n",
       "      <td>0.193556</td>\n",
       "      <td>0.301074</td>\n",
       "      <td>0.299468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...</td>\n",
       "      <td>0.356403</td>\n",
       "      <td>0.475692</td>\n",
       "      <td>0.473081</td>\n",
       "      <td>0.594643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...</td>\n",
       "      <td>1.011023</td>\n",
       "      <td>7.160912</td>\n",
       "      <td>6.622326</td>\n",
       "      <td>9.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...</td>\n",
       "      <td>0.491272</td>\n",
       "      <td>0.191371</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.363958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...</td>\n",
       "      <td>0.324759</td>\n",
       "      <td>0.139948</td>\n",
       "      <td>0.149875</td>\n",
       "      <td>0.140516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.660433</td>\n",
       "      <td>4.746373</td>\n",
       "      <td>8.818042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...</td>\n",
       "      <td>0.702314</td>\n",
       "      <td>0.559332</td>\n",
       "      <td>0.949201</td>\n",
       "      <td>0.927431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.660433</td>\n",
       "      <td>4.746373</td>\n",
       "      <td>8.818042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2797</td>\n",
       "      <td>본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...</td>\n",
       "      <td>0.272751</td>\n",
       "      <td>0.144326</td>\n",
       "      <td>0.084223</td>\n",
       "      <td>0.083391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...  1.011023   \n",
       "1              1  최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...  0.398849   \n",
       "2              2  글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...  0.356403   \n",
       "3              3  본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...  1.011023   \n",
       "4              4  본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...  0.491272   \n",
       "...          ...                                                ...       ...   \n",
       "2793        2793  본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...  0.324759   \n",
       "2794        2794  본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...  0.000000   \n",
       "2795        2795  경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...  0.702314   \n",
       "2796        2796  본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...  0.000000   \n",
       "2797        2797  본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...  0.272751   \n",
       "\n",
       "             1         2         3  \n",
       "0     7.160912  6.622326  9.175439  \n",
       "1     0.193556  0.301074  0.299468  \n",
       "2     0.475692  0.473081  0.594643  \n",
       "3     7.160912  6.622326  9.175439  \n",
       "4     0.191371  0.420455  0.363958  \n",
       "...        ...       ...       ...  \n",
       "2793  0.139948  0.149875  0.140516  \n",
       "2794  8.660433  4.746373  8.818042  \n",
       "2795  0.559332  0.949201  0.927431  \n",
       "2796  8.660433  4.746373  8.818042  \n",
       "2797  0.144326  0.084223  0.083391  \n",
       "\n",
       "[2798 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...</td>\n",
       "      <td>0.191378</td>\n",
       "      <td>1.494957</td>\n",
       "      <td>1.056647</td>\n",
       "      <td>1.635439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...</td>\n",
       "      <td>0.307679</td>\n",
       "      <td>0.163603</td>\n",
       "      <td>0.148952</td>\n",
       "      <td>0.165371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...</td>\n",
       "      <td>0.288512</td>\n",
       "      <td>1.619091</td>\n",
       "      <td>1.294337</td>\n",
       "      <td>1.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...</td>\n",
       "      <td>0.231662</td>\n",
       "      <td>1.367847</td>\n",
       "      <td>1.015004</td>\n",
       "      <td>1.516413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...</td>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164077</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...</td>\n",
       "      <td>0.353901</td>\n",
       "      <td>0.120139</td>\n",
       "      <td>0.161553</td>\n",
       "      <td>0.129024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>0.388819</td>\n",
       "      <td>0.205637</td>\n",
       "      <td>0.410261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...</td>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164078</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...</td>\n",
       "      <td>0.674054</td>\n",
       "      <td>1.166847</td>\n",
       "      <td>1.392862</td>\n",
       "      <td>1.591533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...</td>\n",
       "      <td>0.302789</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>0.150385</td>\n",
       "      <td>0.176820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...  0.191378   \n",
       "1             1  기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...  0.307679   \n",
       "2             2  본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...  0.288512   \n",
       "3             3  본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...  0.231662   \n",
       "4             4  오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...  3.151699   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...  0.353901   \n",
       "928         928  본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...  0.228696   \n",
       "929         929  한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...  3.151699   \n",
       "930         930  본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...  0.674054   \n",
       "931         931  본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...  0.302789   \n",
       "\n",
       "            1         2         3  \n",
       "0    1.494957  1.056647  1.635439  \n",
       "1    0.163603  0.148952  0.165371  \n",
       "2    1.619091  1.294337  1.833050  \n",
       "3    1.367847  1.015004  1.516413  \n",
       "4    5.080933  7.164077  7.851844  \n",
       "..        ...       ...       ...  \n",
       "927  0.120139  0.161553  0.129024  \n",
       "928  0.388819  0.205637  0.410261  \n",
       "929  5.080933  7.164078  7.851844  \n",
       "930  1.166847  1.392862  1.591533  \n",
       "931  0.172958  0.150385  0.176820  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...</td>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164077</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...</td>\n",
       "      <td>0.225507</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>0.050496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...</td>\n",
       "      <td>1.115741</td>\n",
       "      <td>0.423660</td>\n",
       "      <td>1.308002</td>\n",
       "      <td>1.069199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...</td>\n",
       "      <td>5.800450</td>\n",
       "      <td>1.824172</td>\n",
       "      <td>7.856041</td>\n",
       "      <td>6.401890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.685583</td>\n",
       "      <td>1.659593</td>\n",
       "      <td>4.400387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...</td>\n",
       "      <td>1.258299</td>\n",
       "      <td>0.119332</td>\n",
       "      <td>1.243242</td>\n",
       "      <td>0.960823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...</td>\n",
       "      <td>1.188053</td>\n",
       "      <td>1.388057</td>\n",
       "      <td>2.141846</td>\n",
       "      <td>2.207722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...</td>\n",
       "      <td>0.210070</td>\n",
       "      <td>0.408748</td>\n",
       "      <td>0.194105</td>\n",
       "      <td>0.421474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...</td>\n",
       "      <td>1.397555</td>\n",
       "      <td>1.095187</td>\n",
       "      <td>2.152793</td>\n",
       "      <td>2.025491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...</td>\n",
       "      <td>0.415396</td>\n",
       "      <td>0.208450</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.330488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...  3.151699   \n",
       "1             1  본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...  0.225507   \n",
       "2             2  중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...  1.115741   \n",
       "3             3  본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...  5.800450   \n",
       "4             4  본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...  0.000000   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...  1.258299   \n",
       "928         928  최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...  1.188053   \n",
       "929         929  본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...  0.210070   \n",
       "930         930  본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...  1.397555   \n",
       "931         931  2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...  0.415396   \n",
       "\n",
       "            1         2         3  \n",
       "0    5.080933  7.164077  7.851844  \n",
       "1    0.161213  0.030526  0.050496  \n",
       "2    0.423660  1.308002  1.069199  \n",
       "3    1.824172  7.856041  6.401890  \n",
       "4    4.685583  1.659593  4.400387  \n",
       "..        ...       ...       ...  \n",
       "927  0.119332  1.243242  0.960823  \n",
       "928  1.388057  2.141846  2.207722  \n",
       "929  0.408748  0.194105  0.421474  \n",
       "930  1.095187  2.152793  2.025491  \n",
       "931  0.208450  0.344538  0.330488  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...\n",
       "1       최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...\n",
       "2       글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...\n",
       "3       본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...\n",
       "4       본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...\n",
       "                              ...                        \n",
       "2793    본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...\n",
       "2794    본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...\n",
       "2795    경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...\n",
       "2796    본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...\n",
       "2797    본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...\n",
       "Name: abstract, Length: 2798, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.011023</td>\n",
       "      <td>7.160912</td>\n",
       "      <td>6.622326</td>\n",
       "      <td>9.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.398849</td>\n",
       "      <td>0.193556</td>\n",
       "      <td>0.301074</td>\n",
       "      <td>0.299468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356403</td>\n",
       "      <td>0.475692</td>\n",
       "      <td>0.473081</td>\n",
       "      <td>0.594643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.011023</td>\n",
       "      <td>7.160912</td>\n",
       "      <td>6.622326</td>\n",
       "      <td>9.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.491272</td>\n",
       "      <td>0.191371</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.363958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>0.324759</td>\n",
       "      <td>0.139948</td>\n",
       "      <td>0.149875</td>\n",
       "      <td>0.140516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.660433</td>\n",
       "      <td>4.746373</td>\n",
       "      <td>8.818042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>0.702314</td>\n",
       "      <td>0.559332</td>\n",
       "      <td>0.949201</td>\n",
       "      <td>0.927431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.660433</td>\n",
       "      <td>4.746373</td>\n",
       "      <td>8.818042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>0.272751</td>\n",
       "      <td>0.144326</td>\n",
       "      <td>0.084223</td>\n",
       "      <td>0.083391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     1.011023  7.160912  6.622326  9.175439\n",
       "1     0.398849  0.193556  0.301074  0.299468\n",
       "2     0.356403  0.475692  0.473081  0.594643\n",
       "3     1.011023  7.160912  6.622326  9.175439\n",
       "4     0.491272  0.191371  0.420455  0.363958\n",
       "...        ...       ...       ...       ...\n",
       "2793  0.324759  0.139948  0.149875  0.140516\n",
       "2794  0.000000  8.660433  4.746373  8.818042\n",
       "2795  0.702314  0.559332  0.949201  0.927431\n",
       "2796  0.000000  8.660433  4.746373  8.818042\n",
       "2797  0.272751  0.144326  0.084223  0.083391\n",
       "\n",
       "[2798 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...\n",
       "1      기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...\n",
       "2      본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...\n",
       "3      본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...\n",
       "4      오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...\n",
       "                             ...                        \n",
       "927    본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...\n",
       "928    본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...\n",
       "929    한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...\n",
       "930    본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...\n",
       "931    본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191378</td>\n",
       "      <td>1.494957</td>\n",
       "      <td>1.056647</td>\n",
       "      <td>1.635439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307679</td>\n",
       "      <td>0.163603</td>\n",
       "      <td>0.148952</td>\n",
       "      <td>0.165371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288512</td>\n",
       "      <td>1.619091</td>\n",
       "      <td>1.294337</td>\n",
       "      <td>1.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231662</td>\n",
       "      <td>1.367847</td>\n",
       "      <td>1.015004</td>\n",
       "      <td>1.516413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164077</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.353901</td>\n",
       "      <td>0.120139</td>\n",
       "      <td>0.161553</td>\n",
       "      <td>0.129024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.228696</td>\n",
       "      <td>0.388819</td>\n",
       "      <td>0.205637</td>\n",
       "      <td>0.410261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164078</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.674054</td>\n",
       "      <td>1.166847</td>\n",
       "      <td>1.392862</td>\n",
       "      <td>1.591533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.302789</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>0.150385</td>\n",
       "      <td>0.176820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    0.191378  1.494957  1.056647  1.635439\n",
       "1    0.307679  0.163603  0.148952  0.165371\n",
       "2    0.288512  1.619091  1.294337  1.833050\n",
       "3    0.231662  1.367847  1.015004  1.516413\n",
       "4    3.151699  5.080933  7.164077  7.851844\n",
       "..        ...       ...       ...       ...\n",
       "927  0.353901  0.120139  0.161553  0.129024\n",
       "928  0.228696  0.388819  0.205637  0.410261\n",
       "929  3.151699  5.080933  7.164078  7.851844\n",
       "930  0.674054  1.166847  1.392862  1.591533\n",
       "931  0.302789  0.172958  0.150385  0.176820\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...\n",
       "1      본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...\n",
       "2      중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...\n",
       "3      본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...\n",
       "4      본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...\n",
       "                             ...                        \n",
       "927    본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...\n",
       "928    최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...\n",
       "929    본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...\n",
       "930    본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...\n",
       "931    2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.151699</td>\n",
       "      <td>5.080933</td>\n",
       "      <td>7.164077</td>\n",
       "      <td>7.851844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225507</td>\n",
       "      <td>0.161213</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>0.050496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.115741</td>\n",
       "      <td>0.423660</td>\n",
       "      <td>1.308002</td>\n",
       "      <td>1.069199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.800450</td>\n",
       "      <td>1.824172</td>\n",
       "      <td>7.856041</td>\n",
       "      <td>6.401890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.685583</td>\n",
       "      <td>1.659593</td>\n",
       "      <td>4.400387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1.258299</td>\n",
       "      <td>0.119332</td>\n",
       "      <td>1.243242</td>\n",
       "      <td>0.960823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>1.188053</td>\n",
       "      <td>1.388057</td>\n",
       "      <td>2.141846</td>\n",
       "      <td>2.207722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0.210070</td>\n",
       "      <td>0.408748</td>\n",
       "      <td>0.194105</td>\n",
       "      <td>0.421474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>1.397555</td>\n",
       "      <td>1.095187</td>\n",
       "      <td>2.152793</td>\n",
       "      <td>2.025491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.415396</td>\n",
       "      <td>0.208450</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.330488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    3.151699  5.080933  7.164077  7.851844\n",
       "1    0.225507  0.161213  0.030526  0.050496\n",
       "2    1.115741  0.423660  1.308002  1.069199\n",
       "3    5.800450  1.824172  7.856041  6.401890\n",
       "4    0.000000  4.685583  1.659593  4.400387\n",
       "..        ...       ...       ...       ...\n",
       "927  1.258299  0.119332  1.243242  0.960823\n",
       "928  1.188053  1.388057  2.141846  2.207722\n",
       "929  0.210070  0.408748  0.194105  0.421474\n",
       "930  1.397555  1.095187  2.152793  2.025491\n",
       "931  0.415396  0.208450  0.344538  0.330488\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2798/2798 [01:17<00:00, 36.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:24<00:00, 37.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:25<00:00, 37.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['본',\n",
       "  '연구는',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련이',\n",
       "  '인지',\n",
       "  '손상',\n",
       "  '이',\n",
       "  '있는',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '및',\n",
       "  '만족감에',\n",
       "  '미치는',\n",
       "  '영향을',\n",
       "  '알고자',\n",
       "  '하였다',\n",
       "  '인천',\n",
       "  '에',\n",
       "  '소재한',\n",
       "  '병원에',\n",
       "  '입원',\n",
       "  '중인',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자',\n",
       "  '들',\n",
       "  '이',\n",
       "  '본',\n",
       "  '연구에',\n",
       "  '참여',\n",
       "  '하였다',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '대상자들은',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '으로',\n",
       "  '7',\n",
       "  '명씩',\n",
       "  '무작위',\n",
       "  '배정',\n",
       "  '되었다',\n",
       "  '두',\n",
       "  '그룹의',\n",
       "  '대상자들은',\n",
       "  '모두',\n",
       "  '전통적인',\n",
       "  '인지',\n",
       "  '치료를',\n",
       "  '4',\n",
       "  '주간',\n",
       "  '주',\n",
       "  '5회',\n",
       "  '1일',\n",
       "  '30분',\n",
       "  '의',\n",
       "  '중재를',\n",
       "  '받았으며',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련을',\n",
       "  '30분',\n",
       "  '씩',\n",
       "  '추가적으로',\n",
       "  '실시',\n",
       "  '하였다',\n",
       "  '평가는',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후에',\n",
       "  '한국판',\n",
       "  '간이',\n",
       "  '정신',\n",
       "  '상태',\n",
       "  '검사',\n",
       "  '한국판',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '시각',\n",
       "  '상사',\n",
       "  '척도를',\n",
       "  '사용하여',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '만족감을',\n",
       "  '측정',\n",
       "  '하였다',\n",
       "  '연구',\n",
       "  '결과',\n",
       "  '두',\n",
       "  '그룹은',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후로',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가와',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '변화',\n",
       "  '량',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '대조군',\n",
       "  '보다',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '만족감',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '은',\n",
       "  '유의한',\n",
       "  '차이가',\n",
       "  '없었다',\n",
       "  '05',\n",
       "  '본',\n",
       "  '연구의',\n",
       "  '결과를',\n",
       "  '통하여',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련은',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '향상에',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '효과를',\n",
       "  '기대할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '중재법',\n",
       "  '으로',\n",
       "  '사료',\n",
       "  '된다'],\n",
       " ['기독교',\n",
       "  '대학은',\n",
       "  '대학생의',\n",
       "  '스트레스',\n",
       "  '상황에서',\n",
       "  '영향을',\n",
       "  '조절',\n",
       "  '하여',\n",
       "  '완충시켜주거나',\n",
       "  '적응을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '잘',\n",
       "  '분석하여',\n",
       "  '그',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '프로그램을',\n",
       "  '개발',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있다',\n",
       "  '그러므로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '자아탄력성',\n",
       "  '과',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '소그룹',\n",
       "  '활동',\n",
       "  '간의',\n",
       "  '관계성',\n",
       "  '을',\n",
       "  '탐구',\n",
       "  '하여',\n",
       "  '대학생의',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '증진을',\n",
       "  '위한',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '역할을',\n",
       "  '모색하',\n",
       "  '는',\n",
       "  '것을',\n",
       "  '목적으로',\n",
       "  '삼는다',\n",
       "  '구체적으로',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '대표적',\n",
       "  '구성요소',\n",
       "  '인',\n",
       "  '낙관성',\n",
       "  '활력성',\n",
       "  '감정',\n",
       "  '통제력',\n",
       "  '그리고',\n",
       "  '대인관계',\n",
       "  '능력을',\n",
       "  '강화',\n",
       "  '시킴에',\n",
       "  '있어서',\n",
       "  '소그룹',\n",
       "  '활동의',\n",
       "  '특성들',\n",
       "  '과',\n",
       "  '어떠한',\n",
       "  '관련',\n",
       "  '이',\n",
       "  '있는지를',\n",
       "  '분석하는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '그리고',\n",
       "  '이러한',\n",
       "  '분석에',\n",
       "  '기초하여',\n",
       "  '기독교',\n",
       "  '대학에서',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '통한',\n",
       "  '영적',\n",
       "  '돌봄',\n",
       "  '이',\n",
       "  '효과',\n",
       "  '적',\n",
       "  '으로',\n",
       "  '이루어질',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '몇',\n",
       "  '가지',\n",
       "  '사례',\n",
       "  '들',\n",
       "  '을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '결론적으로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '소그룹',\n",
       "  '활동이',\n",
       "  '스트레스로',\n",
       "  '부터의',\n",
       "  '회복을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '네',\n",
       "  '기본',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시켜',\n",
       "  '주기',\n",
       "  '때문에',\n",
       "  '기독교',\n",
       "  '대학이',\n",
       "  '보다',\n",
       "  '적극적으로',\n",
       "  '종교',\n",
       "  '교육적',\n",
       "  '인',\n",
       "  '목적의',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '개발',\n",
       "  '시킬',\n",
       "  '것을',\n",
       "  '제안',\n",
       "  '한다'],\n",
       " ['본',\n",
       "  '연구는',\n",
       "  '초등학생의',\n",
       "  '방과후',\n",
       "  '운동',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '정신건강',\n",
       "  '과의',\n",
       "  '관계를',\n",
       "  '탐색',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '수행',\n",
       "  '되었다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '서울시',\n",
       "  '소재의',\n",
       "  '초등학생',\n",
       "  '217',\n",
       "  '명이',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '척도',\n",
       "  '한국',\n",
       "  '정보화',\n",
       "  '진흥원',\n",
       "  '2011',\n",
       "  '와',\n",
       "  '정신건강',\n",
       "  '측정',\n",
       "  '척도',\n",
       "  '김동일',\n",
       "  '안현',\n",
       "  '의',\n",
       "  '2006',\n",
       "  '에',\n",
       "  '응답',\n",
       "  '하였다',\n",
       "  '수집된',\n",
       "  '자료는',\n",
       "  '먼저',\n",
       "  '운동',\n",
       "  '시간이',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '35시간',\n",
       "  '매일운동으로',\n",
       "  '집단을',\n",
       "  '분류하여',\n",
       "  '스마트폰',\n",
       "  '중독과',\n",
       "  '정신건강',\n",
       "  '의',\n",
       "  '차이를',\n",
       "  '분석',\n",
       "  '하였다',\n",
       "  '그',\n",
       "  '결과',\n",
       "  '매일운동',\n",
       "  '집단은',\n",
       "  '주당',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '운동',\n",
       "  '집단에',\n",
       "  '비해',\n",
       "  '일상생활',\n",
       "  '장애',\n",
       "  '금단',\n",
       "  '내성',\n",
       "  '가상세계',\n",
       "  '의',\n",
       "  '점수가',\n",
       "  '모두',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났고',\n",
       "  '정신건강',\n",
       "  '에서',\n",
       "  '우울',\n",
       "  '충동',\n",
       "  '공격성',\n",
       "  '이',\n",
       "  '유의하게',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '경로분석',\n",
       "  '에서',\n",
       "  '운동',\n",
       "  '시간은',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '직접',\n",
       "  '적',\n",
       "  '인',\n",
       "  '효과가',\n",
       "  '있었으며',\n",
       "  '정신건강',\n",
       "  '을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '효과에서',\n",
       "  '는',\n",
       "  '직접효과',\n",
       "  '는',\n",
       "  '없고',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '통한',\n",
       "  '간접효과',\n",
       "  '만이',\n",
       "  '나타났다'],\n",
       " ['본',\n",
       "  '연구의',\n",
       "  '목적은',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여',\n",
       "  '의의',\n",
       "  '를',\n",
       "  '살펴보고',\n",
       "  '학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '간의',\n",
       "  '연계',\n",
       "  '활동을',\n",
       "  '보다',\n",
       "  '활성화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '방안을',\n",
       "  '제시하',\n",
       "  '는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '관련',\n",
       "  '연구',\n",
       "  '문헌을',\n",
       "  '검토',\n",
       "  '하고',\n",
       "  '관계자를',\n",
       "  '인터뷰',\n",
       "  '하고',\n",
       "  '마을교육',\n",
       "  '과',\n",
       "  '방과후학교',\n",
       "  '의',\n",
       "  '강점',\n",
       "  '약점',\n",
       "  '기회',\n",
       "  '위기',\n",
       "  '요인들을',\n",
       "  '분석',\n",
       "  '하고',\n",
       "  '연계',\n",
       "  '활성화를',\n",
       "  '위한',\n",
       "  '방안을',\n",
       "  '제시',\n",
       "  '하였다',\n",
       "  '연구결과',\n",
       "  '방과후학교',\n",
       "  '는',\n",
       "  '학부모',\n",
       "  '의',\n",
       "  '높은',\n",
       "  '만족도',\n",
       "  '사교육비',\n",
       "  '경감',\n",
       "  '등에',\n",
       "  '효과가',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '인식',\n",
       "  '되는',\n",
       "  '등',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '기능을',\n",
       "  '수행하고',\n",
       "  '있으며',\n",
       "  '지역사회',\n",
       "  '와의',\n",
       "  '연계',\n",
       "  '활동',\n",
       "  '강화를',\n",
       "  '중요하게',\n",
       "  '생각',\n",
       "  '하고',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '최근에는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '이',\n",
       "  '서로',\n",
       "  '연계',\n",
       "  '하는',\n",
       "  '사례가',\n",
       "  '나타나고',\n",
       "  '있다',\n",
       "  '이는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '연계',\n",
       "  '를',\n",
       "  '통해',\n",
       "  '학생들이',\n",
       "  '지역사회',\n",
       "  '공동체',\n",
       "  '의식을',\n",
       "  '함양',\n",
       "  '하고',\n",
       "  '지역사회',\n",
       "  '의',\n",
       "  '공동체',\n",
       "  '성',\n",
       "  '을',\n",
       "  '회복하는',\n",
       "  '밑거름',\n",
       "  '이',\n",
       "  '된다는',\n",
       "  '측면에서',\n",
       "  '매우',\n",
       "  '중요한',\n",
       "  '의미를',\n",
       "  '지니고',\n",
       "  '있다',\n",
       "  '이러한',\n",
       "  '연구',\n",
       "  '결과를',\n",
       "  '토대로',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여가',\n",
       "  '보다',\n",
       "  '활성화를',\n",
       "  '위',\n",
       "  '해서는',\n",
       "  '단위',\n",
       "  '학교에서는',\n",
       "  '마을교육',\n",
       "  '만이',\n",
       "  '가지',\n",
       "  '고',\n",
       "  '있는',\n",
       "  '고유의',\n",
       "  '특징을',\n",
       "  '충분히',\n",
       "  '이해',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있으며',\n",
       "  '마을교육',\n",
       "  '단체들은',\n",
       "  '방과후학교',\n",
       "  '활동을',\n",
       "  '위한',\n",
       "  '전문성',\n",
       "  '을',\n",
       "  '제고',\n",
       "  '해야',\n",
       "  '함을',\n",
       "  '대안으로',\n",
       "  '제시',\n",
       "  '하였다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3730/3730 [00:01<00:00, 3057.46it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이를',\n",
       " '위해',\n",
       " '한국청소년정책연구원에서',\n",
       " '구축한',\n",
       " '한국아동⋅',\n",
       " '청소년패널조사(Korean',\n",
       " 'Children',\n",
       " '&',\n",
       " 'Youth',\n",
       " 'Panel',\n",
       " 'Survey)의',\n",
       " '2013년~2016년(4차,',\n",
       " '5차,',\n",
       " '6차,',\n",
       " '7차)',\n",
       " '의',\n",
       " '데이터를',\n",
       " '사용하였다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 3730/3730 [00:00<00:00, 339992.48it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하고, 청소년의 사회 자본이 주관적 삶의 만족도에 미치는 영향과 종단적 변화 양상을 잠재성장모델(Latent Growth Model)을 활용하여 분석하였다',\n",
       " '이를 위해 한국청소년정책연구원에서 구축한 한국아동⋅ 청소년패널조사(Korean Children & Youth Panel Survey)의 2013년~2016년(4차, 5차, 6차, 7차) 의 데이터를 사용하였다',\n",
       " '연구결과를 살펴보면 첫째, 청소년의 사회자본과 주관적 삶의 만족도의초기 값과의 관계는 학교 또래 관계(+), 부모와의 관계(+), 지역사회 인식(+), 교사와의 관계(+), 공동체 의식(+)이 정적인 관계가 있는 것으로 나타났다',\n",
       " '또한 청소년의 주관적 삶의 만족도에대한 시간에 따른 변화율은 성별(-), 학교 또래 관계(-), 학교 교사와의 관계(-), 공동체의식(-)이영향을 미침을 알 수 있다',\n",
       " '이에 청소년의 주관적 삶의 만족도에 가정 내 부모관계가 여전히 중요하지만 학교 사회자본과 지역사회 사회자본의 중요성 또한 주목하여 이를 강화시킬 수 있는 실천적대안을 제시하였다',\n",
       " '또한 고등학교로 진학하고 시간이 흐름에 따라 학교 또래 관계, 교사와의 관계, 공동체 의식 변수가 스트레스에 대한 보호적 역할을 지속할 수 있도록 학교 현장에 맞는 정책적대안이 필요함을 제언하는 바이다',\n",
       " '본 연구는 청소년의 주관적 삶의 만족도와 사회자본과의 관계와종단적 영향을 보여줌으로서 청소년의 주관적 삶의 만족도 향상을 위한 학문적 기초를 제공함에그 의의가 있을 것이다']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  35\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.892493297587132\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  509\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 18.38516933319746\n",
      "문장 내의 단어 개수 중앙값 : 17.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2798, 20, 200)\n",
      "train_Y_data.shape: (2798, 4)\n",
      "val_X_data.shape: (932, 20, 200)\n",
      "val_Y_data.shape: (932, 4)\n",
      "test_X_data.shape: (932, 20, 200)\n",
      "test_Y_data.shape: (932, 4)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '하였다': 2,\n",
       " '에': 3,\n",
       " '을': 4,\n",
       " '이': 5,\n",
       " '과': 6,\n",
       " '본': 7,\n",
       " '영향을': 8,\n",
       " '대한': 9,\n",
       " '것으로': 10,\n",
       " '적': 11,\n",
       " '및': 12,\n",
       " '수': 13,\n",
       " '를': 14,\n",
       " '미치는': 15,\n",
       " '는': 16,\n",
       " '나타났다': 17,\n",
       " '은': 18,\n",
       " '한': 19,\n",
       " '있는': 20,\n",
       " '하고': 21,\n",
       " '있다': 22,\n",
       " '하는': 23,\n",
       " '인': 24,\n",
       " '연구는': 25,\n",
       " '분석': 26,\n",
       " '연구': 27,\n",
       " '가': 28,\n",
       " '와': 29,\n",
       " '할': 30,\n",
       " '위해': 31,\n",
       " '으로': 32,\n",
       " '통해': 33,\n",
       " '결과': 34,\n",
       " '되었다': 35,\n",
       " '로': 36,\n",
       " '것이': 37,\n",
       " '대상으로': 38,\n",
       " '위한': 39,\n",
       " '연구의': 40,\n",
       " '한다': 41,\n",
       " '고': 42,\n",
       " '다': 43,\n",
       " '이를': 44,\n",
       " '직무': 45,\n",
       " '에서': 46,\n",
       " '우울': 47,\n",
       " '된': 48,\n",
       " '한국': 49,\n",
       " '실시': 50,\n",
       " '들': 51,\n",
       " '하기': 52,\n",
       " '진로': 53,\n",
       " '이러한': 54,\n",
       " '유의한': 55,\n",
       " '그': 56,\n",
       " '확인': 57,\n",
       " '자기': 58,\n",
       " '사회적': 59,\n",
       " '또한': 60,\n",
       " '검증': 61,\n",
       " '둘째': 62,\n",
       " '첫째': 63,\n",
       " '사회': 64,\n",
       " '하여': 65,\n",
       " '중': 66,\n",
       " '그리고': 67,\n",
       " '교육': 68,\n",
       " '관련': 69,\n",
       " '중국': 70,\n",
       " '있었다': 71,\n",
       " '사용': 72,\n",
       " '따라': 73,\n",
       " '지': 74,\n",
       " '이다': 75,\n",
       " '학교': 76,\n",
       " '긍정적': 77,\n",
       " '성': 78,\n",
       " '활용': 79,\n",
       " '삶의': 80,\n",
       " '서비스': 81,\n",
       " '조직': 82,\n",
       " '하였으며': 83,\n",
       " '다음': 84,\n",
       " '제시': 85,\n",
       " '셋째': 86,\n",
       " '명을': 87,\n",
       " '높은': 88,\n",
       " '영향': 89,\n",
       " '학습': 90,\n",
       " '도': 91,\n",
       " '청소년의': 92,\n",
       " '대해': 93,\n",
       " '청소년': 94,\n",
       " '관계를': 95,\n",
       " '경우': 96,\n",
       " '경험': 97,\n",
       " '결과는': 98,\n",
       " '3': 99,\n",
       " '부모': 100,\n",
       " '따른': 101,\n",
       " '4': 102,\n",
       " '결과를': 103,\n",
       " '간': 104,\n",
       " '가장': 105,\n",
       " '2': 106,\n",
       " '이용': 107,\n",
       " '다양한': 108,\n",
       " '가지': 109,\n",
       " '바탕으로': 110,\n",
       " '심리적': 111,\n",
       " '더': 112,\n",
       " '개발': 113,\n",
       " '될': 114,\n",
       " '보다': 115,\n",
       " '요인': 116,\n",
       " '간의': 117,\n",
       " '1': 118,\n",
       " '자료를': 119,\n",
       " '차이가': 120,\n",
       " '연구에서는': 121,\n",
       " '된다': 122,\n",
       " '같다': 123,\n",
       " '서': 124,\n",
       " '모두': 125,\n",
       " '것을': 126,\n",
       " '참여': 127,\n",
       " '위하여': 128,\n",
       " '목적은': 129,\n",
       " '인식': 130,\n",
       " '총': 131,\n",
       " '따라서': 132,\n",
       " '관계': 133,\n",
       " '매개': 134,\n",
       " '증가': 135,\n",
       " '유의미한': 136,\n",
       " '관계에서': 137,\n",
       " '분석을': 138,\n",
       " '문화': 139,\n",
       " '의미': 140,\n",
       " '대학': 141,\n",
       " '후': 142,\n",
       " '수행': 143,\n",
       " '되는': 144,\n",
       " '같은': 145,\n",
       " '개': 146,\n",
       " '해': 147,\n",
       " '논의': 148,\n",
       " '연구를': 149,\n",
       " '하고자': 150,\n",
       " '되고': 151,\n",
       " '개인': 152,\n",
       " '문제': 153,\n",
       " '제공': 154,\n",
       " '특히': 155,\n",
       " '여': 156,\n",
       " '다문화': 157,\n",
       " '등': 158,\n",
       " '구성': 159,\n",
       " '이에': 160,\n",
       " '학년': 161,\n",
       " '프로그램': 162,\n",
       " '제': 163,\n",
       " '평가': 164,\n",
       " '개의': 165,\n",
       " '측정': 166,\n",
       " '일반': 167,\n",
       " '집단': 168,\n",
       " '가족': 169,\n",
       " '정보': 170,\n",
       " '연구결과': 171,\n",
       " '진행': 172,\n",
       " '학업': 173,\n",
       " '지역': 174,\n",
       " '명': 175,\n",
       " '향상': 176,\n",
       " '비교': 177,\n",
       " '효과를': 178,\n",
       " '도출': 179,\n",
       " '명의': 180,\n",
       " '프로그램을': 181,\n",
       " '변화': 182,\n",
       " '만족도': 183,\n",
       " '부터': 184,\n",
       " '적용': 185,\n",
       " '하였고': 186,\n",
       " '중요한': 187,\n",
       " '에서는': 188,\n",
       " '5': 189,\n",
       " '주요': 190,\n",
       " '건강': 191,\n",
       " '정적': 192,\n",
       " '부정적': 193,\n",
       " '조사': 194,\n",
       " '국내': 195,\n",
       " '기술': 196,\n",
       " '했다': 197,\n",
       " '있으며': 198,\n",
       " '하는데': 199,\n",
       " '차이를': 200,\n",
       " '자아존중감': 201,\n",
       " '만족': 202,\n",
       " '통한': 203,\n",
       " '정의': 204,\n",
       " '교사': 205,\n",
       " '자': 206,\n",
       " '까지': 207,\n",
       " '질적': 208,\n",
       " '세': 209,\n",
       " '대': 210,\n",
       " '대학생': 211,\n",
       " '이는': 212,\n",
       " '정서': 213,\n",
       " '때': 214,\n",
       " '차': 215,\n",
       " '스트레스': 216,\n",
       " '나타났으며': 217,\n",
       " '보였다': 218,\n",
       " '통계적으로': 219,\n",
       " '만족도에': 220,\n",
       " '고객': 221,\n",
       " '아니라': 222,\n",
       " '이용하여': 223,\n",
       " '며': 224,\n",
       " '지원': 225,\n",
       " '이었다': 226,\n",
       " '새로운': 227,\n",
       " '생활': 228,\n",
       " '여성': 229,\n",
       " '자료': 230,\n",
       " '각': 231,\n",
       " '에는': 232,\n",
       " '두': 233,\n",
       " '향후': 234,\n",
       " '있음을': 235,\n",
       " '비해': 236,\n",
       " '관한': 237,\n",
       " '척도': 238,\n",
       " '중심으로': 239,\n",
       " '설문조사': 240,\n",
       " '미치': 241,\n",
       " '위': 242,\n",
       " '하위': 243,\n",
       " '인터넷': 244,\n",
       " '감소': 245,\n",
       " '직접': 246,\n",
       " '등의': 247,\n",
       " '수집': 248,\n",
       " '역할을': 249,\n",
       " '대학생의': 250,\n",
       " '함께': 251,\n",
       " '되어': 252,\n",
       " '있어': 253,\n",
       " '상호작용': 254,\n",
       " '연구가': 255,\n",
       " '큰': 256,\n",
       " '탐색': 257,\n",
       " '불안': 258,\n",
       " '학생': 259,\n",
       " '에게': 260,\n",
       " '어떠한': 261,\n",
       " '직업': 262,\n",
       " '매개효과를': 263,\n",
       " '이후': 264,\n",
       " '인지': 265,\n",
       " '대인관계': 266,\n",
       " '통하여': 267,\n",
       " '연구결과를': 268,\n",
       " '형': 269,\n",
       " '토대로': 270,\n",
       " '행동': 271,\n",
       " '해야': 272,\n",
       " '부적': 273,\n",
       " '제안': 274,\n",
       " '고객만족': 275,\n",
       " '분석한': 276,\n",
       " '유의': 277,\n",
       " '노인': 278,\n",
       " '많은': 279,\n",
       " '즉': 280,\n",
       " '요인을': 281,\n",
       " '방안을': 282,\n",
       " '효과': 283,\n",
       " '데': 284,\n",
       " '주관적': 285,\n",
       " '화': 286,\n",
       " '국가': 287,\n",
       " '해서는': 288,\n",
       " '주는': 289,\n",
       " '정책': 290,\n",
       " '다른': 291,\n",
       " '6': 292,\n",
       " '알': 293,\n",
       " '내': 294,\n",
       " '교수': 295,\n",
       " '활용하여': 296,\n",
       " '최근': 297,\n",
       " '시사점을': 298,\n",
       " '마지막으로': 299,\n",
       " '그러나': 300,\n",
       " '수업': 301,\n",
       " '자기효능감': 302,\n",
       " '높을수록': 303,\n",
       " '활동': 304,\n",
       " '온라인': 305,\n",
       " '있어서': 306,\n",
       " '높게': 307,\n",
       " '반면': 308,\n",
       " '환경': 309,\n",
       " '빅데이터': 310,\n",
       " '함으로써': 311,\n",
       " '있을': 312,\n",
       " '낮은': 313,\n",
       " '지지': 314,\n",
       " '정신건강': 315,\n",
       " '분석결과': 316,\n",
       " '전체': 317,\n",
       " '넷째': 318,\n",
       " '안녕감': 319,\n",
       " '의사소통': 320,\n",
       " '필요하다': 321,\n",
       " '현재': 322,\n",
       " '특성': 323,\n",
       " '매우': 324,\n",
       " '과의': 325,\n",
       " '관리': 326,\n",
       " '만족에': 327,\n",
       " '목적이': 328,\n",
       " '가정': 329,\n",
       " '등을': 330,\n",
       " '형성': 331,\n",
       " '조절': 332,\n",
       " '기업': 333,\n",
       " '관련된': 334,\n",
       " '하지': 335,\n",
       " '부모의': 336,\n",
       " '있도록': 337,\n",
       " '파악': 338,\n",
       " '필요가': 339,\n",
       " '않았다': 340,\n",
       " '접근': 341,\n",
       " '핵심': 342,\n",
       " '나': 343,\n",
       " '데이터': 344,\n",
       " '신뢰': 345,\n",
       " '많이': 346,\n",
       " '유형': 347,\n",
       " '연구결과는': 348,\n",
       " '특성을': 349,\n",
       " '효과가': 350,\n",
       " '이나': 351,\n",
       " '평균': 352,\n",
       " '성별': 353,\n",
       " '정서적': 354,\n",
       " '어떻게': 355,\n",
       " '있다는': 356,\n",
       " '자녀': 357,\n",
       " '간호': 358,\n",
       " '지각된': 359,\n",
       " '사용하여': 360,\n",
       " '과정에서': 361,\n",
       " '노인의': 362,\n",
       " '이상': 363,\n",
       " '볼': 364,\n",
       " '001': 365,\n",
       " '요인은': 366,\n",
       " '하며': 367,\n",
       " '운영': 368,\n",
       " '취업': 369,\n",
       " '프로그램의': 370,\n",
       " '스마트폰': 371,\n",
       " '개선': 372,\n",
       " '이해': 373,\n",
       " '수준': 374,\n",
       " '이고': 375,\n",
       " '성과': 376,\n",
       " '품질': 377,\n",
       " '발전': 378,\n",
       " '것은': 379,\n",
       " '수준이': 380,\n",
       " '만': 381,\n",
       " '중국의': 382,\n",
       " '고려': 383,\n",
       " '예측': 384,\n",
       " '자료는': 385,\n",
       " '수집된': 386,\n",
       " '설명': 387,\n",
       " '점': 388,\n",
       " '과정을': 389,\n",
       " '자살': 390,\n",
       " '모바일': 391,\n",
       " '경제적': 392,\n",
       " '기초': 393,\n",
       " '각각': 394,\n",
       " '가치': 395,\n",
       " '통합': 396,\n",
       " '생각': 397,\n",
       " '요인으로': 398,\n",
       " '태도': 399,\n",
       " '변화를': 400,\n",
       " '시사': 401,\n",
       " '규명': 402,\n",
       " '능력': 403,\n",
       " '유의하게': 404,\n",
       " '초기': 405,\n",
       " '와의': 406,\n",
       " '살펴보았다': 407,\n",
       " '자살생각': 408,\n",
       " '장애': 409,\n",
       " '만족도가': 410,\n",
       " '만족도를': 411,\n",
       " '전략': 412,\n",
       " '대상': 413,\n",
       " '없는': 414,\n",
       " '증진': 415,\n",
       " '존재': 416,\n",
       " '브랜드': 417,\n",
       " '연구에서': 418,\n",
       " '통계': 419,\n",
       " '성인': 420,\n",
       " '모형을': 421,\n",
       " '이와': 422,\n",
       " '미래': 423,\n",
       " '감정': 424,\n",
       " '이론적': 425,\n",
       " '않은': 426,\n",
       " '대하여': 427,\n",
       " '관광': 428,\n",
       " '중재': 429,\n",
       " '자신의': 430,\n",
       " '모든': 431,\n",
       " '시': 432,\n",
       " '통제': 433,\n",
       " '근거': 434,\n",
       " '경제': 435,\n",
       " '미치고': 436,\n",
       " '수용': 437,\n",
       " '사용자': 438,\n",
       " '실제': 439,\n",
       " '이들': 440,\n",
       " '선행연구': 441,\n",
       " '목적': 442,\n",
       " '포함': 443,\n",
       " '목적으로': 444,\n",
       " '독립': 445,\n",
       " '적응': 446,\n",
       " '소비자': 447,\n",
       " '학생들의': 448,\n",
       " '점에서': 449,\n",
       " '인간': 450,\n",
       " '사': 451,\n",
       " '중심': 452,\n",
       " '자아탄력성': 453,\n",
       " '아동': 454,\n",
       " '시키는': 455,\n",
       " '영향력을': 456,\n",
       " '되었으며': 457,\n",
       " '경험이': 458,\n",
       " '요인이': 459,\n",
       " '우리나라': 460,\n",
       " '이상의': 461,\n",
       " '이며': 462,\n",
       " '라는': 463,\n",
       " '되어야': 464,\n",
       " '않는': 465,\n",
       " '만족과': 466,\n",
       " '시킬': 467,\n",
       " '상담': 468,\n",
       " '현실': 469,\n",
       " '표현': 470,\n",
       " '전': 471,\n",
       " '확대': 472,\n",
       " '우리': 473,\n",
       " '시도': 474,\n",
       " '서울': 475,\n",
       " '미쳤다': 476,\n",
       " '주': 477,\n",
       " '최종': 478,\n",
       " '일': 479,\n",
       " '판단': 480,\n",
       " '운동': 481,\n",
       " '어떤': 482,\n",
       " '중학생': 483,\n",
       " '방법을': 484,\n",
       " '하면서': 485,\n",
       " '관계가': 486,\n",
       " '설문': 487,\n",
       " '검토': 488,\n",
       " '기반': 489,\n",
       " '일본': 490,\n",
       " '목적을': 491,\n",
       " '체험': 492,\n",
       " '발생': 493,\n",
       " '또래': 494,\n",
       " '활용한': 495,\n",
       " '개입': 496,\n",
       " '표본': 497,\n",
       " '신뢰도': 498,\n",
       " '이라는': 499,\n",
       " '실천': 500,\n",
       " '내용': 501,\n",
       " '남녀': 502,\n",
       " '역량': 503,\n",
       " '국제': 504,\n",
       " '발견': 505,\n",
       " '때문에': 506,\n",
       " '선정': 507,\n",
       " '크게': 508,\n",
       " '방향을': 509,\n",
       " '척도를': 510,\n",
       " '소재': 511,\n",
       " '의의': 512,\n",
       " '북한': 513,\n",
       " '사전': 514,\n",
       " '의의가': 515,\n",
       " '교육의': 516,\n",
       " '하지만': 517,\n",
       " '마련': 518,\n",
       " '나타난': 519,\n",
       " '미국': 520,\n",
       " '예방': 521,\n",
       " '등이': 522,\n",
       " '인공지능': 523,\n",
       " '전공': 524,\n",
       " '만족도와': 525,\n",
       " '순으로': 526,\n",
       " '여가': 527,\n",
       " '성격': 528,\n",
       " '변인': 529,\n",
       " '지역사회': 530,\n",
       " '높았다': 531,\n",
       " '경험을': 532,\n",
       " '전문': 533,\n",
       " '요구': 534,\n",
       " '세계': 535,\n",
       " '20': 536,\n",
       " '필요한': 537,\n",
       " '에서의': 538,\n",
       " '요': 539,\n",
       " '측면에서': 540,\n",
       " '디자인': 541,\n",
       " '결정': 542,\n",
       " '설문지를': 543,\n",
       " '사례': 544,\n",
       " '문화적': 545,\n",
       " '문제를': 546,\n",
       " '상관관계를': 547,\n",
       " '연령': 548,\n",
       " '파악하고': 549,\n",
       " '게': 550,\n",
       " '의해': 551,\n",
       " '만족도는': 552,\n",
       " '력': 553,\n",
       " '19': 554,\n",
       " '연구대상은': 555,\n",
       " '중인': 556,\n",
       " '업무': 557,\n",
       " '학교폭력': 558,\n",
       " '나타났고': 559,\n",
       " '효과적인': 560,\n",
       " '선택': 561,\n",
       " '중독': 562,\n",
       " '애착': 563,\n",
       " '조절효과를': 564,\n",
       " '부분': 565,\n",
       " '제한점': 566,\n",
       " '또는': 567,\n",
       " '중학교': 568,\n",
       " '검사': 569,\n",
       " '남학생': 570,\n",
       " '군': 571,\n",
       " '잠재': 572,\n",
       " '기업의': 573,\n",
       " '상호': 574,\n",
       " '동시에': 575,\n",
       " '분류': 576,\n",
       " '뿐': 577,\n",
       " '모색': 578,\n",
       " '간호대학생의': 579,\n",
       " '산업': 580,\n",
       " '연구에': 581,\n",
       " '인지적': 582,\n",
       " '기존': 583,\n",
       " '시작': 584,\n",
       " '장애인': 585,\n",
       " '나타나': 586,\n",
       " '에도': 587,\n",
       " '응답': 588,\n",
       " '상': 589,\n",
       " '단계': 590,\n",
       " '역할': 591,\n",
       " '실험집단': 592,\n",
       " '10': 593,\n",
       " '구조방정식': 594,\n",
       " '내적': 595,\n",
       " '강화': 596,\n",
       " '부의': 597,\n",
       " '여러': 598,\n",
       " '정책적': 599,\n",
       " '회귀분석을': 600,\n",
       " '자아': 601,\n",
       " '자기효능감과': 602,\n",
       " '분석에': 603,\n",
       " '기존의': 604,\n",
       " '시행': 605,\n",
       " '문항': 606,\n",
       " '향상을': 607,\n",
       " '먼저': 608,\n",
       " '확인할': 609,\n",
       " '하위요인': 610,\n",
       " '게임': 611,\n",
       " '고등학교': 612,\n",
       " '지만': 613,\n",
       " '구조': 614,\n",
       " '한다는': 615,\n",
       " '사후': 616,\n",
       " '융합': 617,\n",
       " '관점에서': 618,\n",
       " '초등학교': 619,\n",
       " '인해': 620,\n",
       " '광고': 621,\n",
       " '시키기': 622,\n",
       " '특성에': 623,\n",
       " '데이터를': 624,\n",
       " '하게': 625,\n",
       " '관계에': 626,\n",
       " '유지': 627,\n",
       " '점을': 628,\n",
       " '창업': 629,\n",
       " '구매': 630,\n",
       " '설정': 631,\n",
       " '공감': 632,\n",
       " '필요성': 633,\n",
       " '공격성': 634,\n",
       " '재학': 635,\n",
       " '모형': 636,\n",
       " '영향이': 637,\n",
       " '시사점': 638,\n",
       " '동안': 639,\n",
       " '빈도': 640,\n",
       " '알아보기': 641,\n",
       " '7': 642,\n",
       " '부를': 643,\n",
       " '내용을': 644,\n",
       " '글쓰기': 645,\n",
       " '네트워크': 646,\n",
       " '분석하여': 647,\n",
       " '기반으로': 648,\n",
       " '편의': 649,\n",
       " '의미를': 650,\n",
       " '수준을': 651,\n",
       " '신체': 652,\n",
       " '지식': 653,\n",
       " '있고': 654,\n",
       " '콘텐츠': 655,\n",
       " '방법': 656,\n",
       " '매개효과': 657,\n",
       " '실시하여': 658,\n",
       " '검증을': 659,\n",
       " '피해': 660,\n",
       " '우울의': 661,\n",
       " '있었으며': 662,\n",
       " '공공': 663,\n",
       " '8': 664,\n",
       " '해결': 665,\n",
       " '비행': 666,\n",
       " '산업혁명': 667,\n",
       " '기': 668,\n",
       " '구축': 669,\n",
       " '실천적': 670,\n",
       " '몰입': 671,\n",
       " '영향력': 672,\n",
       " '상관관계': 673,\n",
       " '더욱': 674,\n",
       " '화된': 675,\n",
       " '알아보고자': 676,\n",
       " '속에서': 677,\n",
       " '예비': 678,\n",
       " '대처': 679,\n",
       " '행복감': 680,\n",
       " '추후': 681,\n",
       " '조절효과': 682,\n",
       " '마케팅': 683,\n",
       " '상황': 684,\n",
       " '교사의': 685,\n",
       " '인한': 686,\n",
       " '한편': 687,\n",
       " '강조': 688,\n",
       " '청소년들의': 689,\n",
       " '동기': 690,\n",
       " '별': 691,\n",
       " '과정': 692,\n",
       " '노력': 693,\n",
       " '이직의도에': 694,\n",
       " '보호': 695,\n",
       " '못하': 696,\n",
       " '거주': 697,\n",
       " '정보를': 698,\n",
       " '질': 699,\n",
       " '발달': 700,\n",
       " '외상': 701,\n",
       " '통제집단': 702,\n",
       " '아동의': 703,\n",
       " '개념': 704,\n",
       " '여학생': 705,\n",
       " '더불어': 706,\n",
       " '개인적': 707,\n",
       " '논문은': 708,\n",
       " '측면': 709,\n",
       " '임파워먼트': 710,\n",
       " '작용': 711,\n",
       " '있었': 712,\n",
       " '프로그램이': 713,\n",
       " '반응': 714,\n",
       " '12': 715,\n",
       " '심리': 716,\n",
       " '가능성이': 717,\n",
       " '개별': 718,\n",
       " '구조적': 719,\n",
       " '유의미하게': 720,\n",
       " '학습자': 721,\n",
       " '전략을': 722,\n",
       " '매개효과가': 723,\n",
       " '기대': 724,\n",
       " '상관': 725,\n",
       " '어머니': 726,\n",
       " '살펴보고': 727,\n",
       " '다중회귀분석': 728,\n",
       " '상관관계가': 729,\n",
       " '정치': 730,\n",
       " '성과에': 731,\n",
       " '차이': 732,\n",
       " '회복탄력성': 733,\n",
       " '제언': 734,\n",
       " '영역': 735,\n",
       " '시간': 736,\n",
       " '되었고': 737,\n",
       " '개인의': 738,\n",
       " '언어': 739,\n",
       " '차년도': 740,\n",
       " '명이': 741,\n",
       " '때문': 742,\n",
       " '스포츠': 743,\n",
       " '제언을': 744,\n",
       " '치료': 745,\n",
       " '위험': 746,\n",
       " '고찰': 747,\n",
       " '특징': 748,\n",
       " '도움이': 749,\n",
       " '간에': 750,\n",
       " '상태': 751,\n",
       " '창의성': 752,\n",
       " '연구방법': 753,\n",
       " '대응': 754,\n",
       " '상대적으로': 755,\n",
       " '제외한': 756,\n",
       " '지속': 757,\n",
       " '인분석': 758,\n",
       " '지도': 759,\n",
       " '높이기': 760,\n",
       " '종교': 761,\n",
       " '근무': 762,\n",
       " '다문화가정': 763,\n",
       " '구분': 764,\n",
       " '대학의': 765,\n",
       " '보다는': 766,\n",
       " '였다': 767,\n",
       " '친구': 768,\n",
       " '어머니의': 769,\n",
       " '추구': 770,\n",
       " '전환': 771,\n",
       " '방문': 772,\n",
       " '이직의도': 773,\n",
       " '호텔': 774,\n",
       " '가진': 775,\n",
       " '행복': 776,\n",
       " '어려움': 777,\n",
       " '목표': 778,\n",
       " '나아가': 779,\n",
       " '대상자의': 780,\n",
       " '전국': 781,\n",
       " '중에서': 782,\n",
       " '대학생들의': 783,\n",
       " '프로그램은': 784,\n",
       " '이미지': 785,\n",
       " '시스템': 786,\n",
       " '속': 787,\n",
       " '잘': 788,\n",
       " '도시': 789,\n",
       " '가능성을': 790,\n",
       " '양적': 791,\n",
       " '가설': 792,\n",
       " '실시하였': 793,\n",
       " '적응에': 794,\n",
       " '맥락': 795,\n",
       " '같이': 796,\n",
       " '스트레스와': 797,\n",
       " '주의': 798,\n",
       " '활성화': 799,\n",
       " '자기효능감이': 800,\n",
       " '사고': 801,\n",
       " '주목': 802,\n",
       " '것': 803,\n",
       " '등에': 804,\n",
       " '디지털': 805,\n",
       " '상관이': 806,\n",
       " '살펴보고자': 807,\n",
       " '달성': 808,\n",
       " '소통': 809,\n",
       " '차별': 810,\n",
       " '해당': 811,\n",
       " '의한': 812,\n",
       " '연계': 813,\n",
       " '종합': 814,\n",
       " '학업적': 815,\n",
       " '기능': 816,\n",
       " '역사': 817,\n",
       " '프로그램에': 818,\n",
       " '탐색적': 819,\n",
       " '사이버': 820,\n",
       " '기본': 821,\n",
       " '군집': 822,\n",
       " '이들의': 823,\n",
       " '추출': 824,\n",
       " '감정노동': 825,\n",
       " '협력': 826,\n",
       " '자존감': 827,\n",
       " '주로': 828,\n",
       " '소재한': 829,\n",
       " '신체적': 830,\n",
       " '지속적인': 831,\n",
       " '계획': 832,\n",
       " '리더십': 833,\n",
       " '면': 834,\n",
       " '욕구': 835,\n",
       " '제공하는': 836,\n",
       " '가치를': 837,\n",
       " '기초자료': 838,\n",
       " '있다고': 839,\n",
       " '변화에': 840,\n",
       " '어': 841,\n",
       " '고등학생': 842,\n",
       " '전통': 843,\n",
       " '교육과정': 844,\n",
       " '코로나': 845,\n",
       " '효능감': 846,\n",
       " '만족을': 847,\n",
       " '참여한': 848,\n",
       " '학업성취도': 849,\n",
       " '제시하': 850,\n",
       " '요소': 851,\n",
       " '주제': 852,\n",
       " '복지': 853,\n",
       " '되지': 854,\n",
       " '상관을': 855,\n",
       " '창의적': 856,\n",
       " '성장': 857,\n",
       " '교육을': 858,\n",
       " '도입': 859,\n",
       " '보고': 860,\n",
       " '활동을': 861,\n",
       " '세기': 862,\n",
       " '시설': 863,\n",
       " '완화': 864,\n",
       " '함의를': 865,\n",
       " '조사를': 866,\n",
       " '남자': 867,\n",
       " '여자': 868,\n",
       " '경로': 869,\n",
       " '지속적으로': 870,\n",
       " '극복': 871,\n",
       " '성취': 872,\n",
       " '생산': 873,\n",
       " '구체적으로': 874,\n",
       " '집단에': 875,\n",
       " '집중': 876,\n",
       " '가운데': 877,\n",
       " '우울증': 878,\n",
       " '사람': 879,\n",
       " '분석과': 880,\n",
       " '시기': 881,\n",
       " '공간': 882,\n",
       " '배경': 883,\n",
       " '설문을': 884,\n",
       " '개인정보': 885,\n",
       " '청소년이': 886,\n",
       " '예술': 887,\n",
       " '커뮤니케이션': 888,\n",
       " '분석하는': 889,\n",
       " '희망': 890,\n",
       " '한류': 891,\n",
       " '뿐만': 892,\n",
       " '살펴본': 893,\n",
       " '갖는': 894,\n",
       " '정도': 895,\n",
       " '중심의': 896,\n",
       " '불구하고': 897,\n",
       " '갈등': 898,\n",
       " '학습자의': 899,\n",
       " '위계적': 900,\n",
       " '지역의': 901,\n",
       " '실행': 902,\n",
       " '실험': 903,\n",
       " '대학생활적응': 904,\n",
       " '있는지를': 905,\n",
       " '회피': 906,\n",
       " '적합한': 907,\n",
       " '상관분석': 908,\n",
       " '외국인': 909,\n",
       " '분석은': 910,\n",
       " '역시': 911,\n",
       " '검정': 912,\n",
       " '인식을': 913,\n",
       " '가능한': 914,\n",
       " '전문가': 915,\n",
       " '서비스를': 916,\n",
       " '자기효능감은': 917,\n",
       " '수준에': 918,\n",
       " '결론': 919,\n",
       " '남성': 920,\n",
       " '경기': 921,\n",
       " '2016년': 922,\n",
       " '죽음': 923,\n",
       " '연구들': 924,\n",
       " '과제': 925,\n",
       " '적용하여': 926,\n",
       " '가지는': 927,\n",
       " '영향력이': 928,\n",
       " '상황에서': 929,\n",
       " '요인에': 930,\n",
       " '관심': 931,\n",
       " '스트레스가': 932,\n",
       " '마음챙김': 933,\n",
       " '분야': 934,\n",
       " '관계는': 935,\n",
       " '결과에': 936,\n",
       " '인식과': 937,\n",
       " '보이': 938,\n",
       " '부적응': 939,\n",
       " '그들의': 940,\n",
       " '동아시아': 941,\n",
       " '범주': 942,\n",
       " '여성의': 943,\n",
       " '정서조절': 944,\n",
       " '타인': 945,\n",
       " '학생의': 946,\n",
       " '몰입에': 947,\n",
       " '선행': 948,\n",
       " '이용자': 949,\n",
       " '설계': 950,\n",
       " '공유': 951,\n",
       " '유아': 952,\n",
       " '지지와': 953,\n",
       " '구': 954,\n",
       " '제품': 955,\n",
       " '체육': 956,\n",
       " '실무적': 957,\n",
       " '제시하고자': 958,\n",
       " '연구자': 959,\n",
       " '처리': 960,\n",
       " '의도에': 961,\n",
       " '미칠': 962,\n",
       " '보인다': 963,\n",
       " '긍정': 964,\n",
       " '교육적': 965,\n",
       " '이야기': 966,\n",
       " '살펴보면': 967,\n",
       " '경험과': 968,\n",
       " '텍스트': 969,\n",
       " '정도가': 970,\n",
       " '으로는': 971,\n",
       " '요인과': 972,\n",
       " '유형에': 973,\n",
       " '자료로': 974,\n",
       " '변수': 975,\n",
       " '스마트': 976,\n",
       " '감성': 977,\n",
       " '스스로': 978,\n",
       " '집단이': 979,\n",
       " '정부': 980,\n",
       " '확장': 981,\n",
       " '인성': 982,\n",
       " '명으로': 983,\n",
       " '9': 984,\n",
       " '함을': 985,\n",
       " '추진': 986,\n",
       " '으로서': 987,\n",
       " '성별에': 988,\n",
       " '아닌': 989,\n",
       " '해외': 990,\n",
       " '과학': 991,\n",
       " '관련하여': 992,\n",
       " '자기효능감에': 993,\n",
       " '전문성': 994,\n",
       " '회복': 995,\n",
       " '특성과': 996,\n",
       " '차원에서': 997,\n",
       " '대학생을': 998,\n",
       " '확보': 999,\n",
       " '만족이': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 43358 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt_all_random_262.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x18ef7de2648>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2798 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 4.0895 - val_loss: 4.9429\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_sae_extra_all_v1_01_4.94290.h5\n",
      "Epoch 2/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 3.1235 - val_loss: 4.1925\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_sae_extra_all_v1_02_4.19246.h5\n",
      "Epoch 3/30\n",
      "2798/2798 [==============================] - 81s 29ms/step - loss: 2.9326 - val_loss: 4.3973\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_sae_extra_all_v1_03_4.39732.h5\n",
      "Epoch 4/30\n",
      "2798/2798 [==============================] - 82s 29ms/step - loss: 2.6433 - val_loss: 4.0197\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_sae_extra_all_v1_04_4.01969.h5\n",
      "Epoch 5/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 2.4172 - val_loss: 3.6864\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_sae_extra_all_v1_05_3.68640.h5\n",
      "Epoch 6/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 2.1946 - val_loss: 3.4958\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_sae_extra_all_v1_06_3.49584.h5\n",
      "Epoch 7/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 1.9114 - val_loss: 3.0621\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_sae_extra_all_v1_07_3.06210.h5\n",
      "Epoch 8/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 1.7131 - val_loss: 3.1269\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_sae_extra_all_v1_08_3.12686.h5\n",
      "Epoch 9/30\n",
      "2798/2798 [==============================] - 82s 29ms/step - loss: 1.5486 - val_loss: 2.8570\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_sae_extra_all_v1_09_2.85703.h5\n",
      "Epoch 10/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 1.3244 - val_loss: 2.7955\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_sae_extra_all_v1_10_2.79546.h5\n",
      "Epoch 11/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 1.0666 - val_loss: 2.9556\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_sae_extra_all_v1_11_2.95563.h5\n",
      "Epoch 12/30\n",
      "2798/2798 [==============================] - 82s 29ms/step - loss: 0.9800 - val_loss: 2.7584\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_sae_extra_all_v1_12_2.75840.h5\n",
      "Epoch 13/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 0.9242 - val_loss: 2.7225\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_sae_extra_all_v1_13_2.72254.h5\n",
      "Epoch 14/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 0.7398 - val_loss: 3.1895\n",
      "\n",
      "Epoch 00014: saving model to ./save_models/han_sae_extra_all_v1_14_3.18947.h5\n",
      "Epoch 15/30\n",
      "2798/2798 [==============================] - 82s 29ms/step - loss: 0.7046 - val_loss: 3.0461\n",
      "\n",
      "Epoch 00015: saving model to ./save_models/han_sae_extra_all_v1_15_3.04612.h5\n",
      "Epoch 16/30\n",
      "2798/2798 [==============================] - 84s 30ms/step - loss: 0.6411 - val_loss: 2.9677\n",
      "\n",
      "Epoch 00016: saving model to ./save_models/han_sae_extra_all_v1_16_2.96768.h5\n",
      "Epoch 17/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 0.6149 - val_loss: 4.8237\n",
      "\n",
      "Epoch 00017: saving model to ./save_models/han_sae_extra_all_v1_17_4.82374.h5\n",
      "Epoch 18/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 0.5509 - val_loss: 2.8843\n",
      "\n",
      "Epoch 00018: saving model to ./save_models/han_sae_extra_all_v1_18_2.88427.h5\n",
      "time : 1500.827181816101\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(4)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_sae_extra_all_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto') #mode='max')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4577300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 4,924,854\n",
      "Trainable params: 588,554\n",
      "Non-trainable params: 4,336,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3h0lEQVR4nO3dd3xUVfr48c9J7wGSEEhCCL0KBJDeFBuKYGERF1g7tlVxV13d7u7+dt3VdV3bF7uiCPYO6iLNAmjoHQIGSIEUSIWElPP748xAiBlImZk75Xm/XnllmLnlmcvkuXfOPec5SmuNEEII/xBgdQBCCCHcR5K+EEL4EUn6QgjhRyTpCyGEH5GkL4QQfkSSvhBC+BFJ+kIASqlXlVJ/a+KyWUqpC1q7HSGsIElfCCH8iCR9IYTwI5L0hdewNavcr5TarJSqUEq9pJRKVEotUUqVKaWWKqXa1lt+ilJqm1KqWCm1QinVp95r6Uqp9bb13gLCGuxrslJqo23d75RSA1oY8y1KqUyl1BGl1MdKqSTb80op9R+lVL5SqsT2nvrbXrtUKbXdFluOUuq+Fh0wIRohSV94m6uBC4GewOXAEuC3QDzm83w3gFKqJ7AQmAskAIuBT5RSIUqpEOBD4HWgHfCObbvY1h0MvAzcCsQBzwEfK6VCmxOoUup84B/AdKAjsB9YZHv5ImCc7X20Aa4BimyvvQTcqrWOBvoDy5qzXyHORJK+8DZPaa0Pa61zgK+BtVrrDVrrKuADIN223DXAZ1rr/2mtq4HHgHBgFDACCAae0FpXa63fBX6ot49bgOe01mu11rVa69eAKtt6zTETeFlrvd4W30PASKVUGlANRAO9AaW13qG1zrOtVw30VUrFaK2Paq3XN3O/QjgkSV94m8P1Hh9v5N9RtsdJmCtrALTWdcBBINn2Wo4+vdrg/nqPOwO/tjXtFCulioFOtvWao2EM5Zir+WSt9TLgaeAZ4LBS6nmlVIxt0auBS4H9SqmVSqmRzdyvEA5J0he+KheTvAHTho5J3DlAHpBse84utd7jg8D/01q3qfcTobVe2MoYIjHNRTkAWusntdZDgH6YZp77bc//oLWeCrTHNEO93cz9CuGQJH3hq94GLlNKTVRKBQO/xjTRfAesBmqAu5VSQUqpq4Bh9dZ9AbhNKTXcdsM1Uil1mVIqupkxvAncoJQaZLsf8HdMc1SWUupc2/aDgQqgEqi13XOYqZSKtTVLlQK1rTgOQpxGkr7wSVrrXcAs4CmgEHPT93Kt9Qmt9QngKuB64Cim/f/9eutmYNr1n7a9nmlbtrkxfAX8AXgP8+2iGzDD9nIM5uRyFNMEVIS57wAwG8hSSpUCt9nehxBOoWQSFSGE8B9ypS+EEH5Ekr4QQvgRSfpCCOFHJOkLIYQfCbI6gPri4+N1Wlqa1WEIIYTXWLduXaHWOqGpy3tU0k9LSyMjI8PqMIQQwmsopfaffalTpHlHCCH8iCR9IYTwI5L0hRDCj7i0TV8plQWUYWqH1GithzZ3G9XV1WRnZ1NZWens8DxKWFgYKSkpBAcHWx2KEMKHueNG7nla68KWrpydnU10dDRpaWmcXhTRd2itKSoqIjs7my5dulgdjhDCh3l8805lZSVxcXE+m/ABlFLExcX5/LcZIYT1XJ30NfClUmqdUmpOYwsopeYopTKUUhkFBQWNbsSXE76dP7xHIYT1XJ30R2utBwOTgDuVUuMaLqC1fl5rPVRrPTQhocnjC+ptoA7KD0NVeeujFUIIH+fSpK+1zrX9zsfMXzrszGu0ZCdAeQGU5oALykQXFxfz7LPPNnu9Sy+9lOLiYqfHI4QQreGypG+bbSja/hi4CNjq9B0FBEB0B6g+BpUlTt+8o6RfW3vmyYwWL15MmzZtnB6PEEK0hit77yQCH9jaqoOAN7XWn7tkTxFxUJ4PZXkQFgtObB9/8MEH2bt3L4MGDSI4OJioqCg6duzIxo0b2b59O1dccQUHDx6ksrKSe+65hzlzzK0Le0mJ8vJyJk2axJgxY/juu+9ITk7mo48+Ijw83GkxCiFEU7ks6Wut9wEDnbnNhz/Zxvbc0sZfrKuBmkoIKoCApvd175sUw58u7+fw9UceeYStW7eyceNGVqxYwWWXXcbWrVtPdq18+eWXadeuHcePH+fcc8/l6quvJi4u7rRt7Nmzh4ULF/LCCy8wffp03nvvPWbNkhnwhBDu5/FdNpssIAhUANSecOluhg0bdlpf+ieffJKBAwcyYsQIDh48yJ49e36yTpcuXRg0aBAAQ4YMISsry6UxCiHcoK4OTlRYHUWzeVSVzbM50xU5AJWlcGQvxKRAVAt6AjVBZGTkyccrVqxg6dKlrF69moiICCZMmNBoX/vQ0NCTjwMDAzl+/LhLYhNCuNHaefD1v+FX2yEo9OzLewjfudIHCI2GkCgoPwR1Z77R2lTR0dGUlZU1+lpJSQlt27YlIiKCnTt3smbNGqfsUwjhBfYug2OFcHib1ZE0i1dd6Z+VUhCTBIW7oaLA9Opppbi4OEaPHk3//v0JDw8nMTHx5GuXXHIJ8+bNY8CAAfTq1YsRI0a0en9CCC+gNeSsM49zN0DyYGvjaQbfSvoAIZGmB095PkTEQ2Dr3+Kbb77Z6POhoaEsWbKk0dfs7fbx8fFs3Xqqp+p9993X6niEEBY7+iMcP2Ie564HbrI0nObwreYdu+iOoGvNSF0hhHC2bNtVfkwy5G60NJTm8s2kHxwO4e1ME0+Na3vzCCH8UE4GBEfAgOmQvwNOHLM6oibzzaQPp9rzyw9ZG4cQwvdkZ0DHQZAyzLQqHNpidURN5rtJPygUIuPhWBFUS8liIYST1FTBoc2QMgSS0s1zueutjakZfDfpA0QlmgFbZXlWRyKE8BWHtppBoMlDIaajuYeYu8HqqJrMt5N+YDBEtofKYq8cOSeE8EA5GeZ3im3216R0yJErfc8R1R5UIJS652o/KirKLfsRQlgkZ51pRYhJNv9OGgxFe0xFAC/g+0k/INDc1D1RBlWNj6wVQogmy84wTTv2ar72dv28jZaF1By+n/TBDNIKCIbS3GZPtPKb3/zmtHr6f/7zn3n44YeZOHEigwcP5pxzzuGjjz5ydsRCCE907Iip75Uy5NRzJ2/meke7vneNyF3yYMu7RtVV20ovh5uKnHYdzoFJjzhcbcaMGcydO5c77rgDgLfffpvPP/+ce++9l5iYGAoLCxkxYgRTpkyReW6F8HX2tvvkoaeei4yDNqle067vXUm/NU6WXq4yTT40LUGnp6eTn59Pbm4uBQUFtG3blo4dO3LvvfeyatUqAgICyMnJ4fDhw3To0PpaP0IID5aTAahTV/d2SYPlSt8lznBF3iTHi03NjDapZratJpo2bRrvvvsuhw4dYsaMGSxYsICCggLWrVtHcHAwaWlpjZZUFkL4mOwMSOgNYTGnP5+UDts/hIoic+XvwfyjTd8uLNYMnS7NMxMgNNGMGTNYtGgR7777LtOmTaOkpIT27dsTHBzM8uXL2b9/vwuDFkJ4BHtlzfrt+Xb2Kpt5nn+1719J3156ua7a1MFuon79+lFWVkZycjIdO3Zk5syZZGRkMHToUBYsWEDv3r1dGLQQwiPYK2smN5L0O9pmhs3x/KTvXc07zhAaDSHRpgJnRJytff/stmw5dQM5Pj6e1atXN7pceXm5U8IUQngYe2XN+jdx7cJiIa6HV7Tr+9eVvl1MRzORenm+c7dbVwtlh8xMOhVN/yYhhPAC9sqa7fs2/npSulfU4PHPpG+faKUiH2qrW7+9Olvt/vztp+r8lBx0/klFCGEde2VNRxMzJQ82f/9uGv3fUl6R9HUzB1Q1SXQS6LrWTbSi66C8wCT70lxTxz++J7TvY04qpTnmyr8J8bvkPQohnKN+ZU1HvGSQlscn/bCwMIqKipyfFIPDTJt+RaH5D20OXWfWO7wdSrNNGee4HhDX3XyLUAHQtouZyKUsD8rOPBJYa01RURFhYWGtfFNCCJeoX1nTkQ4DzN++hyd9j7+Rm5KSQnZ2NgUFBc7feF0NlOZDXgVEtDv78lpD9TFTWKmuGgJDbd1Aa6HgYOPLVx6Dqq0QmgVhbU/V62ggLCyMlJSU1r0fIYRrNKys2ZiQCEjo4/Ht+h6f9IODg+nSpYvrdvDFIljzLNy+Gto76HpZVwc7PoLl/4DCXZB4Dpz/e+g53mESP0lr+N8f4YsnYeC1MOVpp0zWLoRwo+wMiOpwqrKmI8npsGuJ+bv30LIsHt+843JjfgXBkbDsrz99TWvzH/jcOHjnevPcz16DW1dBr0ua9p+qFFz4Fzjvd7BpIbx7ffObk4QQ1spZZ/rnn+1vPindzNZXfMA9cbWAJP3IOBh9N+z81JzNwST7zK/gxYmwcAacKIerXoA7VkO/KyCgmYdNKRj/AFz8D9jxCSz6uVdNpCyEX2ussqYjSbaRuR7cri9JH2DE7ab88tI/Q9Y38Mql8MZVpsvllKfglz+YWe+bOJDLoZF3wOVPmhPKgmleM+mCEH6tscqajiT2M2XcPbhdX5I+mFG64+6HrK/h1cvgyD649DG4ax0M/oWZdtFZhlwHV78IB9bA/KnmKkII4bkcVdZsTFAodOjv0Vf6ckfRbugNZuabxH4w9CZzJ95VzplmRva9cx28Ohl+8aGZ1lEI4XkcVdZ0JCkdtrxrOoA0tynYDTwvIqsEhcKV82DUXa5N+Ha9L4Wfv22KOL18CRQ30uVTCGGtM1XWdCRpMFSVmhYDDyRJ30rdzoPZH0BFAbwyCYr2Wh2REKK+I/tslTWb0J5vd3Jkrme26/tE0j9acYKici/tBpk6Aq77BE5UmMR/eLvVEQkh7HJslTXPNCiroYTeZlpWD23X9/qkX15Vw5h/LuP5VZ75VapJkgbBDUsABa9e6jVzbQrh83LWmftvCX2avk5gkKmv76F/x16f9KNCgxjbI4G3Mw5SWV1rdTgt17433LjE1Pp/bQrs/87qiIQQZ6us6UhSuinQVlvjkrBaw+VJXykVqJTaoJT61FX7mD2yM0ePVbN4i2eXND2rdl3hxs8hugO8fpXpzy+EsEZTKms6kjzY1Okq3OX8uFrJHVf69wA7XLmDUd3i6BofyRtrfGCu2thk09QT192MBt78jtURCeGfmlJZ0xEPLrPs0qSvlEoBLgNedPF+mDmiM+sPFLMtt8SVu3KPqAS4/hNIORfevxmW/a1ZE7kLIZygKZU1HWnXDUJjPLJd39VX+k8ADwAOM5ZSao5SKkMpldGa8snTBqcQFhzAG2s8t9BRs4S3hdkfQvosWPWoKdQm9XqEcJ+mVtZsTECAuZnrT1f6SqnJQL7Wet2ZltNaP6+1Hqq1HpqQkNDi/cVGBDNlYBIfbcyhtNIJUyB6gqAQU4r5ov8H2z82XTpLc62OSgj/kJNhrvJbWiI5eTAc3go1J5wbVyu58kp/NDBFKZUFLALOV0q94cL9MWtEZ46dqOWD9Tmu3I17KQWjfgnXLoKiTHjhfI+8ehDCpxw7YgZmJbfgJq5dUrq5J5C/zXlxOYHLkr7W+iGtdYrWOg2YASzTWs9y1f4ABqS0YUBKLG+s2e97c872ugRu+tJU8Ht5Emz70OqIhPBdJytrtibpDz59Wx7C6/vpNzRrRGf25Jez9kcfrF6Z2A9uWQYdzjHF2lY+2qRJ14UQzdScypqOtEk182R72DdztyR9rfUKrfVkd+zr8gFJxIQF+Ub3zcZEJZiyDQOugeV/g/dvgepKq6MSwrc0t7JmY5Qy7fr+mPTdKTwkkJ8N7cQX2w6RX+ajyTA4DK58Ds7/A2x5x8wBUHbY6qiE8A0tqazpSFI65O/wqJ53Ppf0AWYOT6W6VvP2Dz5crlgpGHcfTH8d8rebG7yHtlgdlRDeryWVNR1JGgy61qP+Nn0y6XdNiGJM93jeXHuA2jofb/PuO8WM4NV18NLFsHOx1REJ4d1aUlnTEQ8cmeuTSR9g1ohUcksqWbYz3+pQXC9pkLnBm9DTTLr+zRNyg1eIlsrOaH5lTUdiOkJ0R4+qre+zSf+CPokkxoT67g3dhmI6wvWLod8VsPRP8NGdpmCUEKJ5ctaZK/TmVtZ0JCldrvTdISgwgGuHpbJydwH7iyqsDsc9QiLg6pdh/IOwcQHMvwIqiqyOSgjvYa+smTzYedtMGgyFe6Cy1HnbbAWfTfoAM85NJTBA8eZaH6nH0xQBAXDeQ3D1S+aK5YXzIH+n1VEJ4R1aU1nTkaR0QEPeJudtsxV8Oul3iA3jor6J3j/BSkucMw1uWAzVx+HFifDVX+WqX4izaU1lTUc8bM5cn076YEbo+sQEKy2RMhTmLIdu58PX/4Yn+sPnv5WibUI40prKmo5ExpnRuR7Sru/zSX9Utzi6JvjIBCstEZsC17wOd66FvlNh7Tz470D45B7TH1kIcUprK2s6kjTYY2rw+HzSV0oxc7gPTbDSUgm94Mp5cPd6SJ8NGxfCU0PgvVvMiEEh/J0zKms6kpQOxfvNPizm80kffHCCldZomwaTH4e5m2HknbDzM3h2BCya6TFXIkJYwv75d2Z7vp29N5AHtOv7RdK3T7Dy4QYfmmCltaI7wEV/g3u3wvjfQNbXpqfP61dC1jcyuEv4H2dU1nSk40DbPqxv1/eLpA/mhu7xah+bYMUZItrBeb+FuVvhgodNl7VXL4OXL4HdX0ryF/7DXlkzNNr52w6LhbgeHnEz12+S/oCUNgz01QlWnCEsBsbMNc0+lz4GpTnw5s/guXFmwpY6P+vyKvyLMytrOpKULs077jbTlydYcZbgcBh2C9y1HqY+A9XHzIQtzwyHze9YHZ0QruHMypqOJA+Gsjwotbb7uF8l/csHJBEbHuy/3TebIygE0mfBnd/DtFcgKAzevxm+e8rqyIRwPmdW1nTEQypu+lXSDw8JZNqQFD7f6sMTrDhbQCD0vwpuXWn6+X/5e9PdUwhf4szKmo50GAAqQJK+u80cnkpNnY9PsOIKAYFw1QvQdYKp4LlridURCeE8ORnOrazZmBDbScXidn2/S/p+NcGKswWFwjVvmO5n71wP+7+zOiIhWq+mysxs5YpBWQ0l28osW9iZxO+SPvjZBCvOFhoNM9+B2E7w5gzTxVMIb2avrOnK9ny7pHQ4VgTF1g0U9cuk73cTrDhbZDzM/gBCIuGNq+DIj1ZHJETL2StruuNKP8k+Mte6dn2/TPp+OcGKs7XpZBJ/7QkzirfssNURCdEyrqis6UhiPwgItrRd3y+TPsC1w/xwghVna98bfv4OlB+GN66GSj8uaCe8l6sqazYmKBQ69JcrfSskxvjxBCvO1OlcU7q5YAcsvNZM2iKEt3BlZU1HktIhdyPU1blvn/X4bdIHP59gxZm6XwBXPmd687x7E9TWWB2REE3jjkFZDSUNhqpSy+az8Oukb59g5XW5odt650yDSf+CXZ/Bp/dIoTbhHbJdWFnTEYunT/TrpG+fYGWDv0+w4izD55gyzRvegKV/sjoaIc4uZx207+OaypqOJPSGoHDL2vX9OumDTLDidBMegnNvhm//C98+aXU0Qjhmr6zpzvZ8MKN+Ow6wbNIiv0/6MsGKkyllmnn6XQn/+wNsWGB1RMJqlaWw7G+w+wuo9aC/sZOVNd2c9MG06x/abMn9L79P+gCzR6TJBCvOFBBobux2nQAf3wU7F1sdkbBKbY0p2bHqUXhzOvy7Nyx+ALLXWX/fx4qbuHZJ6aZseeEut+9akj5wTkosA1NieV0mWHGeoFC4ZoGp0/PuDZD1rdURCXfTGpY8AHu/gsseh2sXQdoYWPcqvHg+PDUEVvzTuhHd7qis6UiydSNzJenbzBzRmcz8ct764SB1UojNOUKjYOa70CYVFs4wRa1a6sQx07d589vw1V/MRO4f3w0VhU4LVzjZmv+DjJdg9D1w7k3QaxJMfw3u3wNTnoaYJFjxD3hyELx0Efzwouk37y7uqKzpSLtuEBpjSbu+8qQr26FDh+qMjAxL9l1ZXcsVz3zLzkNl9EyM4o4J3Zk8oCNBgXJebLXig/DyxaY996YvoF1Xx8tWlkDBbvO1t2AnFOwyP8UHANtnNSDIbONolpl7dPIT0GeyG96IaLJdS8xgvT6T4WfzIcDB31FJNmx5Bza9ZQb4BQRDj4tgwHToeQkEh7kmvpoq+EcKDL8NLvqra/ZxNq9OhhMVMGd5qzajlFqntW5yG5Uk/Xpqauv4bEsezyzPZPfhclLbRXDb+G5cPSSZ0KBAy+LyCQW7TOIPi4UbvzSJu2FiL9gFZbmn1gkMhfiekNDTdHNL6AXxvUzCDwqBw9vhg1vNDbEBM2DSIxDe1rr3KIy8TfDyJPP/dv1iU0f+bLSGw1th0yLY8i6UH4LQWOg7BQbOgNRRjk8cLZG9zjQxTZ9vJgeywpd/gLXz4KEc83luIUn6TlBXp1m64zDPLM9kU3YJHWLCuGVcV64d1omIEAu+CvqK7Ax4bQrUVZtCbXbBkSahn/zpbZJ92zRzU/hMaqth1WPw9WMQmWCaDXpc4NK3Ic6gNBdemGhmiLrlK4ju0Pxt1NXCj6tMU96Oj+FEOcSkwICfQf9p0L5v608Aa58z9xvu3Q6xbii01phtH5ib3HNWtGpwmMckfaVUGLAKCAWCgHe11mccseMpSd9Oa803mYU8vSyTtT8eoV1kCDeN6cLskZ2JCQu2OjzvdGCNuZJr1+XUlXtsSuuLXeVugA9uN00EQ66Hi/7m3gE3AqrK4ZVJpivkjV+YwmKtdeIY7FoMm9+CzK9A15q28A4DIGmQ6SjQcRDEdTv7BUJ9790CWV/Dr3e2PsaWOpoF/x1obnKfe1OLN+NJSV8BkVrrcqVUMPANcI/Weo2jdTwt6deXkXWEp5dnsmJXAdGhQfxiVGduHN2FuKhQq0MTdtWVsOLvZvL22BSY+ix0GWt1VP6hrhbemgW7P4dr34KeFzl/H+UFZvt5G81N/cNbocY213VwpBnwZD8JdBxovi06ukn7ZLr5xjDDwnEkWsO/ukLvy2Dq0y3ejMck/dN2olQEJunfrrVe62g5T076dltzSnh2RSZLth4iLCiQa4elMmdcVzrEuuiGk2i+A2vhw9vMFefw22Din5rWrixa7ovfweqnYdKjphyHO9TWmPtCeZvMSSBvk7m/U33MvB4Ubr5t2E8CSYNM02FVGfyri/lcjP2Ve2J15PWrTGny21vepdmjkr5SKhBYB3QHntFa/6aRZeYAcwBSU1OH7N/vHcXPMvPLeHbFXj7amEugUlw9JIXbxnelc1yk1aEJML0ilj4M3z9nusddOQ86DbM6qrPT2j113Z0p42X49F4Yditc+i9rY6mrhaLMUyeBvI2QtxlOlJnXA0PNBEBFmXDdJ9BlnJXRmpHKXz8OD2W3+MLEo5L+yZ0o1Qb4ALhLa+1wUlVvuNJv6OCRY8xbuZd3MrKpqatjysAk7jivOz0TpT3ZI+xbCR/9EkqzYdTdcN5vzcAxT5O3CTJeMd0X23aB8fdD78ud22PFFfYugzemQfeJMGOhNX3ez6auznzry9to+9lk5n34xcfWfwPc+Rks+rnp0ZY6vEWb8MikD6CU+hNQobV+zNEy3pj07Q6XVvLi1/tYsPYAx07UcvOYLtx/SS/p6ukJKkvhy9/D+tfM6Msr55mv+lY7UQFb3zdXyrnrISgMek82iako07Q5j38A+kz1zOSfv8MMqortZMZfyI3z5ivNg8d7wyX/hBG3tWgTHpP0lVIJQLXWulgpFQ58CfxTa/2po3W8OenbHa04wb//t4s31hygf3IMT85Ip2tClNVhCYA9/zO1gCoKYNz9MPbXEGhBL6zD28xV/ea3zGQa8b1g6A2mP3p4W9NEsfV9WPUvKNxt2qHH3W+K2DWnh4orleebrpm1VXDzV6bJRLTMY72g63i46vkWre5JSX8A8BoQiCn38LbW+i9nWscXkr7dl9sO8cB7mzlRU8dfp/bnqsHJKG9rq/VFx4/Ckt+YhNtxIFwxDxL7un6/1cdNv+yMVyD7e9O23HeqSfapIxtvx6+rNeusetQMYovvZZJ//6usTf7Vx+G1y+HQVrjhM2uqVPqShdeab3a//KFFq7sk6Sul7gFeAcqAF4F04EGt9ZctitIBX0r6AHklx5m7aCNrfzzCFYOS+OsV/YmW/v2eYfvH5uZjVSmkz4LEfhDXw3Tzi+7gvJup+Tth3SuwaaEpMRHXHYbcAIN+DhHtmraNujrY/iGs/JcZhxDXw5b8r3Z/G3pdHbx3E2x7H6a/bkbMitbZ8IYZZzLp0RY147kq6W/SWg9USl0M3An8AXhFaz242RGega8lfYDaOs0zyzN5YuluUtpG8OS16Qzq1MbqsASYft+f/wZ2fQ7VFaeeD4mG+O7mBBDf49TJoF3XptWCqa6E7R+ZZH9gtakn03eKSfZpY1p+QqmrMyNUV/4L8reZXknj7odzfua+5L/sb+abxwUPw5i57tmnOCNXJf3NWusBSqn/Aiu01h8opTZorZ06saQvJn27jKwj3LNoI4dLK7nv4l7MGduVgABp7vEIWpvyAYW7zdfswt1QuMf8lGafWk4FmIqh8T1tJ4Iep04MkQlm3XWvwsYFphmpXVczOnjQTIiMd168dXVmLuKV/zSVS9t1hbH3wYBrXJv8Ny404x/SZ8OUp7yva6mPclXSfwVIBroAAzHt9Cu01k5tzPPlpA9QcqyaB9/fzJKthxjbI55/Tx9I+2gZ1OXRTlTYTgR7Tj8ZFO05NRoUTGmAqlJTSK73ZNNWnzbOtb1utDYlClY8YgYltU0zyX/gDOffoM76FuZPhc4jYeZ7rSoQJpzLVUk/ABgE7LP1xmkHpGitN7c40kb4etIHU89n0Q8HefiTbUSGBPHY9IGc16u91WGJ5qqrM98C6p8IYlPMVX10ontj0dqUJ1jxiOnu2SbV9Ezqeh5EtYfg8NZtv2gvvDjRfJu56UupZOphXJX0RwMbtdYVSqlZwGDgv1prpw6f9Yekb7fncBl3LdzAzkNl0qdfOIfWsOdLk/xz603OERINUQkQ2b7eb9uP/XFkgvkd0mBE+bEj8OIFUFkMNy8981wIwhIua9PHNOsMAF4HXgKu0lqPb2mgjfGnpA9m4pa/L97B/NX7pU+/cB6tTTXTokyoyDc3rCvyTd/68nzz+PjRxtcNjjz9xHB0v6lvc90nkDrCve9DNImrkv56rfVgpdQfgRyt9Uv251oTbEP+lvTtpE+/cLvaajNIrTy/3u8GJ4iKAlPL/oKHzdgA4ZGam/Sbequ/TCn1EDAbGGsrpCYdzp3kon4dOCcllrmLNvLrdzbx9Z4C6dMvXCsw2MxRG5NkdSTCzZrateAaoAq4UWt9CNOT51GXReWHOsaG8+YtI/jVhT35eFMulz35DRsPFlsdlhDCxzQp6dsS/QIgVik1GajUWs93aWR+KDBAcffEHrx960hq6zTT/u87/vrpdkqOVVsdmhDCRzQp6SulpgPfAz8DpgNrlVLTXBmYPxua1o7Fd49l2pAUXv72RyY8tpz5q7Ooqa2zOjQhhJdrchkG4EKtdb7t3wnAUq31QGcG4683cs9ke24pf/10O6v3FdGjfRS/u6wPE6RfvxDCprk3cpvaph9gT/g2Rc1YV7RC36QY3rxlOM/PHkJ1bR3Xv/ID17/yPZn5ZVaHJoTwQk3tvfO5UuoLYKHt39cAi10TkmhIKcVF/TowoVd75q/O4r9f7eHiJ75m1vBU5l7Qk7aRMiReCNE0Ta6nr5S6GhgNKGCV1voDZwcjzTtNc6TiBP/5327e/P4AkSGB3D2xB78YmUZIkHz5EsLfeMwkKi0hSb95dh8u42+f7WDV7gK6xEfyu0v7MLFPexnYJYQfcWqbvlKqTClV2shPmVKqtPXhitbomRjN/BuH8coN5xKg4Ob5Gcx6aS078uS/RgjROLnS9xHVtXW8ufYA/1m6m9Lj1Vxzbiq/vqgn8VGhVocmhHAhV/XeER4uODCA60alsfK+87h+VBfeyTjIhEdXMG/lXqpqaq0OTwjhISTp+5jYiGD+eHlfvrh3HCO6tuORJTu54PGVfLY5D0/6VieEsIYkfR/VLSGKF687lzduGk5kSBB3vrmeafNWs/6Ag5K6Qgi/IEnfx43pEc9nd4/lkavO4cCRY1z17HfctXADB48cszo0IYQF5EauH6moquG5lXt5/ut91Gm4YXQad57XnRgp4SyE15IbucKhyNAgfnVRL5bfN4HJAzry3Mp9THh0Ba9LMTch/IYkfT/UMTacx6cP4tO7xtAzMYo/fLSNi59YxbKdh+VmrxA+TpK+H+ufHMvCW0bw/OwhaA03vmoGd23PlcFdQvgqSfp+zl7M7Yt7x/Hny/uyLbeUy576mvvf2cTh0kqrwxNCOJkkfQGYwV3Xj+7CyvvO4+YxXfhwYw4THl3BE0t3c+xEjdXhCSGcRJK+OE1sRDC/u6wvX/1qAuf3bs8TS/dw3mMreDvjILV10t4vhLeTpC8alRoXwTMzB/PubSPpGBvOA+9uZuoz37DrkEzeIoQ3k6QvzmhoWjs+uGMU/50xiEMllVz+9De8+u2P0stHCC8lSV+clVKKqYOS+XzuOEZ3i+PPn2znhld/oKCsyurQhBDNJElfNFl8VCgvX38uf5naj9V7i7jE1rdfCOE9JOmLZlFK8YuRaXxy1xgSokO58dUM/vjRViqrpXyzEN5Akr5okZ6J0Xz0y9HcNKYL81fv5/KnvpFBXUJ4AUn6osVCgwL5w+S+zL9xGMXHq7nimW958et91EnXTiE8lsuSvlKqk1JquVJqh1Jqm1LqHlftS1hrXM8Evpg7jvG9EvjbZzu47pXvyZfRvEJ4JFde6dcAv9Za9wFGAHcqpfq6cH/CQu0iQ3h+9hD+fuU5/JB1hIufWMWX2w5ZHZYQogGXJX2tdZ7Wer3tcRmwA0h21f6E9ZRS/Hx4Kp/eNZbktuHMeX0dv/1gi5RxEMKDuKVNXymVBqQDaxt5bY5SKkMplVFQUOCOcISLdW8fxfu3j+bW8V1Z+P0BJj/1DVtzSqwOSwiBG5K+UioKeA+Yq7X+SfcOrfXzWuuhWuuhCQkJrg5HuElIUAAPTerDgpuGc6yqliuf/ZbnVu6Vm7xCWMylSV8pFYxJ+Au01u+7cl/CM43qHs/nc8dyQZ9E/rFkJ7NeWkteyXGrwxLCb7my944CXgJ2aK0fd9V+hOdrExHCszMH86+rB7DxYDEXPr6Kx77YRfGxE1aHJoTfceWV/mhgNnC+Umqj7edSF+5PeDClFNPP7cTiu8cyvmcCTy/PZMw/l/PoFzs5WiHJXwh3UZ5ULXHo0KE6IyPD6jCEG+w6VMaTy/aweEseEcGBXD86jZvHdKVtZIjVoQnhVZRS67TWQ5u8vCR9YaXdh8t48qs9fGZL/teNSuPmsV1pJ8lfiCaRpC+8Uv3kH25L/rdI8hfirCTpC6+253AZTy7L5NPNuYQHB/KLkWncMrYLcVGhVocmhEeSpC98wp7DZTy1LJNPJPkLcUaS9IVPycw3yf/jTSb5zx7ZmTlju0ryF8JGkr7wSfbk/8mmXEKDAvnFyM7cMq4r8ZL8hZ+TpC98WmZ+OU8v28PHm3IJCgxg8jkdmTWyM+md2mDGAwrhXyTpC7+wt6Cc177L4v31OZRX1dC3YwyzR3Zm6qAkIkKCrA5PCLeRpC/8SnlVDR9uyOGNNfvZeaiM6LAgrh6cwqwRnenePsrq8IRwOUn6wi9prVm3/yivr9nP4i15VNdqRnWLY9aIzlzYN5HgQJkZVPgmSfrC7xWWV/HWDwd5c+0BcoqP0z46lGuHpXLtsFQ6xIZZHZ4QTiVJXwib2jrNil35vL5mPyt3FxCgFBf1TWT2iM6M7BYnN36FT2hu0pc7XsJnBQYoJvZJZGKfRPYXVfDm2gO8lXGQJVsP0TUhklnDO3P1kBRiw4OtDlUIt5ErfeFXKqtrWbwlj9fX7GfDgWLCggO4Zmgn7p7YQwZ8Ca8kzTtCNNHWnBLmr87ivfU5RIQEctf53bluVBqhQYFWhyZEk0nSF6KZMvPL+PvinSzbmU+nduE8NKkPk/p3kDZ/4RWam/SlH5vwe93bR/Py9efy+k3DiAwJ4o4F65n+3Go2HSy2OjQhnE6SvhA2Y3sk8NndY/nHVefwY2EFU5/5lnvf2khusUzkLnyHJH0h6gkMUFw7LJXl903gjgnd+GxLHuf/ewWPf7mLiqoaq8MTotUk6QvRiOiwYB64pDfLfj2eC/t24MllmUx4bAVv/3CQ2jrPuQ8mRHNJ0hfiDFLaRvDUtem8d/soUtqG88B7m7n8qW/4LrPQ6tCEaBFJ+kI0wZDObXn/9lE8eW06Jcer+fmLa7n5tQz2FZRbHZoQzSJJX4gmUkoxZWASX/16PA9c0os1+4q46D+rePiTbRQfO2F1eEI0iSR9IZopLDiQOyZ0Z/l9E5h+bide+y6L8Y+uYP7qLOqkvV94OEn6QrRQQnQof7/yHBbfM5b+yTH88aNtTH9uNZn50uQjPJckfSFaqXeHGN64aTj//tlA9uSXc+l/v+aZ5ZlU19ZZHZoQPyFJXwgnUEpx9ZAUlv5qPBf2TeTRL3Yx5elv2ZpTYnVoQpxGkr4QTpQQHcozMwczb9YQCsurmPrMtzyyZCeV1bVWhyYEIElfCJe4pH8Hlt47nmmDU5i3ci+T/vs1a/cVWR2WEJL0hXCV2Ihg/jltAAtuHk5NXR3XPL+G33+4hbLKaqtDE35Mkr4QLja6ezxfzB3HzWO68ObaA1z0n1Us23nY6rCEn5KkL4QbRIQE8fvJfXnv9lFEhwVx46sZ3LNoA0XlVVaHJvyMJH0h3Cg9tS2f3jWWuRf0YPGWPC78zyo+2piDJ01mJHybJH0h3CwkKIC5F/Tk07vG0qldBPcs2sjNr2WQVyJ1+4XrSdIXwiK9OkTz/u2j+P1lffh2byEXPr6KBWv3SykH4VIyR64QHuBA0TEefH8z3+0tol1kCOmd2pCe2oZBndoyoFMsMWHBVocoPFRz58gNcmEgLwOTgXytdX9X7UcIX5AaF8GCm4fz6eY8Vu4uYMOBo3y1Mx8ApaBH+ygGdWpDempb0lPb0KN9NIEBMnG7aD6XXekrpcYB5cD8piZ9udIX4pSS49VsOljMhgPFbDx4lA0Hiyk+Zvr4R4YEMiDF/m3AnAwSokMtjlhYwWOu9LXWq5RSaa7avhC+LjY8mHE9ExjXMwEArTX7i46x4eBR24mgmOdX7aPGdg8gpW046altbSeBNvRoH0W0NAuJBlyW9JtKKTUHmAOQmppqcTRCeC6lFGnxkaTFR3JlegoAldW1bM0pOXkSWJd1hE825Z5cJz4qhM5xkXSOiyCt3u+0uEhiI+SE4I9ceiPXdqX/qTTvCOE+h0sr2XiwmH0FFewvqiCrqIL9RcfIK6k8bbk2EcF0joskLS7iJ7/bRYaglNwz8AYe07wjhLBGYkwYF/fr8JPnK6trOXDkGFmF5iRgPxms23+UTzblUr+naHRoEJ3jzbeCywcmcWGfRALkxrFPkKQvhJ8ICw6kZ2I0PROjf/JaVU0t2UePs992IrCfFL7/8Qifbs6jW0Ikt47rxtT0JEKDAi2IXjiLK3vvLAQmAPHAYeBPWuuXzrSONO8I4VlqautYvPUQ81bsZXteKYkxodw4ugs/H54qN4k9RHObd2RwlhDirLTWfJNZyLyVe/k2s4jo0CBmjujMjaPTaB8TZnV4fk2SvhDCpTZnF/Pcyn0s2ZpHUEAAVw9J5paxXemaEGV1aH5Jkr4Qwi2yCit44et9vLMum+raOi7u24Fbx3clPbWt1aH5FUn6Qgi3Kiir4rXvspi/OovSyhqGd2nHbRO6MaFngnT7dANJ+kIIS5RX1bDo+wO89M2P5JVU0rtDNLeO78rkAUkEB0pBX1eRpC+EsNSJmjo+3pTLcyv3sie/nOQ24dwwOo2+HWOIjw4lPiqUNuHB0u/fSSTpCyE8Ql2dZvmufOat3MsPWUdPey0wQNEuMoT4qFDio079josyJ4W4qBASbI/bRYYQEiTfFByREblCCI8QEKCY2CeRiX0SySqsILfkOIXlJygqr6KwvIqi8hMUlldRUH6CHwsrKCyvorK6rtFtxYYHEx8VQkJ0KF3io+je/tRPUmyY3DtoBkn6QgiXsxeKOxOtNcdO1FJoOykU2k4K9pNDYXkVh0oqWbI172SJaYCIkEC6JZgTQLeEyJMng85xkXIvoRGS9IUQHkEpRWRoEJGhQXSOc3yC0FpTVHGCzPxyMvPL2Vtgfq/dV8QHG3JOLhcUoOgcF2E7GZz6ZtAtIYrIUP9Nff77zoUQXkkpZbsHEMqIrnGnvVZRVXPyJGD/2ZNfztId+dTWqyjXPjqUthEhxIYHExMeTGy9n5jwoNP+fer5YMKCvb/ukCR9IYTPiAwNYkBKGwaktDnt+RM1dRw4UnHyRLC/6Bglx6spOV5N9tFjbM81jytO1J5x+6FBAaedCOKiQrzuW4RnRyeEEE4QEhRA9/bRdG//0wqj9VXX1lFqOxmUVtacPDGUHK8++XzJsVPPZeaX89WO/JOzlwEkxYbRPTGa7gmn33BuFxni6rfZJJL0hRDCJjgwgLioUOKimj7fcHVtHfuLKn7SpPT9j0Wn9UaKiwyhm/0kYDsh9EiMokOMe3sfSdIXQohWCA5s/FtEXZ0mp/g4mQXl7K13Mvhscx4lx0/1PooKDaJvxxjeunWEW5K/JH0hhHCBgABFp3YRdGoXwXm92p98XmtNYbmt95HthFBZXeu2q31J+kII4UZKKRKiQ0mIDmVkt7izr+BkMnJBCCH8iCR9IYTwI5L0hRDCj0jSF0IIPyJJXwgh/IgkfSGE8COS9IUQwo9I0hdCCD/iUdMlKqUKgP0tXD0eKHRiOO7gbTF7W7wgMbuLt8XsbfGC45g7a60TmroRj0r6raGUymjOPJGewNti9rZ4QWJ2F2+L2dviBefFLM07QgjhRyTpCyGEH/GlpP+81QG0gLfF7G3xgsTsLt4Ws7fFC06K2Wfa9IUQQpydL13pCyGEOAtJ+kII4Ue8KukrpS5RSu1SSmUqpR5s5HWllHrS9vpmpdRgK+KsF08npdRypdQOpdQ2pdQ9jSwzQSlVopTaaPv5oxWxNogpSym1xRZPRiOve9px7lXv+G1USpUqpeY2WMby46yUelkpla+U2lrvuXZKqf8ppfbYfrd1sO4ZP/tujvlRpdRO2//9B0qpNg7WPePnyI3x/lkplVPv//5SB+t60jF+q168WUqpjQ7Wbf4x1lp7xQ8QCOwFugIhwCagb4NlLgWWAAoYAay1OOaOwGDb42hgdyMxTwA+tfr4NogpC4g/w+sedZwb+ZwcwgxY8ajjDIwDBgNb6z33L+BB2+MHgX86eE9n/Oy7OeaLgCDb4382FnNTPkdujPfPwH1N+Nx4zDFu8Pq/gT866xh705X+MCBTa71Pa30CWARMbbDMVGC+NtYAbZRSHd0dqJ3WOk9rvd72uAzYASRbFY8TedRxbmAisFdr3dKR3S6jtV4FHGnw9FTgNdvj14ArGlm1KZ99l2gsZq31l1rrGts/1wAp7oilKRwc46bwqGNsp8zEudOBhc7anzcl/WTgYL1/Z/PTBNqUZSyhlEoD0oG1jbw8Uim1SSm1RCnVz72RNUoDXyql1iml5jTyusceZ2AGjv9APO04AyRqrfPAXCQA7RtZxpOP942Yb32NOdvnyJ1+aWuOetlBE5qnHuOxwGGt9R4Hrzf7GHtT0m9sqviG/U2bsozbKaWigPeAuVrr0gYvr8c0RQwEngI+dHN4jRmttR4MTALuVEqNa/C6px7nEGAK8E4jL3vicW4qTz3evwNqgAUOFjnb58hd/g/oBgwC8jDNJQ155DEGruXMV/nNPsbelPSzgU71/p0C5LZgGbdSSgVjEv4CrfX7DV/XWpdqrcttjxcDwUqpeDeH2TCmXNvvfOADzFff+jzuONtMAtZrrQ83fMETj7PNYXvTmO13fiPLeNzxVkpdB0wGZmpb43JDTfgcuYXW+rDWulZrXQe84CAOTzzGQcBVwFuOlmnJMfampP8D0EMp1cV2RTcD+LjBMh8Dv7D1LhkBlNi/OlvB1h73ErBDa/24g2U62JZDKTUM839S5L4ofxJPpFIq2v4Yc9Nua4PFPOo41+PwqsjTjnM9HwPX2R5fB3zUyDJN+ey7jVLqEuA3wBSt9TEHyzTlc+QWDe43XekgDo86xjYXADu11tmNvdjiY+yOu9NOvMt9KaYHzF7gd7bnbgNusz1WwDO217cAQy2OdwzmK+JmYKPt59IGMf8S2IbpLbAGGGVxzF1tsWyyxeXxx9kWUwQmicfWe86jjjPmhJQHVGOuLG8C4oCvgD223+1syyYBi+ut+5PPvoUxZ2Lav+2f6XkNY3b0ObIo3tdtn9PNmETe0dOPse35V+2f33rLtvoYSxkGIYTwI97UvCOEEKKVJOkLIYQfkaQvhBB+RJK+EEL4EUn6QgjhRyTpC+EEylTx/NTqOIQ4G0n6QgjhRyTpC7+ilJqllPreVn/8OaVUoFKqXCn1b6XUeqXUV0qpBNuyg5RSa+rVjW9re767UmqprXjbeqVUN9vmo5RS7ypTa36BfQSwEJ5Ekr7wG0qpPsA1mCJVg4BaYCYQianZMxhYCfzJtsp84Dda6wGYEZ325xcAz2hTvG0UZjQlmCqqc4G+mNGSo138loRotiCrAxDCjSYCQ4AfbBfh4ZgCZ3WcKmr1BvC+UioWaKO1Xml7/jXgHVutk2St9QcAWutKANv2vte2Oim2mY7SgG9c/q6EaAZJ+sKfKOA1rfVDpz2p1B8aLHem2iRnarKpqve4Fvn7Eh5ImneEP/kKmKaUag8n56ftjPk7mGZb5ufAN1rrEuCoUmqs7fnZwEpt5kPIVkpdYdtGqFIqwp1vQojWkCsR4Te01tuVUr/HzDQUgKlqeCdQAfRTSq0DSjDt/mBKHc+zJfV9wA2252cDzyml/mLbxs/c+DaEaBWpsin8nlKqXGsdZXUcQriDNO8IIYQfkSt9IYTwI3KlL4QQfkSSvhBC+BFJ+kII4Uck6QshhB+RpC+EEH7k/wOxTPAbQFtF+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_extra_all_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_sae_extra_all_v1_13_2.72254.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.4369918220544577"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.741935  , 0.9469486 , 1.2410445 , 1.4512296 ],\n",
       "       [0.37045714, 0.37638783, 0.3817736 , 0.33020377],\n",
       "       [0.48215064, 0.29127306, 0.5612965 , 0.48565015],\n",
       "       ...,\n",
       "       [0.16529885, 0.61763346, 0.22851908, 0.47713977],\n",
       "       [0.07259187, 4.4508405 , 2.6225014 , 4.420766  ],\n",
       "       [0.48304194, 0.6168254 , 0.56537396, 0.76549065]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/stacked_decoder_extra_all_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3362455e-02, 4.0933874e-06, 1.1170047e-04, ..., 1.8352528e-10,\n",
       "        8.4741798e-04, 1.9566578e-05],\n",
       "       [2.2033405e-02, 6.1040849e-04, 4.6552290e-05, ..., 3.3421453e-05,\n",
       "        4.4074051e-05, 1.9556167e-06],\n",
       "       [5.8846240e-04, 5.3943802e-07, 4.0277669e-07, ..., 2.8321409e-11,\n",
       "        3.5925660e-07, 8.8841441e-09],\n",
       "       ...,\n",
       "       [2.5878819e-03, 1.3397194e-03, 5.2895083e-04, ..., 1.0770562e-03,\n",
       "        1.0984204e-03, 1.6893425e-04],\n",
       "       [9.3331619e-06, 1.0216236e-02, 4.2298799e-03, ..., 7.4678183e-06,\n",
       "        4.4178680e-02, 2.2806285e-02],\n",
       "       [1.0705745e-02, 2.3602915e-05, 4.8792802e-04, ..., 9.8637621e-08,\n",
       "        6.1543047e-04, 2.7563197e-05]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>가족건강성</th>\n",
       "      <th>간호</th>\n",
       "      <th>간호대학생</th>\n",
       "      <th>간호사</th>\n",
       "      <th>감정</th>\n",
       "      <th>감정노동</th>\n",
       "      <th>개인정보</th>\n",
       "      <th>개인정보보호</th>\n",
       "      <th>개인정보보호법</th>\n",
       "      <th>...</th>\n",
       "      <th>한류</th>\n",
       "      <th>한반도</th>\n",
       "      <th>한중</th>\n",
       "      <th>해외직접투자</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>행복감</th>\n",
       "      <th>현상학</th>\n",
       "      <th>확인적요인분석</th>\n",
       "      <th>회복탄력성</th>\n",
       "      <th>희망</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4차산업혁명  가족건강성  간호  간호대학생  간호사  감정  감정노동  개인정보  개인정보보호  개인정보보호법  ...  한류  \\\n",
       "0         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "1         0      0   0      0    1   0     0     0       0        0  ...   0   \n",
       "2         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "3         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "4         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "..      ...    ...  ..    ...  ...  ..   ...   ...     ...      ...  ...  ..   \n",
       "927       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "928       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "929       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "930       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "931       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "\n",
       "     한반도  한중  해외직접투자  핵심역량  행복감  현상학  확인적요인분석  회복탄력성  희망  \n",
       "0      0   0       0     0    0    0        0      0   0  \n",
       "1      0   0       0     0    0    0        0      0   0  \n",
       "2      0   0       0     0    0    0        0      0   0  \n",
       "3      0   0       0     0    0    0        0      0   0  \n",
       "4      0   0       0     0    0    0        0      0   0  \n",
       "..   ...  ..     ...   ...  ...  ...      ...    ...  ..  \n",
       "927    0   0       0     0    0    0        0      0   0  \n",
       "928    0   0       0     0    0    0        0      0   0  \n",
       "929    0   0       0     0    0    0        0      0   0  \n",
       "930    0   0       0     0    0    0        0      0   0  \n",
       "931    0   0       0     0    0    0        0      0   0  \n",
       "\n",
       "[932 rows x 262 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/all_10_random_12000_262_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(932, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.028969957081545063\n",
      "precision :  0.5315315315315315\n",
      "recall :  0.0445619335347432\n",
      "f1 :  0.08222996515679441\n",
      "------------------------\n",
      "hamming_loss :  0.005393473773875438\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.028969957081545063\n",
      "precision :  0.0611587982832618\n",
      "recall :  0.043097281831187405\n",
      "f1 :  0.04785407725321888\n",
      "------------------------\n",
      "hamming_loss :  0.005393473773875438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
