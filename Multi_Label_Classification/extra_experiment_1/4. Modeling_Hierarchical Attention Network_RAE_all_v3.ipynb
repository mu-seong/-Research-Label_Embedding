{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7839317952257454314\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12949652855889779167\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4985044352\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15724555124582382066\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13915240336807231873\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('./data/rae_extra_all_v4_train.xlsx')\n",
    "val = pd.read_excel('./data/rae_extra_all_v4_val.xlsx')\n",
    "test = pd.read_excel('./data/rae_extra_all_v4_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...</td>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...</td>\n",
       "      <td>2.523835</td>\n",
       "      <td>3.260611</td>\n",
       "      <td>1.669686</td>\n",
       "      <td>3.370940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...</td>\n",
       "      <td>0.930321</td>\n",
       "      <td>0.542420</td>\n",
       "      <td>1.852430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...</td>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...</td>\n",
       "      <td>4.333861</td>\n",
       "      <td>3.978497</td>\n",
       "      <td>3.662714</td>\n",
       "      <td>3.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2793</td>\n",
       "      <td>본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...</td>\n",
       "      <td>4.946594</td>\n",
       "      <td>8.686300</td>\n",
       "      <td>1.476334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2794</td>\n",
       "      <td>본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...</td>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2795</td>\n",
       "      <td>경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...</td>\n",
       "      <td>1.834378</td>\n",
       "      <td>1.115448</td>\n",
       "      <td>4.501013</td>\n",
       "      <td>3.099241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2796</td>\n",
       "      <td>본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...</td>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2797</td>\n",
       "      <td>본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...</td>\n",
       "      <td>1.561563</td>\n",
       "      <td>1.182006</td>\n",
       "      <td>2.323821</td>\n",
       "      <td>1.482143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract         0  \\\n",
       "0              0  본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...  5.194959   \n",
       "1              1  최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...  2.523835   \n",
       "2              2  글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...  0.930321   \n",
       "3              3  본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...  5.194959   \n",
       "4              4  본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...  4.333861   \n",
       "...          ...                                                ...       ...   \n",
       "2793        2793  본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...  4.946594   \n",
       "2794        2794  본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...  7.886700   \n",
       "2795        2795  경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...  1.834378   \n",
       "2796        2796  본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...  7.886700   \n",
       "2797        2797  본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...  1.561563   \n",
       "\n",
       "             1         2         3  \n",
       "0     0.463620  3.099519  1.837639  \n",
       "1     3.260611  1.669686  3.370940  \n",
       "2     0.542420  1.852430  0.000000  \n",
       "3     0.463620  3.099519  1.837639  \n",
       "4     3.978497  3.662714  3.577977  \n",
       "...        ...       ...       ...  \n",
       "2793  8.686300  1.476334  0.000000  \n",
       "2794  2.730818  1.936125  2.332378  \n",
       "2795  1.115448  4.501013  3.099241  \n",
       "2796  2.730818  1.936125  2.332378  \n",
       "2797  1.182006  2.323821  1.482143  \n",
       "\n",
       "[2798 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...</td>\n",
       "      <td>4.252167</td>\n",
       "      <td>2.948070</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>2.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...</td>\n",
       "      <td>4.448070</td>\n",
       "      <td>5.104998</td>\n",
       "      <td>1.674422</td>\n",
       "      <td>0.211541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...</td>\n",
       "      <td>4.941952</td>\n",
       "      <td>1.189352</td>\n",
       "      <td>0.948080</td>\n",
       "      <td>5.824813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...</td>\n",
       "      <td>7.061509</td>\n",
       "      <td>4.723454</td>\n",
       "      <td>1.920044</td>\n",
       "      <td>4.697660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...</td>\n",
       "      <td>2.117849</td>\n",
       "      <td>2.717265</td>\n",
       "      <td>1.860312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...</td>\n",
       "      <td>4.311187</td>\n",
       "      <td>1.612342</td>\n",
       "      <td>2.545564</td>\n",
       "      <td>1.304350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174629</td>\n",
       "      <td>5.023723</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...</td>\n",
       "      <td>3.285078</td>\n",
       "      <td>3.259609</td>\n",
       "      <td>2.390505</td>\n",
       "      <td>1.122444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...</td>\n",
       "      <td>2.872831</td>\n",
       "      <td>2.474819</td>\n",
       "      <td>1.055902</td>\n",
       "      <td>2.022084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...  4.252167   \n",
       "1             1  기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...  4.448070   \n",
       "2             2  본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...  4.941952   \n",
       "3             3  본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...  7.061509   \n",
       "4             4  오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...  2.356642   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...  2.117849   \n",
       "928         928  본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...  4.311187   \n",
       "929         929  한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...  2.356642   \n",
       "930         930  본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...  3.285078   \n",
       "931         931  본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...  2.872831   \n",
       "\n",
       "            1         2         3  \n",
       "0    2.948070  0.193734  2.841667  \n",
       "1    5.104998  1.674422  0.211541  \n",
       "2    1.189352  0.948080  5.824813  \n",
       "3    4.723454  1.920044  4.697660  \n",
       "4    6.174630  5.023724  1.891224  \n",
       "..        ...       ...       ...  \n",
       "927  2.717265  1.860312  0.000000  \n",
       "928  1.612342  2.545564  1.304350  \n",
       "929  6.174629  5.023723  1.891224  \n",
       "930  3.259609  2.390505  1.122444  \n",
       "931  2.474819  1.055902  2.022084  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...</td>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...</td>\n",
       "      <td>1.728056</td>\n",
       "      <td>2.490819</td>\n",
       "      <td>1.481277</td>\n",
       "      <td>0.309363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...</td>\n",
       "      <td>0.569367</td>\n",
       "      <td>2.411349</td>\n",
       "      <td>0.669784</td>\n",
       "      <td>2.912357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...</td>\n",
       "      <td>1.272908</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>3.581591</td>\n",
       "      <td>5.395686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...</td>\n",
       "      <td>5.353525</td>\n",
       "      <td>2.865519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.773600</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>4.443259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.431511</td>\n",
       "      <td>3.441139</td>\n",
       "      <td>2.680054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...</td>\n",
       "      <td>3.078681</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>1.338593</td>\n",
       "      <td>0.836499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...</td>\n",
       "      <td>7.714356</td>\n",
       "      <td>5.515837</td>\n",
       "      <td>1.598979</td>\n",
       "      <td>2.919135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...</td>\n",
       "      <td>1.897139</td>\n",
       "      <td>2.673828</td>\n",
       "      <td>1.905965</td>\n",
       "      <td>2.324860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           abstract         0  \\\n",
       "0             0  본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...  2.356642   \n",
       "1             1  본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...  1.728056   \n",
       "2             2  중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...  0.569367   \n",
       "3             3  본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...  1.272908   \n",
       "4             4  본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...  5.353525   \n",
       "..          ...                                                ...       ...   \n",
       "927         927  본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...  0.000000   \n",
       "928         928  최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...  0.000000   \n",
       "929         929  본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...  3.078681   \n",
       "930         930  본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...  7.714356   \n",
       "931         931  2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...  1.897139   \n",
       "\n",
       "            1         2         3  \n",
       "0    6.174630  5.023724  1.891224  \n",
       "1    2.490819  1.481277  0.309363  \n",
       "2    2.411349  0.669784  2.912357  \n",
       "3    0.038271  3.581591  5.395686  \n",
       "4    2.865519  0.000000  1.439444  \n",
       "..        ...       ...       ...  \n",
       "927  1.773600  0.121333  4.443259  \n",
       "928  3.431511  3.441139  2.680054  \n",
       "929  0.956077  1.338593  0.836499  \n",
       "930  5.515837  1.598979  2.919135  \n",
       "931  2.673828  1.905965  2.324860  \n",
       "\n",
       "[932 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하...\n",
       "1       최근 코로나19 사태로 인해 사람들 간의 물리적인 접촉을 최소화하려는 언택트 추세가...\n",
       "2       글로벌경영이 보편화됨에 따라 이문화 조직(Cross-cultural Organiza...\n",
       "3       본 연구는 청소년들이 학대경험에 대한 인식이 학업성취감에 미치는 영향과 스트레스를 ...\n",
       "4       본 연구는 한국소비자들을 대상으로 중국 제품의 지각된 품질이 중국의 국가 및 제품 ...\n",
       "                              ...                        \n",
       "2793    본 연구는 간호대학생의 임상실습 스트레스, 자아탄력성, 동료돌봄행위 정도를 파악하고...\n",
       "2794    본 연구에서는 청소년이 지각하는 부모의 방임 및 학대와 우울 간의 관계에서 자아존중...\n",
       "2795    경본 연구는 경찰청에서 조사한 2015~2016년도 경기남부지방경찰청 시흥경찰서의 ...\n",
       "2796    본 연구의 목적은 대학생의 자기불일치와 사후반추사고가 우울 및 사회불안에 미치는 상...\n",
       "2797    본 연구에서는 수업요소와 창의성교육 요소를 통합적으로 고려한 유아교사의 창의성교육 ...\n",
       "Name: abstract, Length: 2798, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train['abstract']\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.523835</td>\n",
       "      <td>3.260611</td>\n",
       "      <td>1.669686</td>\n",
       "      <td>3.370940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930321</td>\n",
       "      <td>0.542420</td>\n",
       "      <td>1.852430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.194959</td>\n",
       "      <td>0.463620</td>\n",
       "      <td>3.099519</td>\n",
       "      <td>1.837639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.333861</td>\n",
       "      <td>3.978497</td>\n",
       "      <td>3.662714</td>\n",
       "      <td>3.577977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>4.946594</td>\n",
       "      <td>8.686300</td>\n",
       "      <td>1.476334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>1.834378</td>\n",
       "      <td>1.115448</td>\n",
       "      <td>4.501013</td>\n",
       "      <td>3.099241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>7.886700</td>\n",
       "      <td>2.730818</td>\n",
       "      <td>1.936125</td>\n",
       "      <td>2.332378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>1.561563</td>\n",
       "      <td>1.182006</td>\n",
       "      <td>2.323821</td>\n",
       "      <td>1.482143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     5.194959  0.463620  3.099519  1.837639\n",
       "1     2.523835  3.260611  1.669686  3.370940\n",
       "2     0.930321  0.542420  1.852430  0.000000\n",
       "3     5.194959  0.463620  3.099519  1.837639\n",
       "4     4.333861  3.978497  3.662714  3.577977\n",
       "...        ...       ...       ...       ...\n",
       "2793  4.946594  8.686300  1.476334  0.000000\n",
       "2794  7.886700  2.730818  1.936125  2.332378\n",
       "2795  1.834378  1.115448  4.501013  3.099241\n",
       "2796  7.886700  2.730818  1.936125  2.332378\n",
       "2797  1.561563  1.182006  2.323821  1.482143\n",
       "\n",
       "[2798 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구는 테블릿 pc 어플리케이션을 사용한 인지훈련이 인지 손상이 있는 아급성 뇌...\n",
       "1      기독교대학은 대학생의 스트레스 상황에서 영향을 조절하여 완충시켜주거나 적응을 도와주...\n",
       "2      본 연구는 초등학생의 방과후 운동, 스마트폰 중독, 정신건강과의 관계를 탐색하기 위...\n",
       "3      본 연구의 목적은 마을교육의 방과후학교 참여 의의를 살펴보고 학교와 마을교육 간의 ...\n",
       "4      오늘날 고령화뿐만 아니라 복합적 욕구를 가진 인구의 증가는 사회적 돌봄의 필요성을 ...\n",
       "                             ...                        \n",
       "927    본 연구는 직무스트레스 요인이 번영과 직무열의에 영향을 미치는 과정에 있어서 문화 ...\n",
       "928    본 연구는 청소년의 ADHD 성향과 자기유능감 및 학교생활적응의 관계에서 실행기능 ...\n",
       "929    한국의 개인사업자수는 2017년 기준 560만명을 넘어섰는데, 그에 따라 경쟁이 치...\n",
       "930    본 연구는 수원정신보건센터를 방문한 아동들을 대상으로 1) 스마트폰 중독에 따른 정...\n",
       "931    본 연구는 국내의 장애학생 고등교육과 관련된 연구논문들을 분석하여 전반적인 연구동향...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = val['abstract']\n",
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.252167</td>\n",
       "      <td>2.948070</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>2.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.448070</td>\n",
       "      <td>5.104998</td>\n",
       "      <td>1.674422</td>\n",
       "      <td>0.211541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.941952</td>\n",
       "      <td>1.189352</td>\n",
       "      <td>0.948080</td>\n",
       "      <td>5.824813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.061509</td>\n",
       "      <td>4.723454</td>\n",
       "      <td>1.920044</td>\n",
       "      <td>4.697660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>2.117849</td>\n",
       "      <td>2.717265</td>\n",
       "      <td>1.860312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>4.311187</td>\n",
       "      <td>1.612342</td>\n",
       "      <td>2.545564</td>\n",
       "      <td>1.304350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174629</td>\n",
       "      <td>5.023723</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>3.285078</td>\n",
       "      <td>3.259609</td>\n",
       "      <td>2.390505</td>\n",
       "      <td>1.122444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2.872831</td>\n",
       "      <td>2.474819</td>\n",
       "      <td>1.055902</td>\n",
       "      <td>2.022084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    4.252167  2.948070  0.193734  2.841667\n",
       "1    4.448070  5.104998  1.674422  0.211541\n",
       "2    4.941952  1.189352  0.948080  5.824813\n",
       "3    7.061509  4.723454  1.920044  4.697660\n",
       "4    2.356642  6.174630  5.023724  1.891224\n",
       "..        ...       ...       ...       ...\n",
       "927  2.117849  2.717265  1.860312  0.000000\n",
       "928  4.311187  1.612342  2.545564  1.304350\n",
       "929  2.356642  6.174629  5.023723  1.891224\n",
       "930  3.285078  3.259609  2.390505  1.122444\n",
       "931  2.872831  2.474819  1.055902  2.022084\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      본 연구의 목적은 지금까지 개발된 초등학교 안전지도에 대한 비판적 차원의 분석, 검...\n",
       "1      본 연구의 목적은 간호사의 여가활동 유형을 분류하고 실증적 분석을 실시하여 여가활동...\n",
       "2      중국 소비자들의 한국화장품에 대한 소비행태에 대한 연구들은 꾸준하게 연구되어져 왔다...\n",
       "3      본 연구의 목적은 북한이탈주민 부부의 부부관계 적응과 남한사회 적응 과정을 탐색하는...\n",
       "4      본 연구의 목적은 음악과 건강 체조 프로그램이 재가노인의 우울, 자아존중감 및 인지...\n",
       "                             ...                        \n",
       "927    본 연구의 목적은 선행연구를 기초로 하여 호텔에 적합한 다차원적인 서비스 편의성을 ...\n",
       "928    최근 IT 기술의 발달과 함께 소셜 미디어, 모바일 단말기, 사물인터넷과 같은 다양...\n",
       "929    본 연구는 다차원적 진로정체감 모형을 사용하여 대학생의 진로정체감 지위(성취, 유실...\n",
       "930    본 연구의 목적은 노인의 자살생각에 영향을 미치는 개인적 요인을 분석함으로써 노인자...\n",
       "931    2014년 한국 헌법재판소는 문화콘텐츠 산업 관련 중요한 판결을 내렸다. 여성가족부...\n",
       "Name: abstract, Length: 932, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test['abstract']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.356642</td>\n",
       "      <td>6.174630</td>\n",
       "      <td>5.023724</td>\n",
       "      <td>1.891224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.728056</td>\n",
       "      <td>2.490819</td>\n",
       "      <td>1.481277</td>\n",
       "      <td>0.309363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569367</td>\n",
       "      <td>2.411349</td>\n",
       "      <td>0.669784</td>\n",
       "      <td>2.912357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.272908</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>3.581591</td>\n",
       "      <td>5.395686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.353525</td>\n",
       "      <td>2.865519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.773600</td>\n",
       "      <td>0.121333</td>\n",
       "      <td>4.443259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.431511</td>\n",
       "      <td>3.441139</td>\n",
       "      <td>2.680054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3.078681</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>1.338593</td>\n",
       "      <td>0.836499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>7.714356</td>\n",
       "      <td>5.515837</td>\n",
       "      <td>1.598979</td>\n",
       "      <td>2.919135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1.897139</td>\n",
       "      <td>2.673828</td>\n",
       "      <td>1.905965</td>\n",
       "      <td>2.324860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "0    2.356642  6.174630  5.023724  1.891224\n",
       "1    1.728056  2.490819  1.481277  0.309363\n",
       "2    0.569367  2.411349  0.669784  2.912357\n",
       "3    1.272908  0.038271  3.581591  5.395686\n",
       "4    5.353525  2.865519  0.000000  1.439444\n",
       "..        ...       ...       ...       ...\n",
       "927  0.000000  1.773600  0.121333  4.443259\n",
       "928  0.000000  3.431511  3.441139  2.680054\n",
       "929  3.078681  0.956077  1.338593  0.836499\n",
       "930  7.714356  5.515837  1.598979  2.919135\n",
       "931  1.897139  2.673828  1.905965  2.324860\n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text_list):\n",
    "    \n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    stopwords = ['을', '를', '이', '가', '은', '는', '의']\n",
    "    tokenizer = Okt() #형태소 분석기 \n",
    "    token_list = []\n",
    "    \n",
    "    for text in tqdm(text_list):\n",
    "        txt = hangul.sub('', text)\n",
    "        token = tokenizer.morphs(txt)\n",
    "        token = [t for t in token if t not in stopwords or type(t) != float]\n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2798/2798 [01:18<00:00, 35.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:30<00:00, 30.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 932/932 [00:32<00:00, 28.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sent_token = text_preprocessing(train_X)\n",
    "val_sent_token = text_preprocessing(val_X)\n",
    "test_sent_token = text_preprocessing(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['본',\n",
       "  '연구는',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련이',\n",
       "  '인지',\n",
       "  '손상',\n",
       "  '이',\n",
       "  '있는',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '및',\n",
       "  '만족감에',\n",
       "  '미치는',\n",
       "  '영향을',\n",
       "  '알고자',\n",
       "  '하였다',\n",
       "  '인천',\n",
       "  '에',\n",
       "  '소재한',\n",
       "  '병원에',\n",
       "  '입원',\n",
       "  '중인',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자',\n",
       "  '들',\n",
       "  '이',\n",
       "  '본',\n",
       "  '연구에',\n",
       "  '참여',\n",
       "  '하였다',\n",
       "  '14',\n",
       "  '명의',\n",
       "  '대상자들은',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '으로',\n",
       "  '7',\n",
       "  '명씩',\n",
       "  '무작위',\n",
       "  '배정',\n",
       "  '되었다',\n",
       "  '두',\n",
       "  '그룹의',\n",
       "  '대상자들은',\n",
       "  '모두',\n",
       "  '전통적인',\n",
       "  '인지',\n",
       "  '치료를',\n",
       "  '4',\n",
       "  '주간',\n",
       "  '주',\n",
       "  '5회',\n",
       "  '1일',\n",
       "  '30분',\n",
       "  '의',\n",
       "  '중재를',\n",
       "  '받았으며',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련을',\n",
       "  '30분',\n",
       "  '씩',\n",
       "  '추가적으로',\n",
       "  '실시',\n",
       "  '하였다',\n",
       "  '평가는',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후에',\n",
       "  '한국판',\n",
       "  '간이',\n",
       "  '정신',\n",
       "  '상태',\n",
       "  '검사',\n",
       "  '한국판',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '시각',\n",
       "  '상사',\n",
       "  '척도를',\n",
       "  '사용하여',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '일상생활',\n",
       "  '만족감을',\n",
       "  '측정',\n",
       "  '하였다',\n",
       "  '연구',\n",
       "  '결과',\n",
       "  '두',\n",
       "  '그룹은',\n",
       "  '중재',\n",
       "  '전과',\n",
       "  '후로',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가와',\n",
       "  '수정',\n",
       "  '된',\n",
       "  '바델',\n",
       "  '지수',\n",
       "  '에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '변화',\n",
       "  '량',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '은',\n",
       "  '대조군',\n",
       "  '보다',\n",
       "  '몬트리올',\n",
       "  '인지',\n",
       "  '평가에서',\n",
       "  '유의한',\n",
       "  '향상을',\n",
       "  '보였다',\n",
       "  '05',\n",
       "  '두',\n",
       "  '그룹',\n",
       "  '간',\n",
       "  '만족감',\n",
       "  '비교',\n",
       "  '에서',\n",
       "  '실험군',\n",
       "  '과',\n",
       "  '대조군',\n",
       "  '은',\n",
       "  '유의한',\n",
       "  '차이가',\n",
       "  '없었다',\n",
       "  '05',\n",
       "  '본',\n",
       "  '연구의',\n",
       "  '결과를',\n",
       "  '통하여',\n",
       "  '테블릿',\n",
       "  '어플리케이션',\n",
       "  '을',\n",
       "  '사용',\n",
       "  '한',\n",
       "  '인지',\n",
       "  '훈련은',\n",
       "  '아급성',\n",
       "  '뇌졸중',\n",
       "  '환자의',\n",
       "  '인지',\n",
       "  '기능',\n",
       "  '향상에',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '효과를',\n",
       "  '기대할',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '중재법',\n",
       "  '으로',\n",
       "  '사료',\n",
       "  '된다'],\n",
       " ['기독교',\n",
       "  '대학은',\n",
       "  '대학생의',\n",
       "  '스트레스',\n",
       "  '상황에서',\n",
       "  '영향을',\n",
       "  '조절',\n",
       "  '하여',\n",
       "  '완충시켜주거나',\n",
       "  '적응을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '잘',\n",
       "  '분석하여',\n",
       "  '그',\n",
       "  '구성',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '프로그램을',\n",
       "  '개발',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있다',\n",
       "  '그러므로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '자아탄력성',\n",
       "  '과',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '소그룹',\n",
       "  '활동',\n",
       "  '간의',\n",
       "  '관계성',\n",
       "  '을',\n",
       "  '탐구',\n",
       "  '하여',\n",
       "  '대학생의',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '증진을',\n",
       "  '위한',\n",
       "  '기독교',\n",
       "  '대학에서의',\n",
       "  '역할을',\n",
       "  '모색하',\n",
       "  '는',\n",
       "  '것을',\n",
       "  '목적으로',\n",
       "  '삼는다',\n",
       "  '구체적으로',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '대표적',\n",
       "  '구성요소',\n",
       "  '인',\n",
       "  '낙관성',\n",
       "  '활력성',\n",
       "  '감정',\n",
       "  '통제력',\n",
       "  '그리고',\n",
       "  '대인관계',\n",
       "  '능력을',\n",
       "  '강화',\n",
       "  '시킴에',\n",
       "  '있어서',\n",
       "  '소그룹',\n",
       "  '활동의',\n",
       "  '특성들',\n",
       "  '과',\n",
       "  '어떠한',\n",
       "  '관련',\n",
       "  '이',\n",
       "  '있는지를',\n",
       "  '분석하는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '그리고',\n",
       "  '이러한',\n",
       "  '분석에',\n",
       "  '기초하여',\n",
       "  '기독교',\n",
       "  '대학에서',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '통한',\n",
       "  '영적',\n",
       "  '돌봄',\n",
       "  '이',\n",
       "  '효과',\n",
       "  '적',\n",
       "  '으로',\n",
       "  '이루어질',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '몇',\n",
       "  '가지',\n",
       "  '사례',\n",
       "  '들',\n",
       "  '을',\n",
       "  '제시',\n",
       "  '한다',\n",
       "  '결론적으로',\n",
       "  '이',\n",
       "  '연구는',\n",
       "  '소그룹',\n",
       "  '활동이',\n",
       "  '스트레스로',\n",
       "  '부터의',\n",
       "  '회복을',\n",
       "  '도와주는',\n",
       "  '자아탄력성',\n",
       "  '의',\n",
       "  '네',\n",
       "  '기본',\n",
       "  '요소들을',\n",
       "  '강화',\n",
       "  '시켜',\n",
       "  '주기',\n",
       "  '때문에',\n",
       "  '기독교',\n",
       "  '대학이',\n",
       "  '보다',\n",
       "  '적극적으로',\n",
       "  '종교',\n",
       "  '교육적',\n",
       "  '인',\n",
       "  '목적의',\n",
       "  '소그룹',\n",
       "  '활동을',\n",
       "  '개발',\n",
       "  '시킬',\n",
       "  '것을',\n",
       "  '제안',\n",
       "  '한다'],\n",
       " ['본',\n",
       "  '연구는',\n",
       "  '초등학생의',\n",
       "  '방과후',\n",
       "  '운동',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '정신건강',\n",
       "  '과의',\n",
       "  '관계를',\n",
       "  '탐색',\n",
       "  '하기',\n",
       "  '위해',\n",
       "  '수행',\n",
       "  '되었다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '서울시',\n",
       "  '소재의',\n",
       "  '초등학생',\n",
       "  '217',\n",
       "  '명이',\n",
       "  '스마트폰',\n",
       "  '중독',\n",
       "  '척도',\n",
       "  '한국',\n",
       "  '정보화',\n",
       "  '진흥원',\n",
       "  '2011',\n",
       "  '와',\n",
       "  '정신건강',\n",
       "  '측정',\n",
       "  '척도',\n",
       "  '김동일',\n",
       "  '안현',\n",
       "  '의',\n",
       "  '2006',\n",
       "  '에',\n",
       "  '응답',\n",
       "  '하였다',\n",
       "  '수집된',\n",
       "  '자료는',\n",
       "  '먼저',\n",
       "  '운동',\n",
       "  '시간이',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '35시간',\n",
       "  '매일운동으로',\n",
       "  '집단을',\n",
       "  '분류하여',\n",
       "  '스마트폰',\n",
       "  '중독과',\n",
       "  '정신건강',\n",
       "  '의',\n",
       "  '차이를',\n",
       "  '분석',\n",
       "  '하였다',\n",
       "  '그',\n",
       "  '결과',\n",
       "  '매일운동',\n",
       "  '집단은',\n",
       "  '주당',\n",
       "  '2시간',\n",
       "  '이하',\n",
       "  '운동',\n",
       "  '집단에',\n",
       "  '비해',\n",
       "  '일상생활',\n",
       "  '장애',\n",
       "  '금단',\n",
       "  '내성',\n",
       "  '가상세계',\n",
       "  '의',\n",
       "  '점수가',\n",
       "  '모두',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났고',\n",
       "  '정신건강',\n",
       "  '에서',\n",
       "  '우울',\n",
       "  '충동',\n",
       "  '공격성',\n",
       "  '이',\n",
       "  '유의하게',\n",
       "  '낮은',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '경로분석',\n",
       "  '에서',\n",
       "  '운동',\n",
       "  '시간은',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '직접',\n",
       "  '적',\n",
       "  '인',\n",
       "  '효과가',\n",
       "  '있었으며',\n",
       "  '정신건강',\n",
       "  '을',\n",
       "  '중재',\n",
       "  '하는',\n",
       "  '효과에서',\n",
       "  '는',\n",
       "  '직접효과',\n",
       "  '는',\n",
       "  '없고',\n",
       "  '스마트폰',\n",
       "  '중독을',\n",
       "  '통한',\n",
       "  '간접효과',\n",
       "  '만이',\n",
       "  '나타났다'],\n",
       " ['본',\n",
       "  '연구의',\n",
       "  '목적은',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여',\n",
       "  '의의',\n",
       "  '를',\n",
       "  '살펴보고',\n",
       "  '학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '간의',\n",
       "  '연계',\n",
       "  '활동을',\n",
       "  '보다',\n",
       "  '활성화',\n",
       "  '시킬',\n",
       "  '수',\n",
       "  '있는',\n",
       "  '방안을',\n",
       "  '제시하',\n",
       "  '는',\n",
       "  '것이',\n",
       "  '다',\n",
       "  '이를',\n",
       "  '위해',\n",
       "  '관련',\n",
       "  '연구',\n",
       "  '문헌을',\n",
       "  '검토',\n",
       "  '하고',\n",
       "  '관계자를',\n",
       "  '인터뷰',\n",
       "  '하고',\n",
       "  '마을교육',\n",
       "  '과',\n",
       "  '방과후학교',\n",
       "  '의',\n",
       "  '강점',\n",
       "  '약점',\n",
       "  '기회',\n",
       "  '위기',\n",
       "  '요인들을',\n",
       "  '분석',\n",
       "  '하고',\n",
       "  '연계',\n",
       "  '활성화를',\n",
       "  '위한',\n",
       "  '방안을',\n",
       "  '제시',\n",
       "  '하였다',\n",
       "  '연구결과',\n",
       "  '방과후학교',\n",
       "  '는',\n",
       "  '학부모',\n",
       "  '의',\n",
       "  '높은',\n",
       "  '만족도',\n",
       "  '사교육비',\n",
       "  '경감',\n",
       "  '등에',\n",
       "  '효과가',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '인식',\n",
       "  '되는',\n",
       "  '등',\n",
       "  '긍정적',\n",
       "  '인',\n",
       "  '기능을',\n",
       "  '수행하고',\n",
       "  '있으며',\n",
       "  '지역사회',\n",
       "  '와의',\n",
       "  '연계',\n",
       "  '활동',\n",
       "  '강화를',\n",
       "  '중요하게',\n",
       "  '생각',\n",
       "  '하고',\n",
       "  '있는',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '최근에는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '이',\n",
       "  '서로',\n",
       "  '연계',\n",
       "  '하는',\n",
       "  '사례가',\n",
       "  '나타나고',\n",
       "  '있다',\n",
       "  '이는',\n",
       "  '방과후학교',\n",
       "  '와',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '연계',\n",
       "  '를',\n",
       "  '통해',\n",
       "  '학생들이',\n",
       "  '지역사회',\n",
       "  '공동체',\n",
       "  '의식을',\n",
       "  '함양',\n",
       "  '하고',\n",
       "  '지역사회',\n",
       "  '의',\n",
       "  '공동체',\n",
       "  '성',\n",
       "  '을',\n",
       "  '회복하는',\n",
       "  '밑거름',\n",
       "  '이',\n",
       "  '된다는',\n",
       "  '측면에서',\n",
       "  '매우',\n",
       "  '중요한',\n",
       "  '의미를',\n",
       "  '지니고',\n",
       "  '있다',\n",
       "  '이러한',\n",
       "  '연구',\n",
       "  '결과를',\n",
       "  '토대로',\n",
       "  '마을교육',\n",
       "  '의',\n",
       "  '방과후학교',\n",
       "  '참여가',\n",
       "  '보다',\n",
       "  '활성화를',\n",
       "  '위',\n",
       "  '해서는',\n",
       "  '단위',\n",
       "  '학교에서는',\n",
       "  '마을교육',\n",
       "  '만이',\n",
       "  '가지',\n",
       "  '고',\n",
       "  '있는',\n",
       "  '고유의',\n",
       "  '특징을',\n",
       "  '충분히',\n",
       "  '이해',\n",
       "  '할',\n",
       "  '필요가',\n",
       "  '있으며',\n",
       "  '마을교육',\n",
       "  '단체들은',\n",
       "  '방과후학교',\n",
       "  '활동을',\n",
       "  '위한',\n",
       "  '전문성',\n",
       "  '을',\n",
       "  '제고',\n",
       "  '해야',\n",
       "  '함을',\n",
       "  '대안으로',\n",
       "  '제시',\n",
       "  '하였다']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sent_token[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장과 단어 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train + val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = list(train_X) + list(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3730/3730 [00:00<00:00, 4532.99it/s]\n"
     ]
    }
   ],
   "source": [
    "word_len = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    for sentence in sentences.split('. '):\n",
    "        word_len.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이를',\n",
       " '위해',\n",
       " '한국청소년정책연구원에서',\n",
       " '구축한',\n",
       " '한국아동⋅',\n",
       " '청소년패널조사(Korean',\n",
       " 'Children',\n",
       " '&',\n",
       " 'Youth',\n",
       " 'Panel',\n",
       " 'Survey)의',\n",
       " '2013년~2016년(4차,',\n",
       " '5차,',\n",
       " '6차,',\n",
       " '7차)',\n",
       " '의',\n",
       " '데이터를',\n",
       " '사용하였다']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3730/3730 [00:00<00:00, 8657.34it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_num = []\n",
    "\n",
    "for sentences in tqdm(sent_token):\n",
    "    sentence_num.append(sentences.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['본 연구는 청소년의 지역사회 및 가족, 학교생활과 관련한 사회자본의 중요성을 인식하고, 청소년의 사회 자본이 주관적 삶의 만족도에 미치는 영향과 종단적 변화 양상을 잠재성장모델(Latent Growth Model)을 활용하여 분석하였다',\n",
       " '이를 위해 한국청소년정책연구원에서 구축한 한국아동⋅ 청소년패널조사(Korean Children & Youth Panel Survey)의 2013년~2016년(4차, 5차, 6차, 7차) 의 데이터를 사용하였다',\n",
       " '연구결과를 살펴보면 첫째, 청소년의 사회자본과 주관적 삶의 만족도의초기 값과의 관계는 학교 또래 관계(+), 부모와의 관계(+), 지역사회 인식(+), 교사와의 관계(+), 공동체 의식(+)이 정적인 관계가 있는 것으로 나타났다',\n",
       " '또한 청소년의 주관적 삶의 만족도에대한 시간에 따른 변화율은 성별(-), 학교 또래 관계(-), 학교 교사와의 관계(-), 공동체의식(-)이영향을 미침을 알 수 있다',\n",
       " '이에 청소년의 주관적 삶의 만족도에 가정 내 부모관계가 여전히 중요하지만 학교 사회자본과 지역사회 사회자본의 중요성 또한 주목하여 이를 강화시킬 수 있는 실천적대안을 제시하였다',\n",
       " '또한 고등학교로 진학하고 시간이 흐름에 따라 학교 또래 관계, 교사와의 관계, 공동체 의식 변수가 스트레스에 대한 보호적 역할을 지속할 수 있도록 학교 현장에 맞는 정책적대안이 필요함을 제언하는 바이다',\n",
       " '본 연구는 청소년의 주관적 삶의 만족도와 사회자본과의 관계와종단적 영향을 보여줌으로서 청소년의 주관적 삶의 만족도 향상을 위한 학문적 기초를 제공함에그 의의가 있을 것이다']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 내의 최대 문장 개수:  35\n",
      "문서 내의 최소 문장 개수:  5\n",
      "문서 내의 평균 문장 개수 : 7.892493297587132\n",
      "문서 내의 문장 개수 중앙값 : 7.0\n"
     ]
    }
   ],
   "source": [
    "print('문서 내의 최대 문장 개수: ', max([len(i) for i in sentence_num]))\n",
    "print('문서 내의 최소 문장 개수: ', min([len(i) for i in sentence_num]))\n",
    "print('문서 내의 평균 문장 개수 :', sum(map(len, sentence_num))/len(sentence_num))\n",
    "print('문서 내의 문장 개수 중앙값 :', np.median([len(i) for i in sentence_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 내의 최대 단어 개수:  509\n",
      "문장 내의 최소 단어 개수:  1\n",
      "문장 내의 평균 단어 개수 : 18.38516933319746\n",
      "문장 내의 단어 개수 중앙값 : 17.0\n"
     ]
    }
   ],
   "source": [
    "print('문장 내의 최대 단어 개수: ', max([len(j) for j in word_len]))\n",
    "print('문장 내의 최소 단어 개수: ', min([len(j) for j in word_len]))\n",
    "print('문장 내의 평균 단어 개수 :', sum(map(len, word_len))/len(word_len))\n",
    "print('문장 내의 단어 개수 중앙값 :', np.median([len(j) for j in word_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCES = 20\n",
    "MAX_SENTENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sent_token = train_sent_token + val_sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_data.shape: (2798, 20, 200)\n",
      "train_Y_data.shape: (2798, 4)\n",
      "val_X_data.shape: (932, 20, 200)\n",
      "val_Y_data.shape: (932, 4)\n",
      "test_X_data.shape: (932, 20, 200)\n",
      "test_Y_data.shape: (932, 4)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_val_sent_token)\n",
    "\n",
    "\n",
    "max_nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def doc2hierarchical(text, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH):\n",
    "    sentences = text.split('. ')\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen = max_sentence_length)\n",
    "\n",
    "    pad_size = max_sentences - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:  # tokenized_sentences.shape[0] < max_sentences\n",
    "        tokenized_sentences = tokenized_sentences[:max_sentences]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(tokenized_sentences, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "            \n",
    "def build_dataset(x_data, y_data, max_sentences = MAX_SENTENCES, max_sentence_length = MAX_SENTENCE_LENGTH, tokenizer = tokenizer):\n",
    "    nb_instances = len(x_data)\n",
    "    X_data = np.zeros((nb_instances, max_sentences, max_sentence_length), dtype='int32')\n",
    "    for i, review in enumerate(x_data):\n",
    "        tokenized_sentences = doc2hierarchical(review)\n",
    "            \n",
    "        X_data[i] = tokenized_sentences[None, ...]\n",
    "        \n",
    "    nb_classes = y_data\n",
    "    #print(nb_classes)\n",
    "    Y_data = nb_classes #to_categorical(y_data, nb_classes)\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "\n",
    "train_X_data, train_Y_data = build_dataset(train_X, train_y)\n",
    "val_X_data, val_Y_data = build_dataset(val_X, val_y)\n",
    "test_X_data, test_Y_data = build_dataset(test_X, test_y)\n",
    "\n",
    "print(\"train_X_data.shape: {}\".format(train_X_data.shape))\n",
    "print(\"train_Y_data.shape: {}\".format(train_Y_data.shape))\n",
    "print(\"val_X_data.shape: {}\".format(val_X_data.shape))\n",
    "print(\"val_Y_data.shape: {}\".format(val_Y_data.shape))\n",
    "print(\"test_X_data.shape: {}\".format(test_X_data.shape))\n",
    "print(\"test_Y_data.shape: {}\".format(test_Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'의': 1,\n",
       " '하였다': 2,\n",
       " '에': 3,\n",
       " '을': 4,\n",
       " '이': 5,\n",
       " '과': 6,\n",
       " '본': 7,\n",
       " '영향을': 8,\n",
       " '대한': 9,\n",
       " '것으로': 10,\n",
       " '적': 11,\n",
       " '및': 12,\n",
       " '수': 13,\n",
       " '를': 14,\n",
       " '미치는': 15,\n",
       " '는': 16,\n",
       " '나타났다': 17,\n",
       " '은': 18,\n",
       " '한': 19,\n",
       " '있는': 20,\n",
       " '하고': 21,\n",
       " '있다': 22,\n",
       " '하는': 23,\n",
       " '인': 24,\n",
       " '연구는': 25,\n",
       " '분석': 26,\n",
       " '연구': 27,\n",
       " '가': 28,\n",
       " '와': 29,\n",
       " '할': 30,\n",
       " '위해': 31,\n",
       " '으로': 32,\n",
       " '통해': 33,\n",
       " '결과': 34,\n",
       " '되었다': 35,\n",
       " '로': 36,\n",
       " '것이': 37,\n",
       " '대상으로': 38,\n",
       " '위한': 39,\n",
       " '연구의': 40,\n",
       " '한다': 41,\n",
       " '고': 42,\n",
       " '다': 43,\n",
       " '이를': 44,\n",
       " '직무': 45,\n",
       " '에서': 46,\n",
       " '우울': 47,\n",
       " '된': 48,\n",
       " '한국': 49,\n",
       " '실시': 50,\n",
       " '들': 51,\n",
       " '하기': 52,\n",
       " '진로': 53,\n",
       " '이러한': 54,\n",
       " '유의한': 55,\n",
       " '그': 56,\n",
       " '확인': 57,\n",
       " '자기': 58,\n",
       " '사회적': 59,\n",
       " '또한': 60,\n",
       " '검증': 61,\n",
       " '둘째': 62,\n",
       " '첫째': 63,\n",
       " '사회': 64,\n",
       " '하여': 65,\n",
       " '중': 66,\n",
       " '그리고': 67,\n",
       " '교육': 68,\n",
       " '관련': 69,\n",
       " '중국': 70,\n",
       " '있었다': 71,\n",
       " '사용': 72,\n",
       " '따라': 73,\n",
       " '지': 74,\n",
       " '이다': 75,\n",
       " '학교': 76,\n",
       " '긍정적': 77,\n",
       " '성': 78,\n",
       " '활용': 79,\n",
       " '삶의': 80,\n",
       " '서비스': 81,\n",
       " '조직': 82,\n",
       " '하였으며': 83,\n",
       " '다음': 84,\n",
       " '제시': 85,\n",
       " '셋째': 86,\n",
       " '명을': 87,\n",
       " '높은': 88,\n",
       " '영향': 89,\n",
       " '학습': 90,\n",
       " '도': 91,\n",
       " '청소년의': 92,\n",
       " '대해': 93,\n",
       " '청소년': 94,\n",
       " '관계를': 95,\n",
       " '경우': 96,\n",
       " '경험': 97,\n",
       " '결과는': 98,\n",
       " '3': 99,\n",
       " '부모': 100,\n",
       " '따른': 101,\n",
       " '4': 102,\n",
       " '결과를': 103,\n",
       " '간': 104,\n",
       " '가장': 105,\n",
       " '2': 106,\n",
       " '이용': 107,\n",
       " '다양한': 108,\n",
       " '가지': 109,\n",
       " '바탕으로': 110,\n",
       " '심리적': 111,\n",
       " '더': 112,\n",
       " '개발': 113,\n",
       " '될': 114,\n",
       " '보다': 115,\n",
       " '요인': 116,\n",
       " '간의': 117,\n",
       " '1': 118,\n",
       " '자료를': 119,\n",
       " '차이가': 120,\n",
       " '연구에서는': 121,\n",
       " '된다': 122,\n",
       " '같다': 123,\n",
       " '서': 124,\n",
       " '모두': 125,\n",
       " '것을': 126,\n",
       " '참여': 127,\n",
       " '위하여': 128,\n",
       " '목적은': 129,\n",
       " '인식': 130,\n",
       " '총': 131,\n",
       " '따라서': 132,\n",
       " '관계': 133,\n",
       " '매개': 134,\n",
       " '증가': 135,\n",
       " '유의미한': 136,\n",
       " '관계에서': 137,\n",
       " '분석을': 138,\n",
       " '문화': 139,\n",
       " '의미': 140,\n",
       " '대학': 141,\n",
       " '후': 142,\n",
       " '수행': 143,\n",
       " '되는': 144,\n",
       " '같은': 145,\n",
       " '개': 146,\n",
       " '해': 147,\n",
       " '논의': 148,\n",
       " '연구를': 149,\n",
       " '하고자': 150,\n",
       " '되고': 151,\n",
       " '개인': 152,\n",
       " '문제': 153,\n",
       " '제공': 154,\n",
       " '특히': 155,\n",
       " '여': 156,\n",
       " '다문화': 157,\n",
       " '등': 158,\n",
       " '구성': 159,\n",
       " '이에': 160,\n",
       " '학년': 161,\n",
       " '프로그램': 162,\n",
       " '제': 163,\n",
       " '평가': 164,\n",
       " '개의': 165,\n",
       " '측정': 166,\n",
       " '일반': 167,\n",
       " '집단': 168,\n",
       " '가족': 169,\n",
       " '정보': 170,\n",
       " '연구결과': 171,\n",
       " '진행': 172,\n",
       " '학업': 173,\n",
       " '지역': 174,\n",
       " '명': 175,\n",
       " '향상': 176,\n",
       " '비교': 177,\n",
       " '효과를': 178,\n",
       " '도출': 179,\n",
       " '명의': 180,\n",
       " '프로그램을': 181,\n",
       " '변화': 182,\n",
       " '만족도': 183,\n",
       " '부터': 184,\n",
       " '적용': 185,\n",
       " '하였고': 186,\n",
       " '중요한': 187,\n",
       " '에서는': 188,\n",
       " '5': 189,\n",
       " '주요': 190,\n",
       " '건강': 191,\n",
       " '정적': 192,\n",
       " '부정적': 193,\n",
       " '조사': 194,\n",
       " '국내': 195,\n",
       " '기술': 196,\n",
       " '했다': 197,\n",
       " '있으며': 198,\n",
       " '하는데': 199,\n",
       " '차이를': 200,\n",
       " '자아존중감': 201,\n",
       " '만족': 202,\n",
       " '통한': 203,\n",
       " '정의': 204,\n",
       " '교사': 205,\n",
       " '자': 206,\n",
       " '까지': 207,\n",
       " '질적': 208,\n",
       " '세': 209,\n",
       " '대': 210,\n",
       " '대학생': 211,\n",
       " '이는': 212,\n",
       " '정서': 213,\n",
       " '때': 214,\n",
       " '차': 215,\n",
       " '스트레스': 216,\n",
       " '나타났으며': 217,\n",
       " '보였다': 218,\n",
       " '통계적으로': 219,\n",
       " '만족도에': 220,\n",
       " '고객': 221,\n",
       " '아니라': 222,\n",
       " '이용하여': 223,\n",
       " '며': 224,\n",
       " '지원': 225,\n",
       " '이었다': 226,\n",
       " '새로운': 227,\n",
       " '생활': 228,\n",
       " '여성': 229,\n",
       " '자료': 230,\n",
       " '각': 231,\n",
       " '에는': 232,\n",
       " '두': 233,\n",
       " '향후': 234,\n",
       " '있음을': 235,\n",
       " '비해': 236,\n",
       " '관한': 237,\n",
       " '척도': 238,\n",
       " '중심으로': 239,\n",
       " '설문조사': 240,\n",
       " '미치': 241,\n",
       " '위': 242,\n",
       " '하위': 243,\n",
       " '인터넷': 244,\n",
       " '감소': 245,\n",
       " '직접': 246,\n",
       " '등의': 247,\n",
       " '수집': 248,\n",
       " '역할을': 249,\n",
       " '대학생의': 250,\n",
       " '함께': 251,\n",
       " '되어': 252,\n",
       " '있어': 253,\n",
       " '상호작용': 254,\n",
       " '연구가': 255,\n",
       " '큰': 256,\n",
       " '탐색': 257,\n",
       " '불안': 258,\n",
       " '학생': 259,\n",
       " '에게': 260,\n",
       " '어떠한': 261,\n",
       " '직업': 262,\n",
       " '매개효과를': 263,\n",
       " '이후': 264,\n",
       " '인지': 265,\n",
       " '대인관계': 266,\n",
       " '통하여': 267,\n",
       " '연구결과를': 268,\n",
       " '형': 269,\n",
       " '토대로': 270,\n",
       " '행동': 271,\n",
       " '해야': 272,\n",
       " '부적': 273,\n",
       " '제안': 274,\n",
       " '고객만족': 275,\n",
       " '분석한': 276,\n",
       " '유의': 277,\n",
       " '노인': 278,\n",
       " '많은': 279,\n",
       " '즉': 280,\n",
       " '요인을': 281,\n",
       " '방안을': 282,\n",
       " '효과': 283,\n",
       " '데': 284,\n",
       " '주관적': 285,\n",
       " '화': 286,\n",
       " '국가': 287,\n",
       " '해서는': 288,\n",
       " '주는': 289,\n",
       " '정책': 290,\n",
       " '다른': 291,\n",
       " '6': 292,\n",
       " '알': 293,\n",
       " '내': 294,\n",
       " '교수': 295,\n",
       " '활용하여': 296,\n",
       " '최근': 297,\n",
       " '시사점을': 298,\n",
       " '마지막으로': 299,\n",
       " '그러나': 300,\n",
       " '수업': 301,\n",
       " '자기효능감': 302,\n",
       " '높을수록': 303,\n",
       " '활동': 304,\n",
       " '온라인': 305,\n",
       " '있어서': 306,\n",
       " '높게': 307,\n",
       " '반면': 308,\n",
       " '환경': 309,\n",
       " '빅데이터': 310,\n",
       " '함으로써': 311,\n",
       " '있을': 312,\n",
       " '낮은': 313,\n",
       " '지지': 314,\n",
       " '정신건강': 315,\n",
       " '분석결과': 316,\n",
       " '전체': 317,\n",
       " '넷째': 318,\n",
       " '안녕감': 319,\n",
       " '의사소통': 320,\n",
       " '필요하다': 321,\n",
       " '현재': 322,\n",
       " '특성': 323,\n",
       " '매우': 324,\n",
       " '과의': 325,\n",
       " '관리': 326,\n",
       " '만족에': 327,\n",
       " '목적이': 328,\n",
       " '가정': 329,\n",
       " '등을': 330,\n",
       " '형성': 331,\n",
       " '조절': 332,\n",
       " '기업': 333,\n",
       " '관련된': 334,\n",
       " '하지': 335,\n",
       " '부모의': 336,\n",
       " '있도록': 337,\n",
       " '파악': 338,\n",
       " '필요가': 339,\n",
       " '않았다': 340,\n",
       " '접근': 341,\n",
       " '핵심': 342,\n",
       " '나': 343,\n",
       " '데이터': 344,\n",
       " '신뢰': 345,\n",
       " '많이': 346,\n",
       " '유형': 347,\n",
       " '연구결과는': 348,\n",
       " '특성을': 349,\n",
       " '효과가': 350,\n",
       " '이나': 351,\n",
       " '평균': 352,\n",
       " '성별': 353,\n",
       " '정서적': 354,\n",
       " '어떻게': 355,\n",
       " '있다는': 356,\n",
       " '자녀': 357,\n",
       " '간호': 358,\n",
       " '지각된': 359,\n",
       " '사용하여': 360,\n",
       " '과정에서': 361,\n",
       " '노인의': 362,\n",
       " '이상': 363,\n",
       " '볼': 364,\n",
       " '001': 365,\n",
       " '요인은': 366,\n",
       " '하며': 367,\n",
       " '운영': 368,\n",
       " '취업': 369,\n",
       " '프로그램의': 370,\n",
       " '스마트폰': 371,\n",
       " '개선': 372,\n",
       " '이해': 373,\n",
       " '수준': 374,\n",
       " '이고': 375,\n",
       " '성과': 376,\n",
       " '품질': 377,\n",
       " '발전': 378,\n",
       " '것은': 379,\n",
       " '수준이': 380,\n",
       " '만': 381,\n",
       " '중국의': 382,\n",
       " '고려': 383,\n",
       " '예측': 384,\n",
       " '자료는': 385,\n",
       " '수집된': 386,\n",
       " '설명': 387,\n",
       " '점': 388,\n",
       " '과정을': 389,\n",
       " '자살': 390,\n",
       " '모바일': 391,\n",
       " '경제적': 392,\n",
       " '기초': 393,\n",
       " '각각': 394,\n",
       " '가치': 395,\n",
       " '통합': 396,\n",
       " '생각': 397,\n",
       " '요인으로': 398,\n",
       " '태도': 399,\n",
       " '변화를': 400,\n",
       " '시사': 401,\n",
       " '규명': 402,\n",
       " '능력': 403,\n",
       " '유의하게': 404,\n",
       " '초기': 405,\n",
       " '와의': 406,\n",
       " '살펴보았다': 407,\n",
       " '자살생각': 408,\n",
       " '장애': 409,\n",
       " '만족도가': 410,\n",
       " '만족도를': 411,\n",
       " '전략': 412,\n",
       " '대상': 413,\n",
       " '없는': 414,\n",
       " '증진': 415,\n",
       " '존재': 416,\n",
       " '브랜드': 417,\n",
       " '연구에서': 418,\n",
       " '통계': 419,\n",
       " '성인': 420,\n",
       " '모형을': 421,\n",
       " '이와': 422,\n",
       " '미래': 423,\n",
       " '감정': 424,\n",
       " '이론적': 425,\n",
       " '않은': 426,\n",
       " '대하여': 427,\n",
       " '관광': 428,\n",
       " '중재': 429,\n",
       " '자신의': 430,\n",
       " '모든': 431,\n",
       " '시': 432,\n",
       " '통제': 433,\n",
       " '근거': 434,\n",
       " '경제': 435,\n",
       " '미치고': 436,\n",
       " '수용': 437,\n",
       " '사용자': 438,\n",
       " '실제': 439,\n",
       " '이들': 440,\n",
       " '선행연구': 441,\n",
       " '목적': 442,\n",
       " '포함': 443,\n",
       " '목적으로': 444,\n",
       " '독립': 445,\n",
       " '적응': 446,\n",
       " '소비자': 447,\n",
       " '학생들의': 448,\n",
       " '점에서': 449,\n",
       " '인간': 450,\n",
       " '사': 451,\n",
       " '중심': 452,\n",
       " '자아탄력성': 453,\n",
       " '아동': 454,\n",
       " '시키는': 455,\n",
       " '영향력을': 456,\n",
       " '되었으며': 457,\n",
       " '경험이': 458,\n",
       " '요인이': 459,\n",
       " '우리나라': 460,\n",
       " '이상의': 461,\n",
       " '이며': 462,\n",
       " '라는': 463,\n",
       " '되어야': 464,\n",
       " '않는': 465,\n",
       " '만족과': 466,\n",
       " '시킬': 467,\n",
       " '상담': 468,\n",
       " '현실': 469,\n",
       " '표현': 470,\n",
       " '전': 471,\n",
       " '확대': 472,\n",
       " '우리': 473,\n",
       " '시도': 474,\n",
       " '서울': 475,\n",
       " '미쳤다': 476,\n",
       " '주': 477,\n",
       " '최종': 478,\n",
       " '일': 479,\n",
       " '판단': 480,\n",
       " '운동': 481,\n",
       " '어떤': 482,\n",
       " '중학생': 483,\n",
       " '방법을': 484,\n",
       " '하면서': 485,\n",
       " '관계가': 486,\n",
       " '설문': 487,\n",
       " '검토': 488,\n",
       " '기반': 489,\n",
       " '일본': 490,\n",
       " '목적을': 491,\n",
       " '체험': 492,\n",
       " '발생': 493,\n",
       " '또래': 494,\n",
       " '활용한': 495,\n",
       " '개입': 496,\n",
       " '표본': 497,\n",
       " '신뢰도': 498,\n",
       " '이라는': 499,\n",
       " '실천': 500,\n",
       " '내용': 501,\n",
       " '남녀': 502,\n",
       " '역량': 503,\n",
       " '국제': 504,\n",
       " '발견': 505,\n",
       " '때문에': 506,\n",
       " '선정': 507,\n",
       " '크게': 508,\n",
       " '방향을': 509,\n",
       " '척도를': 510,\n",
       " '소재': 511,\n",
       " '의의': 512,\n",
       " '북한': 513,\n",
       " '사전': 514,\n",
       " '의의가': 515,\n",
       " '교육의': 516,\n",
       " '하지만': 517,\n",
       " '마련': 518,\n",
       " '나타난': 519,\n",
       " '미국': 520,\n",
       " '예방': 521,\n",
       " '등이': 522,\n",
       " '인공지능': 523,\n",
       " '전공': 524,\n",
       " '만족도와': 525,\n",
       " '순으로': 526,\n",
       " '여가': 527,\n",
       " '성격': 528,\n",
       " '변인': 529,\n",
       " '지역사회': 530,\n",
       " '높았다': 531,\n",
       " '경험을': 532,\n",
       " '전문': 533,\n",
       " '요구': 534,\n",
       " '세계': 535,\n",
       " '20': 536,\n",
       " '필요한': 537,\n",
       " '에서의': 538,\n",
       " '요': 539,\n",
       " '측면에서': 540,\n",
       " '디자인': 541,\n",
       " '결정': 542,\n",
       " '설문지를': 543,\n",
       " '사례': 544,\n",
       " '문화적': 545,\n",
       " '문제를': 546,\n",
       " '상관관계를': 547,\n",
       " '연령': 548,\n",
       " '파악하고': 549,\n",
       " '게': 550,\n",
       " '의해': 551,\n",
       " '만족도는': 552,\n",
       " '력': 553,\n",
       " '19': 554,\n",
       " '연구대상은': 555,\n",
       " '중인': 556,\n",
       " '업무': 557,\n",
       " '학교폭력': 558,\n",
       " '나타났고': 559,\n",
       " '효과적인': 560,\n",
       " '선택': 561,\n",
       " '중독': 562,\n",
       " '애착': 563,\n",
       " '조절효과를': 564,\n",
       " '부분': 565,\n",
       " '제한점': 566,\n",
       " '또는': 567,\n",
       " '중학교': 568,\n",
       " '검사': 569,\n",
       " '남학생': 570,\n",
       " '군': 571,\n",
       " '잠재': 572,\n",
       " '기업의': 573,\n",
       " '상호': 574,\n",
       " '동시에': 575,\n",
       " '분류': 576,\n",
       " '뿐': 577,\n",
       " '모색': 578,\n",
       " '간호대학생의': 579,\n",
       " '산업': 580,\n",
       " '연구에': 581,\n",
       " '인지적': 582,\n",
       " '기존': 583,\n",
       " '시작': 584,\n",
       " '장애인': 585,\n",
       " '나타나': 586,\n",
       " '에도': 587,\n",
       " '응답': 588,\n",
       " '상': 589,\n",
       " '단계': 590,\n",
       " '역할': 591,\n",
       " '실험집단': 592,\n",
       " '10': 593,\n",
       " '구조방정식': 594,\n",
       " '내적': 595,\n",
       " '강화': 596,\n",
       " '부의': 597,\n",
       " '여러': 598,\n",
       " '정책적': 599,\n",
       " '회귀분석을': 600,\n",
       " '자아': 601,\n",
       " '자기효능감과': 602,\n",
       " '분석에': 603,\n",
       " '기존의': 604,\n",
       " '시행': 605,\n",
       " '문항': 606,\n",
       " '향상을': 607,\n",
       " '먼저': 608,\n",
       " '확인할': 609,\n",
       " '하위요인': 610,\n",
       " '게임': 611,\n",
       " '고등학교': 612,\n",
       " '지만': 613,\n",
       " '구조': 614,\n",
       " '한다는': 615,\n",
       " '사후': 616,\n",
       " '융합': 617,\n",
       " '관점에서': 618,\n",
       " '초등학교': 619,\n",
       " '인해': 620,\n",
       " '광고': 621,\n",
       " '시키기': 622,\n",
       " '특성에': 623,\n",
       " '데이터를': 624,\n",
       " '하게': 625,\n",
       " '관계에': 626,\n",
       " '유지': 627,\n",
       " '점을': 628,\n",
       " '창업': 629,\n",
       " '구매': 630,\n",
       " '설정': 631,\n",
       " '공감': 632,\n",
       " '필요성': 633,\n",
       " '공격성': 634,\n",
       " '재학': 635,\n",
       " '모형': 636,\n",
       " '영향이': 637,\n",
       " '시사점': 638,\n",
       " '동안': 639,\n",
       " '빈도': 640,\n",
       " '알아보기': 641,\n",
       " '7': 642,\n",
       " '부를': 643,\n",
       " '내용을': 644,\n",
       " '글쓰기': 645,\n",
       " '네트워크': 646,\n",
       " '분석하여': 647,\n",
       " '기반으로': 648,\n",
       " '편의': 649,\n",
       " '의미를': 650,\n",
       " '수준을': 651,\n",
       " '신체': 652,\n",
       " '지식': 653,\n",
       " '있고': 654,\n",
       " '콘텐츠': 655,\n",
       " '방법': 656,\n",
       " '매개효과': 657,\n",
       " '실시하여': 658,\n",
       " '검증을': 659,\n",
       " '피해': 660,\n",
       " '우울의': 661,\n",
       " '있었으며': 662,\n",
       " '공공': 663,\n",
       " '8': 664,\n",
       " '해결': 665,\n",
       " '비행': 666,\n",
       " '산업혁명': 667,\n",
       " '기': 668,\n",
       " '구축': 669,\n",
       " '실천적': 670,\n",
       " '몰입': 671,\n",
       " '영향력': 672,\n",
       " '상관관계': 673,\n",
       " '더욱': 674,\n",
       " '화된': 675,\n",
       " '알아보고자': 676,\n",
       " '속에서': 677,\n",
       " '예비': 678,\n",
       " '대처': 679,\n",
       " '행복감': 680,\n",
       " '추후': 681,\n",
       " '조절효과': 682,\n",
       " '마케팅': 683,\n",
       " '상황': 684,\n",
       " '교사의': 685,\n",
       " '인한': 686,\n",
       " '한편': 687,\n",
       " '강조': 688,\n",
       " '청소년들의': 689,\n",
       " '동기': 690,\n",
       " '별': 691,\n",
       " '과정': 692,\n",
       " '노력': 693,\n",
       " '이직의도에': 694,\n",
       " '보호': 695,\n",
       " '못하': 696,\n",
       " '거주': 697,\n",
       " '정보를': 698,\n",
       " '질': 699,\n",
       " '발달': 700,\n",
       " '외상': 701,\n",
       " '통제집단': 702,\n",
       " '아동의': 703,\n",
       " '개념': 704,\n",
       " '여학생': 705,\n",
       " '더불어': 706,\n",
       " '개인적': 707,\n",
       " '논문은': 708,\n",
       " '측면': 709,\n",
       " '임파워먼트': 710,\n",
       " '작용': 711,\n",
       " '있었': 712,\n",
       " '프로그램이': 713,\n",
       " '반응': 714,\n",
       " '12': 715,\n",
       " '심리': 716,\n",
       " '가능성이': 717,\n",
       " '개별': 718,\n",
       " '구조적': 719,\n",
       " '유의미하게': 720,\n",
       " '학습자': 721,\n",
       " '전략을': 722,\n",
       " '매개효과가': 723,\n",
       " '기대': 724,\n",
       " '상관': 725,\n",
       " '어머니': 726,\n",
       " '살펴보고': 727,\n",
       " '다중회귀분석': 728,\n",
       " '상관관계가': 729,\n",
       " '정치': 730,\n",
       " '성과에': 731,\n",
       " '차이': 732,\n",
       " '회복탄력성': 733,\n",
       " '제언': 734,\n",
       " '영역': 735,\n",
       " '시간': 736,\n",
       " '되었고': 737,\n",
       " '개인의': 738,\n",
       " '언어': 739,\n",
       " '차년도': 740,\n",
       " '명이': 741,\n",
       " '때문': 742,\n",
       " '스포츠': 743,\n",
       " '제언을': 744,\n",
       " '치료': 745,\n",
       " '위험': 746,\n",
       " '고찰': 747,\n",
       " '특징': 748,\n",
       " '도움이': 749,\n",
       " '간에': 750,\n",
       " '상태': 751,\n",
       " '창의성': 752,\n",
       " '연구방법': 753,\n",
       " '대응': 754,\n",
       " '상대적으로': 755,\n",
       " '제외한': 756,\n",
       " '지속': 757,\n",
       " '인분석': 758,\n",
       " '지도': 759,\n",
       " '높이기': 760,\n",
       " '종교': 761,\n",
       " '근무': 762,\n",
       " '다문화가정': 763,\n",
       " '구분': 764,\n",
       " '대학의': 765,\n",
       " '보다는': 766,\n",
       " '였다': 767,\n",
       " '친구': 768,\n",
       " '어머니의': 769,\n",
       " '추구': 770,\n",
       " '전환': 771,\n",
       " '방문': 772,\n",
       " '이직의도': 773,\n",
       " '호텔': 774,\n",
       " '가진': 775,\n",
       " '행복': 776,\n",
       " '어려움': 777,\n",
       " '목표': 778,\n",
       " '나아가': 779,\n",
       " '대상자의': 780,\n",
       " '전국': 781,\n",
       " '중에서': 782,\n",
       " '대학생들의': 783,\n",
       " '프로그램은': 784,\n",
       " '이미지': 785,\n",
       " '시스템': 786,\n",
       " '속': 787,\n",
       " '잘': 788,\n",
       " '도시': 789,\n",
       " '가능성을': 790,\n",
       " '양적': 791,\n",
       " '가설': 792,\n",
       " '실시하였': 793,\n",
       " '적응에': 794,\n",
       " '맥락': 795,\n",
       " '같이': 796,\n",
       " '스트레스와': 797,\n",
       " '주의': 798,\n",
       " '활성화': 799,\n",
       " '자기효능감이': 800,\n",
       " '사고': 801,\n",
       " '주목': 802,\n",
       " '것': 803,\n",
       " '등에': 804,\n",
       " '디지털': 805,\n",
       " '상관이': 806,\n",
       " '살펴보고자': 807,\n",
       " '달성': 808,\n",
       " '소통': 809,\n",
       " '차별': 810,\n",
       " '해당': 811,\n",
       " '의한': 812,\n",
       " '연계': 813,\n",
       " '종합': 814,\n",
       " '학업적': 815,\n",
       " '기능': 816,\n",
       " '역사': 817,\n",
       " '프로그램에': 818,\n",
       " '탐색적': 819,\n",
       " '사이버': 820,\n",
       " '기본': 821,\n",
       " '군집': 822,\n",
       " '이들의': 823,\n",
       " '추출': 824,\n",
       " '감정노동': 825,\n",
       " '협력': 826,\n",
       " '자존감': 827,\n",
       " '주로': 828,\n",
       " '소재한': 829,\n",
       " '신체적': 830,\n",
       " '지속적인': 831,\n",
       " '계획': 832,\n",
       " '리더십': 833,\n",
       " '면': 834,\n",
       " '욕구': 835,\n",
       " '제공하는': 836,\n",
       " '가치를': 837,\n",
       " '기초자료': 838,\n",
       " '있다고': 839,\n",
       " '변화에': 840,\n",
       " '어': 841,\n",
       " '고등학생': 842,\n",
       " '전통': 843,\n",
       " '교육과정': 844,\n",
       " '코로나': 845,\n",
       " '효능감': 846,\n",
       " '만족을': 847,\n",
       " '참여한': 848,\n",
       " '학업성취도': 849,\n",
       " '제시하': 850,\n",
       " '요소': 851,\n",
       " '주제': 852,\n",
       " '복지': 853,\n",
       " '되지': 854,\n",
       " '상관을': 855,\n",
       " '창의적': 856,\n",
       " '성장': 857,\n",
       " '교육을': 858,\n",
       " '도입': 859,\n",
       " '보고': 860,\n",
       " '활동을': 861,\n",
       " '세기': 862,\n",
       " '시설': 863,\n",
       " '완화': 864,\n",
       " '함의를': 865,\n",
       " '조사를': 866,\n",
       " '남자': 867,\n",
       " '여자': 868,\n",
       " '경로': 869,\n",
       " '지속적으로': 870,\n",
       " '극복': 871,\n",
       " '성취': 872,\n",
       " '생산': 873,\n",
       " '구체적으로': 874,\n",
       " '집단에': 875,\n",
       " '집중': 876,\n",
       " '가운데': 877,\n",
       " '우울증': 878,\n",
       " '사람': 879,\n",
       " '분석과': 880,\n",
       " '시기': 881,\n",
       " '공간': 882,\n",
       " '배경': 883,\n",
       " '설문을': 884,\n",
       " '개인정보': 885,\n",
       " '청소년이': 886,\n",
       " '예술': 887,\n",
       " '커뮤니케이션': 888,\n",
       " '분석하는': 889,\n",
       " '희망': 890,\n",
       " '한류': 891,\n",
       " '뿐만': 892,\n",
       " '살펴본': 893,\n",
       " '갖는': 894,\n",
       " '정도': 895,\n",
       " '중심의': 896,\n",
       " '불구하고': 897,\n",
       " '갈등': 898,\n",
       " '학습자의': 899,\n",
       " '위계적': 900,\n",
       " '지역의': 901,\n",
       " '실행': 902,\n",
       " '실험': 903,\n",
       " '대학생활적응': 904,\n",
       " '있는지를': 905,\n",
       " '회피': 906,\n",
       " '적합한': 907,\n",
       " '상관분석': 908,\n",
       " '외국인': 909,\n",
       " '분석은': 910,\n",
       " '역시': 911,\n",
       " '검정': 912,\n",
       " '인식을': 913,\n",
       " '가능한': 914,\n",
       " '전문가': 915,\n",
       " '서비스를': 916,\n",
       " '자기효능감은': 917,\n",
       " '수준에': 918,\n",
       " '결론': 919,\n",
       " '남성': 920,\n",
       " '경기': 921,\n",
       " '2016년': 922,\n",
       " '죽음': 923,\n",
       " '연구들': 924,\n",
       " '과제': 925,\n",
       " '적용하여': 926,\n",
       " '가지는': 927,\n",
       " '영향력이': 928,\n",
       " '상황에서': 929,\n",
       " '요인에': 930,\n",
       " '관심': 931,\n",
       " '스트레스가': 932,\n",
       " '마음챙김': 933,\n",
       " '분야': 934,\n",
       " '관계는': 935,\n",
       " '결과에': 936,\n",
       " '인식과': 937,\n",
       " '보이': 938,\n",
       " '부적응': 939,\n",
       " '그들의': 940,\n",
       " '동아시아': 941,\n",
       " '범주': 942,\n",
       " '여성의': 943,\n",
       " '정서조절': 944,\n",
       " '타인': 945,\n",
       " '학생의': 946,\n",
       " '몰입에': 947,\n",
       " '선행': 948,\n",
       " '이용자': 949,\n",
       " '설계': 950,\n",
       " '공유': 951,\n",
       " '유아': 952,\n",
       " '지지와': 953,\n",
       " '구': 954,\n",
       " '제품': 955,\n",
       " '체육': 956,\n",
       " '실무적': 957,\n",
       " '제시하고자': 958,\n",
       " '연구자': 959,\n",
       " '처리': 960,\n",
       " '의도에': 961,\n",
       " '미칠': 962,\n",
       " '보인다': 963,\n",
       " '긍정': 964,\n",
       " '교육적': 965,\n",
       " '이야기': 966,\n",
       " '살펴보면': 967,\n",
       " '경험과': 968,\n",
       " '텍스트': 969,\n",
       " '정도가': 970,\n",
       " '으로는': 971,\n",
       " '요인과': 972,\n",
       " '유형에': 973,\n",
       " '자료로': 974,\n",
       " '변수': 975,\n",
       " '스마트': 976,\n",
       " '감성': 977,\n",
       " '스스로': 978,\n",
       " '집단이': 979,\n",
       " '정부': 980,\n",
       " '확장': 981,\n",
       " '인성': 982,\n",
       " '명으로': 983,\n",
       " '9': 984,\n",
       " '함을': 985,\n",
       " '추진': 986,\n",
       " '으로서': 987,\n",
       " '성별에': 988,\n",
       " '아닌': 989,\n",
       " '해외': 990,\n",
       " '과학': 991,\n",
       " '관련하여': 992,\n",
       " '자기효능감에': 993,\n",
       " '전문성': 994,\n",
       " '회복': 995,\n",
       " '특성과': 996,\n",
       " '차원에서': 997,\n",
       " '대학생을': 998,\n",
       " '확보': 999,\n",
       " '만족이': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 43358 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./data/embedding/word2vec_okt_all_random_262.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x20aada1f208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word_vectors:\n",
    "        return word_vectors[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 7 which is 0.02 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    tmp = get_vector(word)\n",
    "    if tmp is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = tmp\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length = MAX_SENTENCE_LENGTH,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2798 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "2798/2798 [==============================] - 83s 30ms/step - loss: 4.4576 - val_loss: 5.3737\n",
      "\n",
      "Epoch 00001: saving model to ./save_models/han_rae_extra_all_v3_01_5.37373.h5\n",
      "Epoch 2/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 3.3849 - val_loss: 4.7217\n",
      "\n",
      "Epoch 00002: saving model to ./save_models/han_rae_extra_all_v3_02_4.72173.h5\n",
      "Epoch 3/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 3.1309 - val_loss: 3.8822\n",
      "\n",
      "Epoch 00003: saving model to ./save_models/han_rae_extra_all_v3_03_3.88218.h5\n",
      "Epoch 4/30\n",
      "2798/2798 [==============================] - 77s 27ms/step - loss: 2.7872 - val_loss: 3.5581\n",
      "\n",
      "Epoch 00004: saving model to ./save_models/han_rae_extra_all_v3_04_3.55812.h5\n",
      "Epoch 5/30\n",
      "2798/2798 [==============================] - 75s 27ms/step - loss: 2.5226 - val_loss: 3.3976\n",
      "\n",
      "Epoch 00005: saving model to ./save_models/han_rae_extra_all_v3_05_3.39760.h5\n",
      "Epoch 6/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 2.3200 - val_loss: 3.1466\n",
      "\n",
      "Epoch 00006: saving model to ./save_models/han_rae_extra_all_v3_06_3.14657.h5\n",
      "Epoch 7/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 2.1592 - val_loss: 3.1648\n",
      "\n",
      "Epoch 00007: saving model to ./save_models/han_rae_extra_all_v3_07_3.16479.h5\n",
      "Epoch 8/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 1.9320 - val_loss: 3.1189\n",
      "\n",
      "Epoch 00008: saving model to ./save_models/han_rae_extra_all_v3_08_3.11887.h5\n",
      "Epoch 9/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 1.7938 - val_loss: 3.2481\n",
      "\n",
      "Epoch 00009: saving model to ./save_models/han_rae_extra_all_v3_09_3.24810.h5\n",
      "Epoch 10/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 1.6280 - val_loss: 3.8188\n",
      "\n",
      "Epoch 00010: saving model to ./save_models/han_rae_extra_all_v3_10_3.81876.h5\n",
      "Epoch 11/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 1.5007 - val_loss: 3.7933\n",
      "\n",
      "Epoch 00011: saving model to ./save_models/han_rae_extra_all_v3_11_3.79326.h5\n",
      "Epoch 12/30\n",
      "2798/2798 [==============================] - 76s 27ms/step - loss: 1.4058 - val_loss: 3.2311\n",
      "\n",
      "Epoch 00012: saving model to ./save_models/han_rae_extra_all_v3_12_3.23106.h5\n",
      "Epoch 13/30\n",
      "2798/2798 [==============================] - 77s 27ms/step - loss: 1.2725 - val_loss: 3.3533\n",
      "\n",
      "Epoch 00013: saving model to ./save_models/han_rae_extra_all_v3_13_3.35333.h5\n",
      "time : 1002.6825129985809\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    # first, build a sentence encoder\n",
    "    word_input = Input(shape=(MAX_SENTENCE_LENGTH,), dtype='float32')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(word_sequences)\n",
    "    word_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(word_lstm)\n",
    "    word_att = AttentionWithContext()(word_dense)\n",
    "    wordEncoder = Model(word_input, word_att)\n",
    "\n",
    "    # then, build a document encoder\n",
    "    sent_input = Input(shape=(MAX_SENTENCES, MAX_SENTENCE_LENGTH), dtype='float32')\n",
    "    sent_encoder = TimeDistributed(wordEncoder)(sent_input)\n",
    "    sent_lstm = Bidirectional(LSTM(100, return_sequences=True, kernel_regularizer=l2_reg))(sent_encoder)\n",
    "    sent_dense = TimeDistributed(Dense(200, kernel_regularizer=l2_reg))(sent_lstm)\n",
    "    sent_att = AttentionWithContext()(sent_dense)\n",
    "\n",
    "    # finally, add fc layers for classification\n",
    "    hidden = BatchNormalization()(sent_att)\n",
    "    hidden = Dense(100, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(50, activation='relu')(hidden)\n",
    "    preds = Dense(4)(hidden)\n",
    "    \n",
    "    model = Model(inputs=[sent_input], outputs=[preds])\n",
    "\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss=['mse'], optimizer=optimizer)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_path = './save_models/han_rae_extra_all_{}'.format(version) + '_{epoch:02d}_{val_loss:.5f}.h5'\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "       \n",
    "    history = model.fit(x=[train_X_data], y=[train_Y_data], batch_size=32, epochs=30,\n",
    "                        verbose=True, validation_data=(val_X_data, val_Y_data), callbacks=[es, mc])\n",
    "    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 20, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 200)           4577300   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 200)           40200     \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 4,924,854\n",
      "Trainable params: 588,554\n",
      "Non-trainable params: 4,336,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('./img/HAN_RAE_extra_all_{}.png'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda, Permute, RepeatVector, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'W_regularizer': self.W_regularizer,\n",
    "            'u_regularizer': self.u_regularizer,\n",
    "            'b_regularizer': self.b_regularizer,\n",
    "            'W_constraint': self.W_constraint,\n",
    "            'u_constraint': self.u_constraint,\n",
    "            'b_constraint': self.b_constraint,\n",
    "            'bias': self.bias\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with CustomObjectScope({'AttentionWithContext': AttentionWithContext}):\n",
    "    model = load_model('./save_models/best_models/han_rae_extra_all_v3_08_3.11887.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932/932 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.23074525313316"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_data, test_Y_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2324145, 1.5738947, 1.5536633, 1.9273113],\n",
       "       [2.5566578, 1.6323103, 2.3301997, 1.3653381],\n",
       "       [2.0120263, 3.6481488, 2.941749 , 5.1587553],\n",
       "       ...,\n",
       "       [2.8860307, 2.3267324, 1.5305814, 3.64048  ],\n",
       "       [6.1416945, 2.5322335, 1.276673 , 1.4351026],\n",
       "       [2.6150386, 1.6711218, 3.6250925, 2.0913813]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X_data, batch_size=32)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model('./save_models/decoder_models/residual_decoder_extra_all_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.3338256e-05, 1.0436057e-03, 1.7871942e-04, ..., 7.8560720e-04,\n",
       "        1.4203800e-04, 1.2111555e-04],\n",
       "       [2.1206681e-09, 2.2520903e-04, 3.2404625e-08, ..., 4.2019619e-07,\n",
       "        1.1827879e-05, 1.2617295e-06],\n",
       "       [1.7850081e-06, 8.3498321e-07, 2.9112603e-06, ..., 7.4028424e-07,\n",
       "        1.5019556e-09, 5.1894169e-08],\n",
       "       ...,\n",
       "       [2.7517111e-10, 1.6230730e-04, 6.2496257e-03, ..., 1.5210013e-06,\n",
       "        2.3327459e-04, 3.8886743e-03],\n",
       "       [2.5252689e-19, 2.2580367e-05, 8.6333422e-08, ..., 8.3857034e-14,\n",
       "        1.5818892e-05, 4.5149318e-06],\n",
       "       [1.3201808e-12, 3.4261652e-06, 5.8123836e-11, ..., 5.4892122e-09,\n",
       "        2.3205337e-06, 5.5147098e-10]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode = decoder.predict(pred)\n",
    "test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(test_decode[:, :], test_decode[:, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_predict = test_decode.round()\\ntest_predict'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test_predict = test_decode.round()\n",
    "test_predict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = np.where(test_decode > 0.5, 1, 0)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix = multilabel_confusion_matrix(one_hot_test_labels, predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test label load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4차산업혁명</th>\n",
       "      <th>가족건강성</th>\n",
       "      <th>간호</th>\n",
       "      <th>간호대학생</th>\n",
       "      <th>간호사</th>\n",
       "      <th>감정</th>\n",
       "      <th>감정노동</th>\n",
       "      <th>개인정보</th>\n",
       "      <th>개인정보보호</th>\n",
       "      <th>개인정보보호법</th>\n",
       "      <th>...</th>\n",
       "      <th>한류</th>\n",
       "      <th>한반도</th>\n",
       "      <th>한중</th>\n",
       "      <th>해외직접투자</th>\n",
       "      <th>핵심역량</th>\n",
       "      <th>행복감</th>\n",
       "      <th>현상학</th>\n",
       "      <th>확인적요인분석</th>\n",
       "      <th>회복탄력성</th>\n",
       "      <th>희망</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4차산업혁명  가족건강성  간호  간호대학생  간호사  감정  감정노동  개인정보  개인정보보호  개인정보보호법  ...  한류  \\\n",
       "0         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "1         0      0   0      0    1   0     0     0       0        0  ...   0   \n",
       "2         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "3         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "4         0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "..      ...    ...  ..    ...  ...  ..   ...   ...     ...      ...  ...  ..   \n",
       "927       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "928       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "929       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "930       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "931       0      0   0      0    0   0     0     0       0        0  ...   0   \n",
       "\n",
       "     한반도  한중  해외직접투자  핵심역량  행복감  현상학  확인적요인분석  회복탄력성  희망  \n",
       "0      0   0       0     0    0    0        0      0   0  \n",
       "1      0   0       0     0    0    0        0      0   0  \n",
       "2      0   0       0     0    0    0        0      0   0  \n",
       "3      0   0       0     0    0    0        0      0   0  \n",
       "4      0   0       0     0    0    0        0      0   0  \n",
       "..   ...  ..     ...   ...  ...  ...      ...    ...  ..  \n",
       "927    0   0       0     0    0    0        0      0   0  \n",
       "928    0   0       0     0    0    0        0      0   0  \n",
       "929    0   0       0     0    0    0        0      0   0  \n",
       "930    0   0       0     0    0    0        0      0   0  \n",
       "931    0   0       0     0    0    0        0      0   0  \n",
       "\n",
       "[932 rows x 262 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = pd.read_excel('./data/all_10_random_12000_262_test.xlsx')\n",
    "test_X = test_X.drop(['Unnamed: 0', 'abstract'], axis=1)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(932, 262)\n"
     ]
    }
   ],
   "source": [
    "one_hot_test_labels = np.array(test_X)\n",
    "print(one_hot_test_labels)\n",
    "print(one_hot_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.016094420600858368\n",
      "precision :  0.3270440251572327\n",
      "recall :  0.03927492447129909\n",
      "f1 :  0.07012811867835468\n",
      "------------------------\n",
      "hamming_loss :  0.0056473806637617535\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='micro'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.016094420600858368\n",
      "precision :  0.05293276108726752\n",
      "recall :  0.03290414878397711\n",
      "f1 :  0.03855507868383405\n",
      "------------------------\n",
      "hamming_loss :  0.0056473806637617535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\mlc2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ', accuracy_score(one_hot_test_labels, test_predict))\n",
    "print('precision : ', precision_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('recall : ', recall_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('f1 : ', f1_score(one_hot_test_labels, test_predict, average='samples'))\n",
    "print('------------------------')\n",
    "print('hamming_loss : ', hamming_loss(one_hot_test_labels, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ccf08da81ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# wrong example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m attention_extractor = Model(inputs=[document_input],\n\u001b[0m\u001b[0;32m      3\u001b[0m                             outputs=[word_attention, sentence_attention])\n\u001b[0;32m      4\u001b[0m \u001b[0mattention_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'document_input' is not defined"
     ]
    }
   ],
   "source": [
    "# wrong example\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attention, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "attention_extractor.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review):    \n",
    "    sentences = sent_tokenize(review)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENTENCE_LENGTH)\n",
    "    pad_size = MAX_SENTENCES - tokenized_sentences.shape[0]\n",
    "\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTENCES]\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )\n",
    "    \n",
    "    # word attention만 가져오기\n",
    "    pred_attention = attention_extractor.predict(np.asarray([tokenized_sentences]))[0]\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_attention[0][i][::-1][:len(words)][::-1])\n",
    "        pred_att = np.expand_dims(pred_att, axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(len(words), 2))\n",
    "        plt.rc('xtick', labelsize=22)\n",
    "        heatmap = sn.heatmap(pred_att, xticklabels=words, square=True, linewidths=0.1)\n",
    "        plt.xticks(rotation=70)\n",
    "        plt.show()\n",
    "        \n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
